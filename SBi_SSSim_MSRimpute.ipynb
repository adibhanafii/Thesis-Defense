{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpX2ZBl0M3OF"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdAuz3TjM19K"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") \n",
        "\n",
        "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
        "from sklearn.impute import KNNImputer\n",
        "from IPython.display import display\n",
        "\n",
        "np.set_printoptions(formatter={'float': lambda x: \"{:.3f}\".format(x)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6oPSlhRM9Sf"
      },
      "source": [
        "# Input Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2hEIISRNCZ6"
      },
      "outputs": [],
      "source": [
        "class DataHandle(object):\n",
        "    \"\"\"Read data and store to D_gene object\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data_categ : \"missing\" | \"complete\", default=\"missing\"\n",
        "        Select the object to read approriate the kind of data \n",
        "    \"\"\"\n",
        "    def __init__(self, filepath, filename, data_categ=\"missing\", verbose=False):\n",
        "        self.data_categ = data_categ\n",
        "        \n",
        "        if data_categ == \"missing\":\n",
        "            self.read_missing_data(filepath, filename, verbose=verbose)\n",
        "        elif data_categ == \"complete\":\n",
        "            self.read_complete_data(filepath, filename, verbose=verbose)\n",
        "        else:\n",
        "            print(\"Please provide with the correct category: ('missing' or 'complete')\")\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def is_duplicate_nan_in_row(self):\n",
        "        if self.data_categ == \"missing\":\n",
        "            value = self.value\n",
        "            nan_per_row = [np.sum(np.isnan(row)) for row in value]\n",
        "            more_than_one = np.any(np.array(nan_per_row) > 1)\n",
        "            return more_than_one\n",
        "        else:\n",
        "            print(\"You cannot find NaN entries in complete matrix!\")\n",
        "            return None\n",
        "    \n",
        "    def num_nan_rows(self):\n",
        "        value = self.value\n",
        "        nan_idx = np.argwhere(np.isnan(value))\n",
        "        return len(value[nan_idx[:, 0], nan_idx[:, 1]])\n",
        "    \n",
        "        \n",
        "    def compute_std(self, D_gene_complete):\n",
        "        data_categ = self.data_categ\n",
        "        if data_categ == \"missing\":\n",
        "            missing_idx = self.get_missing_idx(self.value, data_categ)\n",
        "            y_true = D_gene_complete[missing_idx[:,0], missing_idx[:,1]]\n",
        "            return np.std(y_true)\n",
        "        \n",
        "        else:\n",
        "            print(\"You cannot get missing indices for complete matrix!\")\n",
        "            return None\n",
        "        \n",
        "    def get_p_mis_rate(self):\n",
        "        data_categ = self.data_categ\n",
        "        value = self.value\n",
        "        if data_categ == \"missing\":\n",
        "            missing_idx = self.get_missing_idx(value, data_categ)\n",
        "            return len(missing_idx)/ (len(value))\n",
        "        \n",
        "        else:\n",
        "            print(\"You cannot get missing rate for complete matrix!\")\n",
        "            return None\n",
        "        \n",
        "    def get_F_mat(self):\n",
        "        data_categ = self.data_categ\n",
        "        value = self.value\n",
        "        if data_categ == \"missing\":\n",
        "            missing_idx = self.get_missing_idx(value, data_categ)\n",
        "            F_mat = np.ones_like(value, dtype=int)\n",
        "            F_mat[missing_idx[:,0], missing_idx[:, 1]] = 0\n",
        "            return F_mat\n",
        "        \n",
        "        else:\n",
        "            print(\"You cannot get indicator matrix for complete matrix!\")\n",
        "            return None\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_missing_idx(value, data_categ):\n",
        "        if data_categ == \"missing\":\n",
        "            missing_idx = np.argwhere(np.isnan(value))\n",
        "            return missing_idx\n",
        "        \n",
        "        else:\n",
        "            print(\"You cannot get missing indices for complete matrix!\")\n",
        "            return None\n",
        "        \n",
        "    def read_missing_data(self, filepath, filename, verbose=False):\n",
        "        path_to_file = os.path.join(filepath, filename)\n",
        "        self.raw_df = pd.read_csv(path_to_file)\n",
        "\n",
        "        self.value = self.raw_df.iloc[:, 1:].values\n",
        "\n",
        "        if verbose:\n",
        "            display(self.raw_df)\n",
        "            display(self.value)   \n",
        "            \n",
        "    def read_complete_data(self, filepath, filename, verbose=False):\n",
        "        path_to_file = os.path.join(filepath, filename)\n",
        "        self.raw_df = pd.read_csv(path_to_file)\n",
        "\n",
        "        self.value = self.raw_df.iloc[:, 1:].values\n",
        "\n",
        "        if verbose:\n",
        "            display(self.raw_df)\n",
        "            display(self.value)  \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5bqpX-ONIRW"
      },
      "source": [
        "## Load Dataset Lengkap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJorfkw-TC1a",
        "outputId": "6202a248-0a6f-457a-e013-579e4c8c30bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8IC2aak9NJ1f",
        "outputId": "10d2a1fd-69f1-41b5-a718-29b02f354198",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      ID_REF  GSM4037995  GSM4037996  GSM4037997  GSM4037998  GSM4037999  \\\n",
              "0       AAMP     2611.34     2519.65     2841.68     2850.22     2758.71   \n",
              "1     ABI3BP       29.81       34.94       33.78       53.94       51.88   \n",
              "2       ACHE       64.79       74.14       73.67       98.17      120.14   \n",
              "3      ACTG2       29.81       34.94       33.78       38.84       29.13   \n",
              "4      ACVR1      970.40     1263.76     1134.33     1165.12     1207.79   \n",
              "..       ...         ...         ...         ...         ...         ...   \n",
              "779  ZFYVE16     1160.26     1373.84     1206.84     1787.59     1751.16   \n",
              "780   ZFYVE9      996.02     1231.18     1154.21      908.36      974.79   \n",
              "781  ZKSCAN5      171.78      181.98      137.99      257.84      274.87   \n",
              "782   ZNF143      789.58      984.04      797.54     1065.87     1006.64   \n",
              "783   ZNF346      235.07      199.95      261.95      449.87      411.39   \n",
              "\n",
              "     GSM4038000  \n",
              "0       2589.80  \n",
              "1         62.82  \n",
              "2        122.99  \n",
              "3         31.41  \n",
              "4       1172.35  \n",
              "..          ...  \n",
              "779     1785.52  \n",
              "780     1037.87  \n",
              "781      268.98  \n",
              "782     1033.44  \n",
              "783      460.98  \n",
              "\n",
              "[784 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0bde790-9fe7-4d23-920b-ee1418723d6f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID_REF</th>\n",
              "      <th>GSM4037995</th>\n",
              "      <th>GSM4037996</th>\n",
              "      <th>GSM4037997</th>\n",
              "      <th>GSM4037998</th>\n",
              "      <th>GSM4037999</th>\n",
              "      <th>GSM4038000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAMP</td>\n",
              "      <td>2611.34</td>\n",
              "      <td>2519.65</td>\n",
              "      <td>2841.68</td>\n",
              "      <td>2850.22</td>\n",
              "      <td>2758.71</td>\n",
              "      <td>2589.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABI3BP</td>\n",
              "      <td>29.81</td>\n",
              "      <td>34.94</td>\n",
              "      <td>33.78</td>\n",
              "      <td>53.94</td>\n",
              "      <td>51.88</td>\n",
              "      <td>62.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ACHE</td>\n",
              "      <td>64.79</td>\n",
              "      <td>74.14</td>\n",
              "      <td>73.67</td>\n",
              "      <td>98.17</td>\n",
              "      <td>120.14</td>\n",
              "      <td>122.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ACTG2</td>\n",
              "      <td>29.81</td>\n",
              "      <td>34.94</td>\n",
              "      <td>33.78</td>\n",
              "      <td>38.84</td>\n",
              "      <td>29.13</td>\n",
              "      <td>31.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ACVR1</td>\n",
              "      <td>970.40</td>\n",
              "      <td>1263.76</td>\n",
              "      <td>1134.33</td>\n",
              "      <td>1165.12</td>\n",
              "      <td>1207.79</td>\n",
              "      <td>1172.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>ZFYVE16</td>\n",
              "      <td>1160.26</td>\n",
              "      <td>1373.84</td>\n",
              "      <td>1206.84</td>\n",
              "      <td>1787.59</td>\n",
              "      <td>1751.16</td>\n",
              "      <td>1785.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>780</th>\n",
              "      <td>ZFYVE9</td>\n",
              "      <td>996.02</td>\n",
              "      <td>1231.18</td>\n",
              "      <td>1154.21</td>\n",
              "      <td>908.36</td>\n",
              "      <td>974.79</td>\n",
              "      <td>1037.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>781</th>\n",
              "      <td>ZKSCAN5</td>\n",
              "      <td>171.78</td>\n",
              "      <td>181.98</td>\n",
              "      <td>137.99</td>\n",
              "      <td>257.84</td>\n",
              "      <td>274.87</td>\n",
              "      <td>268.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>782</th>\n",
              "      <td>ZNF143</td>\n",
              "      <td>789.58</td>\n",
              "      <td>984.04</td>\n",
              "      <td>797.54</td>\n",
              "      <td>1065.87</td>\n",
              "      <td>1006.64</td>\n",
              "      <td>1033.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>783</th>\n",
              "      <td>ZNF346</td>\n",
              "      <td>235.07</td>\n",
              "      <td>199.95</td>\n",
              "      <td>261.95</td>\n",
              "      <td>449.87</td>\n",
              "      <td>411.39</td>\n",
              "      <td>460.98</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>784 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0bde790-9fe7-4d23-920b-ee1418723d6f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b0bde790-9fe7-4d23-920b-ee1418723d6f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b0bde790-9fe7-4d23-920b-ee1418723d6f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "D_gene_complete = DataHandle(\"/content/drive/MyDrive/SKRIPSI/\", \"GSE135923-GPL26599_series_matrix.csv\", verbose=False,\n",
        "                             data_categ=\"complete\")\n",
        "display(D_gene_complete.raw_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTt5cYfbNTl9"
      },
      "outputs": [],
      "source": [
        "D_gene = D_gene_complete.value.copy()\n",
        "\n",
        "idx_not_NaN = np.array([np.all(np.logical_not(np.isnan(row))) for row in D_gene])\n",
        "D_gene_not_NaN = D_gene[idx_not_NaN]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJD8JzSxqSe3"
      },
      "source": [
        "# Generate Dataset with MCAR Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtlLDt_ZqSe3"
      },
      "outputs": [],
      "source": [
        "# Function produce_NA for generating missing values ------------------------------------------------------\n",
        "\n",
        "def produce_NA(X, p_miss, mecha=\"MCAR\", opt=None, p_obs=None, q=None):\n",
        "    \"\"\"\n",
        "    Generate missing values for specifics missing-data mechanism and proportion of missing values. \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    X : torch.DoubleTensor or np.ndarray, shape (n, d)\n",
        "        Data for which missing values will be simulated.\n",
        "        If a numpy array is provided, it will be converted to a pytorch tensor.\n",
        "    p_miss : float\n",
        "        Proportion of missing values to generate for variables which will have missing values.\n",
        "    mecha : str, \n",
        "            Indicates the missing-data mechanism to be used. \"MCAR\" by default, \"MAR\", \"MNAR\" or \"MNARsmask\"\n",
        "    opt: str, \n",
        "         For mecha = \"MNAR\", it indicates how the missing-data mechanism is generated: using a logistic regression (\"logistic\"), quantile censorship (\"quantile\") or logistic regression for generating a self-masked MNAR mechanism (\"selfmasked\").\n",
        "    p_obs : float\n",
        "            If mecha = \"MAR\", or mecha = \"MNAR\" with opt = \"logistic\" or \"quanti\", proportion of variables with *no* missing values that will be used for the logistic masking model.\n",
        "    q : float\n",
        "        If mecha = \"MNAR\" and opt = \"quanti\", quantile level at which the cuts should occur.\n",
        "    \n",
        "    Returns\n",
        "    ----------\n",
        "    A dictionnary containing:\n",
        "    'X_init': the initial data matrix.\n",
        "    'X_incomp': the data with the generated missing values.\n",
        "    'mask': a matrix indexing the generated missing values.s\n",
        "    \"\"\"\n",
        "    \n",
        "    to_torch = torch.is_tensor(X) ## output a pytorch tensor, or a numpy array\n",
        "    if not to_torch:\n",
        "        X = X.astype(np.float32)\n",
        "        X = torch.from_numpy(X)\n",
        "    \n",
        "    if mecha == \"MAR\":\n",
        "        mask = MAR_mask(X, p_miss, p_obs).double()\n",
        "    elif mecha == \"MNAR\" and opt == \"logistic\":\n",
        "        mask = MNAR_mask_logistic(X, p_miss, p_obs).double()\n",
        "    elif mecha == \"MNAR\" and opt == \"quantile\":\n",
        "        mask = MNAR_mask_quantiles(X, p_miss, q, 1-p_obs).double()\n",
        "    elif mecha == \"MNAR\" and opt == \"selfmasked\":\n",
        "        mask = MNAR_self_mask_logistic(X, p_miss).double()\n",
        "    else:\n",
        "        mask = (torch.rand(X.shape) < p_miss).double()\n",
        "    \n",
        "    X_nas = X.clone()\n",
        "    X_nas[mask.bool()] = np.nan\n",
        "    \n",
        "    return {'X_init': X.double(), 'X_incomp': X_nas.double(), 'mask': mask}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E46E2zoXqSe4"
      },
      "source": [
        "## Generate Missing Values Data Pertama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ2qJpUeqSe4"
      },
      "source": [
        "### Generate 5% MV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGnZpIwBqSe5",
        "outputId": "4b86c692-fad0-4eb3-92dd-d976d003ab79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of newly generated missing values:  5.038265306122449  %\n"
          ]
        }
      ],
      "source": [
        "# Minimal example for generating missing data ------------------------\n",
        "X_miss_mcar = produce_NA(D_gene, p_miss=0.05, mecha=\"MCAR\")\n",
        "\n",
        "X_missing_5 = X_miss_mcar['X_incomp']\n",
        "R_mcar_5 = X_miss_mcar['mask']\n",
        "\n",
        "print(\"Percentage of newly generated missing values: \", (R_mcar_5.sum()).numpy()/np.prod(R_mcar_5.size())*100, \" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uy0B0aoQqSe5"
      },
      "outputs": [],
      "source": [
        "data_missing_5 = pd.DataFrame(X_missing_5.numpy(),\n",
        "                               columns = D_gene_complete.raw_df.columns[1:])\n",
        "data_missing_5.insert(loc = 0,\n",
        "                       column = D_gene_complete.raw_df.columns[0],\n",
        "                       value = D_gene_complete.raw_df['ID_REF'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOK8DOXCqSe6"
      },
      "source": [
        "### Generate 10% MV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMA-p5MxqSe6",
        "outputId": "f6399cdc-8c4f-4b87-cfc8-fbe685620e1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of newly generated missing values:  9.800170068027212  %\n"
          ]
        }
      ],
      "source": [
        "# Minimal example for generating missing data ------------------------\n",
        "X_miss_mcar = produce_NA(D_gene, p_miss=0.1, mecha=\"MCAR\")\n",
        "\n",
        "X_missing_10 = X_miss_mcar['X_incomp']\n",
        "R_mcar_10 = X_miss_mcar['mask']\n",
        "\n",
        "print(\"Percentage of newly generated missing values: \", (R_mcar_10.sum()).numpy()/np.prod(R_mcar_10.size())*100, \" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yv4ILKC8qSe7"
      },
      "outputs": [],
      "source": [
        "data_missing_10 = pd.DataFrame(X_missing_10.numpy(),\n",
        "                               columns = D_gene_complete.raw_df.columns[1:])\n",
        "data_missing_10.insert(loc = 0,\n",
        "                       column = D_gene_complete.raw_df.columns[0],\n",
        "                       value = D_gene_complete.raw_df['ID_REF'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0thnZExFqSe7"
      },
      "source": [
        "### Generate 15% MV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-gwez-RqSe9",
        "outputId": "f0b637f9-e8f4-41e1-d9a3-217436f4769a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of newly generated missing values:  14.306972789115646  %\n"
          ]
        }
      ],
      "source": [
        "# Minimal example for generating missing data ------------------------\n",
        "X_miss_mcar = produce_NA(D_gene, p_miss=0.15, mecha=\"MCAR\")\n",
        "\n",
        "X_missing_15 = X_miss_mcar['X_incomp']\n",
        "R_mcar_15 = X_miss_mcar['mask']\n",
        "\n",
        "print(\"Percentage of newly generated missing values: \", (R_mcar_15.sum()).numpy()/np.prod(R_mcar_15.size())*100, \" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTgLMkgPqSe9"
      },
      "outputs": [],
      "source": [
        "data_missing_15 = pd.DataFrame(X_missing_15.numpy(),\n",
        "                               columns = D_gene_complete.raw_df.columns[1:])\n",
        "data_missing_15.insert(loc = 0,\n",
        "                       column = D_gene_complete.raw_df.columns[0],\n",
        "                       value = D_gene_complete.raw_df['ID_REF'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qobHk1aqSe9"
      },
      "source": [
        "### Generate 20% MV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvC1ZE5-qSe-",
        "outputId": "fd12a468-82bc-441f-fdc8-f8536e99fc2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of newly generated missing values:  19.196428571428573  %\n"
          ]
        }
      ],
      "source": [
        "# Minimal example for generating missing data ------------------------\n",
        "X_miss_mcar = produce_NA(D_gene, p_miss=0.2, mecha=\"MCAR\")\n",
        "\n",
        "X_missing_20 = X_miss_mcar['X_incomp']\n",
        "R_mcar_20 = X_miss_mcar['mask']\n",
        "\n",
        "print(\"Percentage of newly generated missing values: \", (R_mcar_20.sum()).numpy()/np.prod(R_mcar_20.size())*100, \" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wS7z9lLVqSe_"
      },
      "outputs": [],
      "source": [
        "data_missing_20 = pd.DataFrame(X_missing_20.numpy(),\n",
        "                               columns = D_gene_complete.raw_df.columns[1:])\n",
        "data_missing_20.insert(loc = 0,\n",
        "                       column = D_gene_complete.raw_df.columns[0],\n",
        "                       value = D_gene_complete.raw_df['ID_REF'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7WPFX98qSe_"
      },
      "source": [
        "### Generate 25% MV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlvqIDWXqSfA",
        "outputId": "0a4d8e64-6574-4134-d151-f2745ab3579b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of newly generated missing values:  25.42517006802721  %\n"
          ]
        }
      ],
      "source": [
        "# Minimal example for generating missing data ------------------------\n",
        "X_miss_mcar = produce_NA(D_gene, p_miss=0.25, mecha=\"MCAR\")\n",
        "\n",
        "X_missing_25 = X_miss_mcar['X_incomp']\n",
        "R_mcar_25 = X_miss_mcar['mask']\n",
        "\n",
        "print(\"Percentage of newly generated missing values: \", (R_mcar_25.sum()).numpy()/np.prod(R_mcar_25.size())*100, \" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5x0BF7_qSfB"
      },
      "outputs": [],
      "source": [
        "data_missing_25 = pd.DataFrame(X_missing_25.numpy(),\n",
        "                               columns = D_gene_complete.raw_df.columns[1:])\n",
        "data_missing_25.insert(loc = 0,\n",
        "                       column = D_gene_complete.raw_df.columns[0],\n",
        "                       value = D_gene_complete.raw_df['ID_REF'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8jq8cKuqSfB"
      },
      "source": [
        "### Generate 30% MV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRD1lTYIqSfB",
        "outputId": "b6231586-70b8-41df-bec7-614ad101a65c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of newly generated missing values:  30.272108843537417  %\n"
          ]
        }
      ],
      "source": [
        "# Minimal example for generating missing data ------------------------\n",
        "X_miss_mcar = produce_NA(D_gene, p_miss=0.3, mecha=\"MCAR\")\n",
        "\n",
        "X_missing_30 = X_miss_mcar['X_incomp']\n",
        "R_mcar_30 = X_miss_mcar['mask']\n",
        "\n",
        "print(\"Percentage of newly generated missing values: \", (R_mcar_30.sum()).numpy()/np.prod(R_mcar_30.size())*100, \" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSJZXyOtqSfC"
      },
      "outputs": [],
      "source": [
        "data_missing_30 = pd.DataFrame(X_missing_30.numpy(),\n",
        "                               columns = D_gene_complete.raw_df.columns[1:])\n",
        "data_missing_30.insert(loc = 0,\n",
        "                       column = D_gene_complete.raw_df.columns[0],\n",
        "                       value = D_gene_complete.raw_df['ID_REF'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft41ns9ZYNfz"
      },
      "source": [
        "### Generate 35% MV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6231586-70b8-41df-bec7-614ad101a65c",
        "id": "qfmfzzA1YNf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of newly generated missing values:  30.272108843537417  %\n"
          ]
        }
      ],
      "source": [
        "# Minimal example for generating missing data ------------------------\n",
        "X_miss_mcar = produce_NA(D_gene, p_miss=0.35, mecha=\"MCAR\")\n",
        "\n",
        "X_missing_35 = X_miss_mcar['X_incomp']\n",
        "R_mcar_35 = X_miss_mcar['mask']\n",
        "\n",
        "print(\"Percentage of newly generated missing values: \", (R_mcar_35.sum()).numpy()/np.prod(R_mcar_35.size())*100, \" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yyf1k7_MYNf1"
      },
      "outputs": [],
      "source": [
        "data_missing_35 = pd.DataFrame(X_missing_35.numpy(),\n",
        "                               columns = D_gene_complete.raw_df.columns[1:])\n",
        "data_missing_35.insert(loc = 0,\n",
        "                       column = D_gene_complete.raw_df.columns[0],\n",
        "                       value = D_gene_complete.raw_df['ID_REF'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLfAdXyDqSfC"
      },
      "source": [
        "### Generate 40% MV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl4PAIkpqSfD",
        "outputId": "f55eadaa-7590-48b2-cbd7-f1be7fb831f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of newly generated missing values:  39.98724489795919  %\n"
          ]
        }
      ],
      "source": [
        "# Minimal example for generating missing data ------------------------\n",
        "X_miss_mcar = produce_NA(D_gene, p_miss=0.4, mecha=\"MCAR\")\n",
        "\n",
        "X_missing_40 = X_miss_mcar['X_incomp']\n",
        "R_mcar_40 = X_miss_mcar['mask']\n",
        "\n",
        "print(\"Percentage of newly generated missing values: \", (R_mcar_40.sum()).numpy()/np.prod(R_mcar_40.size())*100, \" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dmp4h4AaqSfD"
      },
      "outputs": [],
      "source": [
        "data_missing_40 = pd.DataFrame(X_missing_40.numpy(),\n",
        "                               columns = D_gene_complete.raw_df.columns[1:])\n",
        "data_missing_40.insert(loc = 0,\n",
        "                       column = D_gene_complete.raw_df.columns[0],\n",
        "                       value = D_gene_complete.raw_df['ID_REF'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSgaI3ZcYaXj"
      },
      "source": [
        "### Generate 45% MV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f55eadaa-7590-48b2-cbd7-f1be7fb831f1",
        "id": "wzcI4olsYaXj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of newly generated missing values:  39.98724489795919  %\n"
          ]
        }
      ],
      "source": [
        "# Minimal example for generating missing data ------------------------\n",
        "X_miss_mcar = produce_NA(D_gene, p_miss=0.45, mecha=\"MCAR\")\n",
        "\n",
        "X_missing_45 = X_miss_mcar['X_incomp']\n",
        "R_mcar_45 = X_miss_mcar['mask']\n",
        "\n",
        "print(\"Percentage of newly generated missing values: \", (R_mcar_45.sum()).numpy()/np.prod(R_mcar_45.size())*100, \" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d400vzJKYaXk"
      },
      "outputs": [],
      "source": [
        "data_missing_45 = pd.DataFrame(X_missing_45.numpy(),\n",
        "                               columns = D_gene_complete.raw_df.columns[1:])\n",
        "data_missing_45.insert(loc = 0,\n",
        "                       column = D_gene_complete.raw_df.columns[0],\n",
        "                       value = D_gene_complete.raw_df['ID_REF'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rect4SNfqSfE"
      },
      "source": [
        "### Generate 50% MV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytqtkFmZqSfE",
        "outputId": "f0391c17-4ca8-4809-cbbd-2f6fb83742e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of newly generated missing values:  50.595238095238095  %\n"
          ]
        }
      ],
      "source": [
        "# Minimal example for generating missing data ------------------------\n",
        "X_miss_mcar = produce_NA(D_gene, p_miss=0.5, mecha=\"MCAR\")\n",
        "\n",
        "X_missing_50 = X_miss_mcar['X_incomp']\n",
        "R_mcar_50 = X_miss_mcar['mask']\n",
        "\n",
        "print(\"Percentage of newly generated missing values: \", (R_mcar_50.sum()).numpy()/np.prod(R_mcar_50.size())*100, \" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWoWqLvbqSfF"
      },
      "outputs": [],
      "source": [
        "data_missing_50 = pd.DataFrame(X_missing_50.numpy(),\n",
        "                               columns = D_gene_complete.raw_df.columns[1:])\n",
        "data_missing_50.insert(loc = 0,\n",
        "                       column = D_gene_complete.raw_df.columns[0],\n",
        "                       value = D_gene_complete.raw_df['ID_REF'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J107JIIahuHF"
      },
      "source": [
        "### Generate 60% MV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Minimal example for generating missing data ------------------------\n",
        "X_miss_mcar = produce_NA(D_gene, p_miss=0.6, mecha=\"MCAR\")\n",
        "\n",
        "X_missing_60 = X_miss_mcar['X_incomp']\n",
        "R_mcar_60 = X_miss_mcar['mask']\n",
        "\n",
        "print(\"Percentage of newly generated missing values: \", (R_mcar_60.sum()).numpy()/np.prod(R_mcar_60.size())*100, \" %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEtBctbyCVPk",
        "outputId": "6d83dc47-94f2-4fe8-bd2d-4f129f85a979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of newly generated missing values:  60.26785714285714  %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_missing_60 = pd.DataFrame(X_missing_60.numpy(),\n",
        "                               columns = D_gene_complete.raw_df.columns[1:])\n",
        "data_missing_60.insert(loc = 0,\n",
        "                       column = D_gene_complete.raw_df.columns[0],\n",
        "                       value = D_gene_complete.raw_df['ID_REF'])"
      ],
      "metadata": {
        "id": "g9dc4JLBCoQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAGdPmBDqSfF"
      },
      "source": [
        "## Export as csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izFCMU7aqSfF"
      },
      "outputs": [],
      "source": [
        "data_missing_5.to_csv('/content/drive/MyDrive/SKRIPSI/data missing GSE135923-GPL26599_v5/data missing 5%.csv', index = False)\n",
        "data_missing_10.to_csv('/content/drive/MyDrive/SKRIPSI/data missing GSE135923-GPL26599_v5/data missing 10%.csv', index = False)\n",
        "data_missing_15.to_csv('/content/drive/MyDrive/SKRIPSI/data missing GSE135923-GPL26599_v5/data missing 15%.csv', index = False)\n",
        "data_missing_20.to_csv('/content/drive/MyDrive/SKRIPSI/data missing GSE135923-GPL26599_v5/data missing 20%.csv', index = False)\n",
        "data_missing_25.to_csv('/content/drive/MyDrive/SKRIPSI/data missing GSE135923-GPL26599_v5/data missing 25%.csv', index = False)\n",
        "data_missing_30.to_csv('/content/drive/MyDrive/SKRIPSI/data missing GSE135923-GPL26599_v5/data missing 30%.csv', index = False)\n",
        "data_missing_40.to_csv('/content/drive/MyDrive/SKRIPSI/data missing GSE135923-GPL26599_v5/data missing 40%.csv', index = False)\n",
        "data_missing_50.to_csv('/content/drive/MyDrive/SKRIPSI/data missing GSE135923-GPL26599_v5/data missing 50%.csv', index = False)\n",
        "data_missing_60.to_csv('/content/drive/MyDrive/SKRIPSI/data missing GSE135923-GPL26599_v5/data missing 50%.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_missing_35.to_csv('/content/drive/MyDrive/SKRIPSI/data missing GSE135923-GPL26599_v5/data missing 60%.csv', index = False)\n",
        "data_missing_45.to_csv('/content/drive/MyDrive/SKRIPSI/data missing GSE135923-GPL26599_v5/data missing 60%.csv', index = False)"
      ],
      "metadata": {
        "id": "wuZ21IWWCvZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFXuhgCkNjhQ"
      },
      "source": [
        "## Load Dataset Missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b06dVvXyNlSd",
        "outputId": "af8eca34-2737-44b6-8aab-0f3398befaf2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data missing 5%.csv',\n",
              " 'data missing 10%.csv',\n",
              " 'data missing 15%.csv',\n",
              " 'data missing 20%.csv',\n",
              " 'data missing 25%.csv',\n",
              " 'data missing 30%.csv',\n",
              " 'data missing 40%.csv',\n",
              " 'data missing 50%.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "list_missing_files = [f\"data missing {p_mis_rate:d}%.csv\"for p_mis_rate in [5, 10, 15, 20, 25, 30, 40, 50]]\n",
        "list_missing_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ooj9Xb-yNpKP"
      },
      "outputs": [],
      "source": [
        "D_gene_mis_arr = [0]*len(list_missing_files)\n",
        "for i, missing_file in enumerate(list_missing_files):\n",
        "    D_gene_mis_arr[i] = DataHandle(\"/content/drive/MyDrive/SKRIPSI/data missing GSE135923-GPL26599_v5\", missing_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmW6tCo9N1zX"
      },
      "source": [
        "# Data Imputation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY3IDOrGKJWI"
      },
      "source": [
        "## compute_SSSIM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pkcYTtmKIy4"
      },
      "outputs": [],
      "source": [
        "from skimage.metrics import structural_similarity\n",
        "\n",
        "def sssim(a,b):\n",
        "    # return np.sqrt(np.sum((a - b)**2))/len(a)\n",
        "\n",
        "    # return structural_similarity(a,b, full=True)\n",
        "    n = len(a)\n",
        "\n",
        "    def lmean(i):\n",
        "        if i == 1:  # python index start from 0\n",
        "            c1 = (a[i+1]-a[i])/(a[1]-a[0])\n",
        "            c2 = (b[i+1]-b[i])/(b[1]-b[0])\n",
        "            c3 = (a[i+2]-a[i+1])/(a[1]-a[0])\n",
        "            c4 = (b[i+2]-b[i+1])/(b[1]-b[0])\n",
        "            return np.mean([c1,c2,c3,c4])\n",
        "        elif i == n-2:  # python index start from 0\n",
        "            c1 = (a[i]-a[i-1])/(a[1]-a[0])\n",
        "            c2 = (b[i]-b[i-1])/(b[1]-b[0])\n",
        "            c3 = (a[i+1]-a[i])/(a[1]-a[0])\n",
        "            c4 = (b[i+1]-b[i])/(b[1]-b[0])\n",
        "            return np.mean([c1,c2,c3,c4])\n",
        "        else:\n",
        "            c1 = (a[i]-a[i-1])/(a[1]-a[0])\n",
        "            c2 = (b[i]-b[i-1])/(b[1]-b[0])\n",
        "            c3 = (a[i+1]-a[i])/(a[1]-a[0])\n",
        "            c4 = (b[i+1]-b[i])/(b[1]-b[0])\n",
        "            c5 = (a[i+2]-a[i+1])/(a[1]-a[0])\n",
        "            c6 = (b[i+2]-b[i+1])/(b[1]-b[0])\n",
        "            return np.mean([c1,c2,c3,c4,c5,c6])\n",
        "    \n",
        "    numerator = 0\n",
        "    for i in range(1, n-1):\n",
        "        top = np.abs(((a[i+1]-a[i])/(a[1]-a[0])) - ((b[i+1]-b[i])/(b[1]-b[0])))\n",
        "        \n",
        "        bot_a = np.abs(lmean(i)-(a[i+1]-a[i])/(a[1]-a[0]))\n",
        "        bot_b = np.abs(lmean(i)-(b[i+1]-b[i])/(b[1]-b[0]))\n",
        "        bot = 2*np.max([bot_a, bot_b])\n",
        "\n",
        "        numerator += (top/bot)\n",
        "    \n",
        "    return 1 - (numerator/(n-2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kWQqDDmOB92"
      },
      "source": [
        "## compute_MSR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6nJFBBaOAcL"
      },
      "outputs": [],
      "source": [
        "def compute_MSR(G_bicluster, verbose=False):\n",
        "    \n",
        "    vert_mean_cluster = np.mean(G_bicluster, axis=0)\n",
        "    hort_mean_cluster = np.mean(G_bicluster, axis=1).reshape(-1,1)\n",
        "    global_mean_cluster = np.mean(G_bicluster)\n",
        "    \n",
        "    Rsq = (G_bicluster - hort_mean_cluster - vert_mean_cluster + global_mean_cluster)**2\n",
        "    MSR = np.sum(Rsq)/(len(G_bicluster) * len(G_bicluster[0]))\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"G_bicluster\\n{G_bicluster}\")\n",
        "        print(f\"vert_mean_cluster\\n{vert_mean_cluster}\")\n",
        "        print(f\"hort_mean_cluster\\n{hort_mean_cluster}\")\n",
        "        print(f\"global_mean_cluster\\n{global_mean_cluster}\")\n",
        "        print(f\"Rsq\\n{Rsq}\")\n",
        "    return MSR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVejjTkhOHHe"
      },
      "source": [
        "## get_setZ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "747NMaRQOF6p"
      },
      "outputs": [],
      "source": [
        "def get_setZ(D_gene_expression, k_max=4, verbose=False, method=\"intersect\"):\n",
        "    \"\"\"Get the set Z. (see Eq. (7)).\n",
        "    \n",
        "    Sometimes we have to set k_max, maximum number of nearest neighbour\n",
        "    for each distance 'MSR' and 'Euclidean'.\n",
        "        \n",
        "    Parameters\n",
        "    ----------\n",
        "    method : \"intersect\", \"summation\", \"msr\", \"euclid\", default=\"intersect\"\n",
        "        Method to get set Z.\n",
        "    \"\"\"\n",
        "    G_tg = D_gene_expression[0, :]\n",
        "    G_remain = D_gene_expression[1:, :]\n",
        "    \n",
        "    MSR = np.zeros(len(G_remain))\n",
        "    euclidean = np.zeros_like(MSR)\n",
        "    ssim_matrix = np.zeros_like(MSR)\n",
        "    for i, G_near in enumerate(G_remain):\n",
        "        MSR[i] = compute_MSR(np.stack((G_tg, G_near)))\n",
        "        euclidean[i] = np.sqrt(np.sum((G_tg - G_near)**2))/len(G_tg)\n",
        "        #euclidean[i] = np.sqrt(np.sum((G_tg - G_near)**2))\n",
        "        ssim_matrix[i] = sssim(G_tg, G_near) # adib_baru\n",
        "    \n",
        "    nth_MSR = np.argsort(MSR, kind=\"stable\")\n",
        "    nth_euclidean = np.argsort(euclidean, kind=\"stable\")\n",
        "    nth_sum_MSR_euclid = np.argsort(MSR + euclidean, kind=\"stable\")\n",
        "    nth_ssim = np.argsort(ssim_matrix, kind=\"stable\")[::-1] #adib_baru\n",
        "    # nth_setZ = np.intersect1d(nth_MSR[:k_max], nth_euclidean[:k_max]) ##euclidean ganti jadi ssim\n",
        "    nth_setZ = np.intersect1d(nth_MSR[:k_max], nth_ssim[:k_max]) #adib_baru\n",
        "    \n",
        "    if method == \"intersect\":\n",
        "        G_neigh = G_remain[nth_setZ].copy()\n",
        "    elif method == \"summation\":\n",
        "        G_neigh = G_remain[nth_sum_MSR_euclid[:k_max]].copy()\n",
        "    elif method == \"msr\":\n",
        "        G_neigh = G_remain[nth_MSR[:k_max]].copy()\n",
        "    elif method == \"euclid\":\n",
        "        G_neigh = G_remain[nth_euclidean[:k_max]].copy()\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"G_tg\\n{G_tg}\")\n",
        "        print(f\"G_remain\\n{G_remain}\")\n",
        "        print(f\"MSR\\n{MSR}\")\n",
        "        print(f\"euclidean\\n{euclidean}\")\n",
        "        print(f\"nth_MSR\\n{nth_MSR}\")\n",
        "        print(f\"nth_euclidean\\n{nth_euclidean}\")\n",
        "        print(f\"nth_euclidean\\n{nth_ssim}\") #adib_baru\n",
        "        print(f\"nth_setZ\\n{nth_setZ}\")\n",
        "        print(f\"G_neigh\\n{G_neigh}\")\n",
        "    \n",
        "    return np.concatenate((G_tg[np.newaxis, :], G_neigh))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPSJaLL3OX9w"
      },
      "source": [
        "## column_elimination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGxEbygHOalC"
      },
      "outputs": [],
      "source": [
        "def column_elimination(bicluster, target_col, show_plot=False):\n",
        "    \"\"\"Perform column elimination in bicluster Z\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    C_bicluster : ndarray of shape ((u+1)_genes, v_samples)\n",
        "        A bicluster that consists of nearest rows and columns\n",
        "        to the target column and target row\n",
        "    \n",
        "    target_col_in_C : int\n",
        "        A column index of target column relative to the C_bicluster\n",
        "    \"\"\"\n",
        "    \n",
        "    varphi = len(bicluster[0])/2\n",
        "\n",
        "    bicluster_shape = bicluster.shape\n",
        "    col_range = np.ones(bicluster_shape[1], dtype=bool)\n",
        "    col_without_target =  col_range.copy()\n",
        "    col_without_target[target_col] = False\n",
        "\n",
        "    if show_plot:\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(8, 12), dpi=100)\n",
        "    \n",
        "    k = 0\n",
        "    col_range_final = col_range.copy()\n",
        "    while True:\n",
        "        #print(f\"col_range  {col_range}\")\n",
        "        max_MSR = compute_MSR(bicluster[:, col_range].copy())\n",
        "        temp = max_MSR\n",
        "\n",
        "        MSR_arr = np.ones(bicluster_shape[1]) * np.nan\n",
        "        delete_col = -1\n",
        "        for i, p_col in enumerate(range(len(col_without_target))):\n",
        "            if col_without_target[p_col]:\n",
        "                col_without_p_col = col_range.copy()\n",
        "                col_without_p_col[p_col] = False\n",
        "                \n",
        "                temp1 = compute_MSR(bicluster[:, col_without_p_col].copy())\n",
        "                MSR_arr[i] = temp1\n",
        "            \n",
        "                if temp1 < max_MSR:\n",
        "                    max_MSR = temp1\n",
        "                    delete_col = p_col\n",
        "        \n",
        "        if k == 0 and show_plot:\n",
        "                axes[0].plot(np.arange(len(col_range)), MSR_arr, linewidth=0.5, marker='o', markersize=2, \n",
        "                        alpha=0.5, label=\"k = {:d}\".format(k))\n",
        "                    \n",
        "        if delete_col != -1:\n",
        "            col_range[delete_col] = False\n",
        "            col_without_target = col_range.copy()\n",
        "            col_without_target[target_col] = False\n",
        "            \n",
        "            MSR_arr[delete_col] = np.nan\n",
        "            if  k != 0 and show_plot:\n",
        "                axes[0].plot(np.arange(len(col_range)), MSR_arr, linewidth=0.5, marker='o', markersize=2, \n",
        "                        alpha=0.5, label=\"k = {:d}\".format(k))\n",
        "            k += 1\n",
        "    \n",
        "        else:\n",
        "            break\n",
        "            \n",
        "        new_max_MSR = compute_MSR(bicluster[:, col_range].copy())\n",
        "        #print(f\"max_MSR  {temp}\")\n",
        "        #print(f\"new_max_MSR  {new_max_MSR}\")\n",
        "        #print(f\"np.arange(len(col_range))[col_range]\\n  {np.arange(len(col_range))[col_range]}\")\n",
        "        if sum(col_range) <= varphi or new_max_MSR >= temp:\n",
        "            break\n",
        "    \n",
        "  \n",
        "    if show_plot:\n",
        "        axes[0].grid(linewidth=0.1)\n",
        "        axes[0].set_xlabel(\"nth sample or column\")\n",
        "        axes[0].set_ylabel(\"MSR\")\n",
        "        axes[0].set_xticks(np.arange(bicluster_shape[1], dtype=int))\n",
        "        axes[0].axvline(x=target_col, linestyle='--', color='gray', linewidth=0.5)\n",
        "\n",
        "        axes[0].legend(bbox_to_anchor=(1.01, 1), loc='upper left', title='iteration')\n",
        "        #tick_top = ax.xaxis.set_tick_params(labeltop='on')\n",
        "\n",
        "        ax1_xlim_min, ax1_xlim_max = axes[0].get_xlim()\n",
        "\n",
        "\n",
        "        # plot gene expression level before column elimination\n",
        "        for i, gene in enumerate(bicluster):\n",
        "            if i == 0:\n",
        "                axes[1].plot(gene, linewidth=1.5, marker='o', color=\"red\", \n",
        "                        markersize=4, markerfacecolor='white', zorder=99)\n",
        "            else:\n",
        "                axes[1].plot(gene, linewidth=0.5, marker='o', markersize=2, \n",
        "                          alpha=0.5, color='blue')\n",
        "        axes[1].set_xticks(np.arange(bicluster_shape[1], dtype=int))\n",
        "        axes[1].axvline(x=target_col, linestyle='--', color='gray', linewidth=0.5)\n",
        "        axes[1].set_xlim(ax1_xlim_min, ax1_xlim_max)\n",
        "        axes[1].set_title(\"before column elimination\")\n",
        "        \n",
        "        ax2_ylim_min, ax2_ylim_max = axes[1].get_ylim()\n",
        "\n",
        "\n",
        "        # plot gene expression level after column elimination\n",
        "        new_col_range = np.arange(bicluster_shape[1], dtype=int)\n",
        "        new_col_range = new_col_range[col_range]\n",
        "        for i, gene in enumerate(bicluster[:, col_range]):\n",
        "            if i == 0:\n",
        "                axes[2].plot(new_col_range, gene, linewidth=1.5, marker='o', color=\"red\", \n",
        "                        markersize=4, markerfacecolor='white', zorder=99)\n",
        "            else:\n",
        "                axes[2].plot(new_col_range, gene, linewidth=0.5, marker='o', markersize=2, \n",
        "                          alpha=0.5, color='blue')\n",
        "\n",
        "        # compute alpha_mis\n",
        "        new_col_range = np.arange(bicluster_shape[1], dtype=int)\n",
        "        new_col_range = new_col_range[col_range]\n",
        "        target_col_in_C = np.argwhere(new_col_range == target_col).item()\n",
        "        alpha_mis = compute_alpha_mis(bicluster[:, col_range].copy(), target_col_in_C)\n",
        "        axes[2].plot(target_col, alpha_mis, marker='o', color=\"green\", \n",
        "                     markersize=6, markerfacecolor='white', zorder=100)\n",
        "        \n",
        "        axes[2].set_xticks(np.arange(bicluster_shape[1], dtype=int))\n",
        "        axes[2].axvline(x=target_col, linestyle='--', color='gray', linewidth=0.5)\n",
        "        axes[2].set_xlim(ax1_xlim_min, ax1_xlim_max)\n",
        "        axes[2].set_ylim(ax2_ylim_min, ax2_ylim_max)\n",
        "        axes[2].set_title(\"after column elimination\")\n",
        "            \n",
        "        plt.tight_layout()\n",
        "    \n",
        "    \n",
        "    new_col_range = np.arange(bicluster_shape[1], dtype=int)\n",
        "    new_col_range = new_col_range[col_range]\n",
        "    target_col_in_C = np.argwhere(new_col_range == target_col).item()\n",
        "    \n",
        "    return bicluster[:, col_range], target_col_in_C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5usDE_zwOy5f"
      },
      "source": [
        "## compute_alpha_mis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeyA-muTO2gJ"
      },
      "outputs": [],
      "source": [
        "def compute_alpha_mis(C_bicluster, target_col, verbose=False):\n",
        "    # compute W_jl\n",
        "    C_bicluster_shape = C_bicluster.shape\n",
        "    col_without_target_col = np.arange(C_bicluster_shape[1], dtype=int)\\\n",
        "                             [np.arange(C_bicluster_shape[1], dtype=int) != target_col]\n",
        "    C_target_col = C_bicluster[:, target_col].reshape(-1, 1)\n",
        "    C_remain = C_bicluster[:, col_without_target_col]\n",
        "  \n",
        "    euclidean_arr_1 = np.sqrt(np.sum((C_remain - C_target_col)**2, axis=0))/len(C_target_col) ##ganti jadi ssim\n",
        "    # euclidean_arr_1 = sssim(C_remain, C_target_col) #ga ganti variabel because it's so much work #adib_baru \n",
        "    #euclidean_arr_1 = np.sqrt(np.sum((C_remain - C_target_col)**2, axis=0))  # doesn't change the NRMSE\n",
        "    \n",
        "    \n",
        "    #W_jl = euclidean_arr_1/np.sum(euclidean_arr_1) if np.sum(euclidean_arr_1) > 1e-14 else np.zeros_like(euclidean_arr_1)\n",
        "    #W_jl = euclidean_arr_1/np.sum(euclidean_arr_1)\n",
        "    if np.any(euclidean_arr_1 < 1e-14):\n",
        "        idx_nan_weight = np.argwhere(euclidean_arr_1 < 1e-14)\n",
        "        W_jl = np.zeros_like(euclidean_arr_1)\n",
        "        W_jl[idx_nan_weight] = 1/len(idx_nan_weight)\n",
        "    else:\n",
        "        inv_euclid_arr_1 = 1./euclidean_arr_1  # further genes should have small contribution\n",
        "        W_jl = (inv_euclid_arr_1) /np.sum(inv_euclid_arr_1) \\\n",
        "                if np.sum(inv_euclid_arr_1) > 1e-14 else np.zeros_like(inv_euclid_arr_1)\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"C_bicluster\\n{C_bicluster}\")\n",
        "        print(f\"col_without_target_col\\n{col_without_target_col}\")\n",
        "        print(f\"C_target_col\\n{C_target_col}\")\n",
        "        print(f\"C_remain\\n{C_remain}\")\n",
        "        print(f\"euclidean_arr_1\\n{euclidean_arr_1}\")\n",
        "        print(f\"W_jl\\n{W_jl}\")\n",
        "    \n",
        "    # compute W_i1\n",
        "    C_target = C_bicluster[0]\n",
        "    C_remain = C_bicluster[1:]\n",
        "    euclidean_arr_2 = np.sqrt(np.sum((C_remain - C_target)**2, axis=1))/len(C_target) ##ganti jadi ssim\n",
        "    # euclidean_arr_2 = sssim(C_remain, C_target) #ga ganti variabel because it's so much work #adib_baru\n",
        "    #euclidean_arr_2 = np.sqrt(np.sum((C_remain - C_target)**2, axis=1))   # doesn't change the NRMSE\n",
        "    \n",
        "    \n",
        "    #W_i1 = euclidean_arr_2/np.sum(euclidean_arr_2) if np.sum(euclidean_arr_2) > 1e-14 else np.zeros_like(euclidean_arr_2)\n",
        "    #W_i1 = euclidean_arr_2/np.sum(euclidean_arr_2)\n",
        "    if np.any(euclidean_arr_2 < 1e-14):\n",
        "        idx_nan_weight = np.argwhere(euclidean_arr_2 < 1e-14)\n",
        "        W_i1 = np.zeros_like(euclidean_arr_2)\n",
        "        W_i1[idx_nan_weight] = 1/len(idx_nan_weight)\n",
        "    else:\n",
        "        inv_euclid_arr_2 = 1./euclidean_arr_2  # further genes should have small contribution\n",
        "        W_i1 = (inv_euclid_arr_2) /np.sum(inv_euclid_arr_2) \\\n",
        "                if np.sum(inv_euclid_arr_2) > 1e-14 else np.zeros_like(inv_euclid_arr_2)\n",
        "    \n",
        "    \n",
        "    # compute alpha\n",
        "    # Dutta 2018\n",
        "    R_avg = C_target[col_without_target_col] * W_jl\n",
        "    C_avg = C_target_col[1:].flatten() * W_i1\n",
        "    \n",
        "    # Bose 2015\n",
        "    # This doesn't make sense to multiply by euclidean distance\n",
        "    #R_avg = euclidean_arr_1 * W_jl\n",
        "    #C_avg = euclidean_arr_2 * W_i1\n",
        "\n",
        "    R_avg = np.sum(R_avg)\n",
        "    C_avg = np.sum(C_avg)\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"C_target\\n{C_target}\")\n",
        "        print(f\"C_remain\\n{C_remain}\")\n",
        "        print(f\"euclidean_arr_2\\n{euclidean_arr_2}\")\n",
        "        print(f\"W_i1\\n{W_i1}\")\n",
        "        \n",
        "        print(f\"C_target[col_without_target_col]\\n{C_target[col_without_target_col]}\")\n",
        "        print(f\"C_target_col[1:].flatten()\\n{C_target_col[1:].flatten()}\")\n",
        "        print(f\"R_avg  {R_avg}\")\n",
        "        print(f\"C_avg  {C_avg}\")\n",
        "    \n",
        "    return (R_avg + C_avg)/2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5yGAEERO7PA"
      },
      "source": [
        "## SBi_MSREimpute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wunroOiYO-RX"
      },
      "outputs": [],
      "source": [
        "def SBi_MSRE(y_cluster_val, y_cluster_val_mis, k_max=4, verbose=False):\n",
        "    \"\"\"Sequential biclustering with mean square residue error. (Dutta, et.al., 2019)\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    k_max : int, default=4\n",
        "        Number of closest gene expression with metric provided by `get_setZ`\n",
        "    \n",
        "    Algorithm\n",
        "    ---------\n",
        "    (1) Replace all the missing values by row averages\n",
        "    \n",
        "    \n",
        "    (2) Sort all m number of genes in ascending order according to \n",
        "        their missing rate. I guessed this is to speed up the computation\n",
        "        by doing the small number of missing rate first\n",
        "        \n",
        "        \n",
        "    (3) For each missing position t in every target x_s do\n",
        "    \n",
        "        (a) consider the target gene x_s, as the initial bicluster B\n",
        "        \n",
        "        (b) add set Z (formed according to Eq. (7)) containing u number of nearest\n",
        "            neighbour genes of x_s in the bicluster B as shown in Eq. (8).\n",
        "            \n",
        "        (c) repeat from step (i) to step (iv) until the no. of columns in the bicluster B <= varphi\n",
        "            or no decrease in the MSR score of the bicluster B due to deletion of any column\n",
        "              (i) Calculate MSR score H(B) of the bicluster B and store it in `Temp`.\n",
        "             (ii) Max := Temp\n",
        "            (iii) For every column (p) in the bicluster B except for the target column do:\n",
        "                  (A) Calculate MSR score H(B) of the bicluster B but ignoring column p and store it in `Temp1`\n",
        "                  (B) If (`Temp1` < Max) then\n",
        "                          Max := Temp1\n",
        "                          Pos := p\n",
        "             (iv) Delete Pos column from the bicluster B and reduce no. of column of B by 1\n",
        "        \n",
        "        (d) rename the modified bicluster B as C\n",
        "        \n",
        "        (e) replace missing value alpha by (R_avg + C_avg)/2 where R_avg is the weighted\n",
        "            average of target gene (here first row) as shown in Eq. (10) and C_avg is the\n",
        "            weighted average of the target column (here l) as shown in Eq. (11)\n",
        "            \n",
        "        (f) place calculated value for alpha at x_{st} position in the input gene expression\n",
        "            matrix D and set the corresponding position of the indicator matrix F to 1.\n",
        "    \"\"\"\n",
        "    missing_idx = np.argwhere(np.isnan(y_cluster_val_mis))\n",
        "\n",
        "    F_mat = np.ones_like(y_cluster_val_mis, dtype=int)\n",
        "    F_mat_shape = F_mat.shape\n",
        "    F_mat[missing_idx[:,0], missing_idx[:, 1]] = 0\n",
        "    \n",
        "    A = y_cluster_val_mis.copy()\n",
        "    \n",
        "    # using row average to put initial values in missing values\n",
        "    for p, q in missing_idx:\n",
        "        idx_cols_without_nan = np.argwhere(np.isnan(y_cluster_val_mis[p]) == False).flatten()\n",
        "        A[p, q] = np.sum(y_cluster_val_mis[p, idx_cols_without_nan])/len(y_cluster_val_mis[p])\n",
        "        \n",
        "        # doesn't change NRMSE and doesn't give correct alpha_mis for matrix one\n",
        "        #A[p, q] = np.sum(y_cluster_val_mis[p, idx_cols_without_nan])/len(idx_cols_without_nan)  \n",
        "        \n",
        "        if verbose:\n",
        "            print(f\"  p, q = {p}, {q}\")\n",
        "            print(f\"  A[p, :]\\n{A[p, :]}\")\n",
        "    \n",
        "    row_mis_rate = (F_mat == 0).sum(axis=1)\n",
        "    idx_sorted_row_mis_rate = np.argsort(row_mis_rate, kind=\"stable\")\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"missing_idx\\n{missing_idx}\")\n",
        "\n",
        "        print(f\"A[missing_idx[:, 0], missing_idx[:, 1]]\\n\"\n",
        "              +f\"{A[missing_idx[:, 0], missing_idx[:, 1]]}\")\n",
        "        print(f\"row_mis_rate\\n{row_mis_rate}\")\n",
        "        print(f\"F_mat\\n{F_mat}\")\n",
        "        print(f\"F_mat_shape\\n{F_mat_shape}\")\n",
        "        print(f\"row_mis_rate[idx_sorted_row_mis_rate]\\n{row_mis_rate[idx_sorted_row_mis_rate]}\")\n",
        "    \n",
        "    F_mat = F_mat[idx_sorted_row_mis_rate, :]\n",
        "    A = A[idx_sorted_row_mis_rate, :]\n",
        "    \n",
        "    y_cluster_val_sorted = y_cluster_val[idx_sorted_row_mis_rate, :].copy()\n",
        "    F_mat_sorted = F_mat.copy()\n",
        "    A_sorted = A.copy()\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"F_mat (after sorted)\\n{F_mat}\")\n",
        "    \n",
        "    nth_start_imputation_init = np.arange(F_mat_shape[0], dtype=int)\\\n",
        "                                        [row_mis_rate[idx_sorted_row_mis_rate] > 0][0]\n",
        "    print(f\"  nth_start_imputation_init  {nth_start_imputation_init}\")\n",
        "    for i, nth_start_imputation in enumerate(range(nth_start_imputation_init, F_mat_shape[0])):\n",
        "        \n",
        "        # process indicator\n",
        "        if not verbose:\n",
        "            sys.stdout.write(\"\\r  {:3.0f}%\".format(i*100/(F_mat_shape[0] - (nth_start_imputation_init + 1))))\n",
        "        \n",
        "        # swap x_s to the first row (you have to use .copy()!!!)\n",
        "        dummy_index = np.arange(F_mat_shape[0], dtype=int)\n",
        "        dummy_index[0], dummy_index[nth_start_imputation] \\\n",
        "            = dummy_index[nth_start_imputation].copy(), dummy_index[0].copy()\n",
        "        F_mat_target_gene = F_mat[nth_start_imputation].copy()\n",
        "        bicluster = get_setZ(A[dummy_index], k_max=k_max)  \n",
        "        \n",
        "        varphi = len(bicluster[0])/2     # from the paper\n",
        "        target_cols = np.argwhere(F_mat_target_gene == 0).flatten()\n",
        "        \n",
        "        if verbose:\n",
        "            print(f\"  nth_start_imputation  {nth_start_imputation}\")\n",
        "            print(f\"  dummy_index\\n{dummy_index}\")\n",
        "            print(f\"  F_mat_target_gene\\n{F_mat_target_gene}\")\n",
        "            print(f\"  bicluster\\n{bicluster}\")\n",
        "            print(f\"  target_cols\\n{target_cols}\")\n",
        "            print(\"  --- before imputation\")\n",
        "            print(f\"  A[nth_start_imputation]\\n{A[nth_start_imputation]}\")\n",
        "            print(f\"  F_mat[nth_start_imputation]\\n{F_mat[nth_start_imputation]}\")\n",
        "        \n",
        "        for target_col in target_cols:\n",
        "            C_bicluster, target_col_in_C = column_elimination(bicluster.copy(), target_col)\n",
        "                  \n",
        "            alpha_mis = compute_alpha_mis(C_bicluster, target_col_in_C)\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"    target_col  {target_col}\")\n",
        "                print(f\"    C_bicluster\\n{C_bicluster}\")\n",
        "                print(f\"    C_bicluster.shape\\n{C_bicluster.shape}\")\n",
        "                print(f\"    target_col_in_C {target_col_in_C}\")\n",
        "                print(f\"    alpha_mis {alpha_mis}\")\n",
        "\n",
        "            A[nth_start_imputation, target_col] = alpha_mis\n",
        "            F_mat[nth_start_imputation, target_col] = 1\n",
        "\n",
        "        if verbose:\n",
        "            print(\"  -- after imputation\")\n",
        "            print(f\"  A[nth_start_imputation]\\n{A[nth_start_imputation]}\")\n",
        "            print(f\"  F_mat[nth_start_imputation]\\n{F_mat[nth_start_imputation]}\")\n",
        "        \n",
        "        if not verbose:\n",
        "            sys.stdout.flush()\n",
        "    \n",
        "    return y_cluster_val_sorted, A, F_mat_sorted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gvHbuvUC3LL"
      },
      "outputs": [],
      "source": [
        "# SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLm_EqWhPRiF"
      },
      "source": [
        "# Performance Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Asw9bobNPU2c"
      },
      "source": [
        "## compute_NRMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNbKf6FMPTxO"
      },
      "outputs": [],
      "source": [
        "def compute_NRMSE(D_gene_actual_sorted, D_gene_estimate, F_mat_sorted, verbose=False):\n",
        "    idx_missing = np.argwhere(F_mat_sorted == 0)\n",
        "    \n",
        "    N = len(idx_missing)\n",
        "    y_estimate = D_gene_estimate[idx_missing[:,0], idx_missing[:,1]]\n",
        "    \n",
        "    y_true = D_gene_actual_sorted[idx_missing[:,0], idx_missing[:,1]]  \n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"F_mat_sorted\\n{F_mat_sorted}\")\n",
        "        print(f\"idx_missing\\n{idx_missing}\")\n",
        "        print(f\"N {N}\")\n",
        "        print(f\"y_estimate\\n{y_estimate}\")\n",
        "        print(f\"y_true\\n{y_true}\")\n",
        "    \n",
        "    \n",
        "    return (1./np.std(y_true)) * np.sqrt(np.sum((y_true - y_estimate)**2)/N)\n",
        "    #return np.sqrt(np.sum((y_true - y_estimate)**2)/N)\n",
        "\n",
        "    # Using nrmse from user\n",
        "    #return np.sqrt(np.sum((y_true - y_estimate)**2)/N) / (np.max(y_true)-np.min(y_true))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcTWuDYEPswb"
      },
      "source": [
        "## compute_pearsoncorr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhzWeqizPyZT"
      },
      "outputs": [],
      "source": [
        "def compute_pearsoncorr(D_gene_actual_sorted, D_gene_estimate, F_mat_sorted, verbose=False):\n",
        "    idx_missing = np.argwhere(F_mat_sorted == 0)\n",
        "    \n",
        "    N = len(idx_missing)\n",
        "    y_estimate = D_gene_estimate[idx_missing[:,0], idx_missing[:,1]]\n",
        "    \n",
        "    y_true = D_gene_actual_sorted[idx_missing[:,0], idx_missing[:,1]]  \n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"F_mat_sorted\\n{F_mat_sorted}\")\n",
        "        print(f\"idx_missing\\n{idx_missing}\")\n",
        "        print(f\"N {N}\")\n",
        "        print(f\"y_estimate\\n{y_estimate}\")\n",
        "        print(f\"y_true\\n{y_true}\")\n",
        "\n",
        "    #return np.sum(y_true-y_true.mean())*(y_estimate-y_estimate.mean()) / ((np.sqrt(np.sum(np.power((y_true-y_true.mean),2)))) * (np.sqrt(np.sum(np.power((y_estimate-y_estimate.mean),2)))))\n",
        "    #return np.sqrt(np.sum(y_true-y_true.mean())*(y_estimate-y_estimate.mean()))  \n",
        "    return np.sum(np.multiply((y_true - y_true.mean()),(y_estimate - y_estimate.mean()))) / (np.sqrt(np.sum((y_true-y_true.mean())**2)) * np.sqrt(np.sum((y_estimate-y_estimate.mean())**2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nT8b0W3LP7Rf"
      },
      "source": [
        "## Hasil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T53wf9TgC3LM"
      },
      "source": [
        "### Untuk k = 5%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaLYFHlSC3LM"
      },
      "source": [
        "#### k = 5% (Percobaan 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3ZVmYStC3LM",
        "outputId": "ff19084d-2d2b-428f-a43f-9ec3f67d093e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.88%\n",
            "  nth_start_imputation_init  586\n",
            "  100%\n",
            "  NRMSE_arr   0.5795426829115352\n",
            "  comp.time   52.55 s\n",
            "  Pearson_arr   0.8414752213897891\n",
            "  comp.time   52.55 s\n",
            "p missing rate: 6.11%\n",
            "  nth_start_imputation_init  409\n",
            "  100%\n",
            "  NRMSE_arr   0.6047337439684181\n",
            "  comp.time   90.53 s\n",
            "  Pearson_arr   0.9583512024444023\n",
            "  comp.time   90.54 s\n",
            "p missing rate: 8.81%\n",
            "  nth_start_imputation_init  294\n",
            "  100%\n",
            "  NRMSE_arr   0.5198631871916037\n",
            "  comp.time   121.06 s\n",
            "  Pearson_arr   0.9209295247537066\n",
            "  comp.time   121.06 s\n",
            "p missing rate: 12.09%\n",
            "  nth_start_imputation_init  215\n",
            "  100%\n",
            "  NRMSE_arr   0.637086244372689\n",
            "  comp.time   139.86 s\n",
            "  Pearson_arr   0.9610621782444323\n",
            "  comp.time   139.86 s\n",
            "p missing rate: 14.83%\n",
            "  nth_start_imputation_init  144\n",
            "  100%\n",
            "  NRMSE_arr   0.728571656902378\n",
            "  comp.time   159.75 s\n",
            "  Pearson_arr   0.843256051000744\n",
            "  comp.time   159.76 s\n",
            "p missing rate: 17.08%\n",
            "  nth_start_imputation_init  99\n",
            "  100%\n",
            "  NRMSE_arr   0.6991454793476615\n",
            "  comp.time   170.01 s\n",
            "  Pearson_arr   0.8937000909220381\n",
            "  comp.time   170.01 s\n",
            "p missing rate: 24.53%\n",
            "  nth_start_imputation_init  40\n",
            "  100%\n",
            "  NRMSE_arr   0.7292650231304759\n",
            "  comp.time   193.71 s\n",
            "  Pearson_arr   0.9233144763036999\n",
            "  comp.time   193.72 s\n",
            "p missing rate: 29.71%\n",
            "  nth_start_imputation_init  17\n",
            "  100%\n",
            "  NRMSE_arr   0.7894061193169031\n",
            "  comp.time   206.03 s\n",
            "  Pearson_arr   0.9207838359961509\n",
            "  comp.time   206.03 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.05*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx6Zgu1aMlyQ"
      },
      "source": [
        "#### k = 5% (Percobaan 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEjRI75XMlyQ",
        "outputId": "2b52cfa1-3e29-495e-9893-b32405d8ceff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.79%\n",
            "  nth_start_imputation_init  594\n",
            "  100%\n",
            "  NRMSE_arr   0.6238185660265827\n",
            "  comp.time   50.31 s\n",
            "  Pearson_arr   0.9145909501339694\n",
            "  comp.time   50.31 s\n",
            "p missing rate: 6.59%\n",
            "  nth_start_imputation_init  392\n",
            "  100%\n",
            "  NRMSE_arr   0.5595051952693265\n",
            "  comp.time   94.43 s\n",
            "  Pearson_arr   0.9775942671505145\n",
            "  comp.time   94.43 s\n",
            "p missing rate: 8.66%\n",
            "  nth_start_imputation_init  303\n",
            "  100%\n",
            "  NRMSE_arr   0.5538670600202991\n",
            "  comp.time   116.51 s\n",
            "  Pearson_arr   0.962991414608002\n",
            "  comp.time   116.51 s\n",
            "p missing rate: 12.37%\n",
            "  nth_start_imputation_init  174\n",
            "  100%\n",
            "  NRMSE_arr   0.749166133861194\n",
            "  comp.time   150.37 s\n",
            "  Pearson_arr   0.8595548421642929\n",
            "  comp.time   150.38 s\n",
            "p missing rate: 15.04%\n",
            "  nth_start_imputation_init  129\n",
            "  100%\n",
            "  NRMSE_arr   0.6649888174106534\n",
            "  comp.time   162.58 s\n",
            "  Pearson_arr   0.9145077805970294\n",
            "  comp.time   162.58 s\n",
            "p missing rate: 18.57%\n",
            "  nth_start_imputation_init  88\n",
            "  100%\n",
            "  NRMSE_arr   0.7683909078613397\n",
            "  comp.time   175.29 s\n",
            "  Pearson_arr   0.9367747619791305\n",
            "  comp.time   175.29 s\n",
            "p missing rate: 23.43%\n",
            "  nth_start_imputation_init  42\n",
            "  100%\n",
            "  NRMSE_arr   0.8277481657141512\n",
            "  comp.time   198.97 s\n",
            "  Pearson_arr   0.890883594693203\n",
            "  comp.time   198.97 s\n",
            "p missing rate: 29.76%\n",
            "  nth_start_imputation_init  10\n",
            "  100%\n",
            "  NRMSE_arr   0.7896857602025364\n",
            "  comp.time   208.99 s\n",
            "  Pearson_arr   0.9202044382668719\n",
            "  comp.time   208.99 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.05*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l2RJMfTMm7x"
      },
      "source": [
        "#### k = 5% (Percobaan 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJdxF8OSMm7y",
        "outputId": "106abcb2-1a06-4117-e6f2-acfb09fca4b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 3.06%\n",
            "  nth_start_imputation_init  567\n",
            "  100%\n",
            "  NRMSE_arr   0.567941781229729\n",
            "  comp.time   50.68 s\n",
            "  Pearson_arr   0.8972813913155095\n",
            "  comp.time   50.68 s\n",
            "p missing rate: 5.96%\n",
            "  nth_start_imputation_init  413\n",
            "  100%\n",
            "  NRMSE_arr   0.4856139751419793\n",
            "  comp.time   86.98 s\n",
            "  Pearson_arr   0.9719577182966739\n",
            "  comp.time   86.98 s\n",
            "p missing rate: 8.55%\n",
            "  nth_start_imputation_init  311\n",
            "  100%\n",
            "  NRMSE_arr   0.6618286512214887\n",
            "  comp.time   112.83 s\n",
            "  Pearson_arr   0.8472688367486501\n",
            "  comp.time   112.83 s\n",
            "p missing rate: 11.82%\n",
            "  nth_start_imputation_init  216\n",
            "  100%\n",
            "  NRMSE_arr   0.6849166809203848\n",
            "  comp.time   135.35 s\n",
            "  Pearson_arr   0.9287416516106798\n",
            "  comp.time   135.35 s\n",
            "p missing rate: 15.01%\n",
            "  nth_start_imputation_init  143\n",
            "  100%\n",
            "  NRMSE_arr   0.6185793702853665\n",
            "  comp.time   156.56 s\n",
            "  Pearson_arr   0.918188740869031\n",
            "  comp.time   156.56 s\n",
            "p missing rate: 18.04%\n",
            "  nth_start_imputation_init  102\n",
            "  100%\n",
            "  NRMSE_arr   0.7226069962401135\n",
            "  comp.time   168.78 s\n",
            "  Pearson_arr   0.8952471985424022\n",
            "  comp.time   168.78 s\n",
            "p missing rate: 24.40%\n",
            "  nth_start_imputation_init  35\n",
            "  100%\n",
            "  NRMSE_arr   0.7988803009259792\n",
            "  comp.time   192.93 s\n",
            "  Pearson_arr   0.926269035792374\n",
            "  comp.time   192.93 s\n",
            "p missing rate: 30.24%\n",
            "  nth_start_imputation_init  15\n",
            "  100%\n",
            "  NRMSE_arr   0.7712300214580224\n",
            "  comp.time   202.90 s\n",
            "  Pearson_arr   0.907634994243079\n",
            "  comp.time   202.90 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.05*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y5B2jxXMnzO"
      },
      "source": [
        "#### k = 5% (Percobaan 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1h8Il9X6MnzP",
        "outputId": "fbcc289b-1f83-462e-e42c-4c936c9e392e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.78%\n",
            "  nth_start_imputation_init  589\n",
            "  100%\n",
            "  NRMSE_arr   0.5495718047712128\n",
            "  comp.time   56.63 s\n",
            "  Pearson_arr   0.9538245841382628\n",
            "  comp.time   56.63 s\n",
            "p missing rate: 6.30%\n",
            "  nth_start_imputation_init  407\n",
            "  100%\n",
            "  NRMSE_arr   0.6080157985986963\n",
            "  comp.time   95.09 s\n",
            "  Pearson_arr   0.8788832072647516\n",
            "  comp.time   95.10 s\n",
            "p missing rate: 8.76%\n",
            "  nth_start_imputation_init  313\n",
            "  100%\n",
            "  NRMSE_arr   0.6648589324374816\n",
            "  comp.time   116.31 s\n",
            "  Pearson_arr   0.8757093013477729\n",
            "  comp.time   116.31 s\n",
            "p missing rate: 11.91%\n",
            "  nth_start_imputation_init  208\n",
            "  100%\n",
            "  NRMSE_arr   0.5929629533508265\n",
            "  comp.time   144.83 s\n",
            "  Pearson_arr   0.9569660762879395\n",
            "  comp.time   144.83 s\n",
            "p missing rate: 14.50%\n",
            "  nth_start_imputation_init  157\n",
            "  100%\n",
            "  NRMSE_arr   0.6923759457020936\n",
            "  comp.time   158.91 s\n",
            "  Pearson_arr   0.9058196296547022\n",
            "  comp.time   158.91 s\n",
            "p missing rate: 18.11%\n",
            "  nth_start_imputation_init  80\n",
            "  100%\n",
            "  NRMSE_arr   0.7900916778882509\n",
            "  comp.time   181.15 s\n",
            "  Pearson_arr   0.9105540737971418\n",
            "  comp.time   181.15 s\n",
            "p missing rate: 23.29%\n",
            "  nth_start_imputation_init  49\n",
            "  100%\n",
            "  NRMSE_arr   0.7057935101681664\n",
            "  comp.time   196.23 s\n",
            "  Pearson_arr   0.9066680288345255\n",
            "  comp.time   196.24 s\n",
            "p missing rate: 29.82%\n",
            "  nth_start_imputation_init  19\n",
            "  100%\n",
            "  NRMSE_arr   0.7658828677736971\n",
            "  comp.time   212.22 s\n",
            "  Pearson_arr   0.9004989804570421\n",
            "  comp.time   212.22 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.05*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYfU_-p5Mobo"
      },
      "source": [
        "#### k = 5% (Percobaan 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp1_A7vZMobp",
        "outputId": "8333d95d-dd0a-4b3f-e941-64724b045a7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 3.02%\n",
            "  nth_start_imputation_init  574\n",
            "  100%\n",
            "  NRMSE_arr   0.5431725064649032\n",
            "  comp.time   59.17 s\n",
            "  Pearson_arr   0.9760266246013843\n",
            "  comp.time   59.17 s\n",
            "p missing rate: 5.88%\n",
            "  nth_start_imputation_init  416\n",
            "  100%\n",
            "  NRMSE_arr   0.584425115722519\n",
            "  comp.time   104.82 s\n",
            "  Pearson_arr   0.9428283079680642\n",
            "  comp.time   104.82 s\n",
            "p missing rate: 8.58%\n",
            "  nth_start_imputation_init  303\n",
            "  100%\n",
            "  NRMSE_arr   0.6145807944770794\n",
            "  comp.time   123.88 s\n",
            "  Pearson_arr   0.9697120260724434\n",
            "  comp.time   123.88 s\n",
            "p missing rate: 11.52%\n",
            "  nth_start_imputation_init  212\n",
            "  100%\n",
            "  NRMSE_arr   0.6596870131174765\n",
            "  comp.time   150.37 s\n",
            "  Pearson_arr   0.9228882885703313\n",
            "  comp.time   150.37 s\n",
            "p missing rate: 15.26%\n",
            "  nth_start_imputation_init  135\n",
            "  100%\n",
            "  NRMSE_arr   0.6642483511327898\n",
            "  comp.time   171.31 s\n",
            "  Pearson_arr   0.8995296469681665\n",
            "  comp.time   171.31 s\n",
            "p missing rate: 18.16%\n",
            "  nth_start_imputation_init  94\n",
            "  100%\n",
            "  NRMSE_arr   0.7414122860779137\n",
            "  comp.time   181.87 s\n",
            "  Pearson_arr   0.9367875036874594\n",
            "  comp.time   181.87 s\n",
            "p missing rate: 23.99%\n",
            "  nth_start_imputation_init  35\n",
            "  100%\n",
            "  NRMSE_arr   0.7920992755482608\n",
            "  comp.time   205.94 s\n",
            "  Pearson_arr   0.9116368750764461\n",
            "  comp.time   205.94 s\n",
            "p missing rate: 30.36%\n",
            "  nth_start_imputation_init  10\n",
            "  100%\n",
            "  NRMSE_arr   0.9099368295921113\n",
            "  comp.time   224.30 s\n",
            "  Pearson_arr   0.7218651465615396\n",
            "  comp.time   224.30 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.05*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myulvpPDC3LP"
      },
      "source": [
        "### Untuk k = 10%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW_Xl6eyC3LP"
      },
      "source": [
        "#### k = 10% (Percobaan 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4PqefF4C3LP",
        "outputId": "8f25cb33-60ff-4e7d-db64-29ce38d1b034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.88%\n",
            "  nth_start_imputation_init  586\n",
            "  100%\n",
            "  NRMSE_arr   0.5953215560767893\n",
            "  comp.time   47.85 s\n",
            "  Pearson_arr   0.8238273303926589\n",
            "  comp.time   47.86 s\n",
            "p missing rate: 6.11%\n",
            "  nth_start_imputation_init  409\n",
            "  100%\n",
            "  NRMSE_arr   0.6082569978883788\n",
            "  comp.time   89.28 s\n",
            "  Pearson_arr   0.9584175424143094\n",
            "  comp.time   89.28 s\n",
            "p missing rate: 8.81%\n",
            "  nth_start_imputation_init  294\n",
            "  100%\n",
            "  NRMSE_arr   0.5253102982056784\n",
            "  comp.time   118.39 s\n",
            "  Pearson_arr   0.9222717666645684\n",
            "  comp.time   118.39 s\n",
            "p missing rate: 12.09%\n",
            "  nth_start_imputation_init  215\n",
            "  100%\n",
            "  NRMSE_arr   0.6160399827715004\n",
            "  comp.time   140.07 s\n",
            "  Pearson_arr   0.9471170333619524\n",
            "  comp.time   140.07 s\n",
            "p missing rate: 14.83%\n",
            "  nth_start_imputation_init  144\n",
            "  100%\n",
            "  NRMSE_arr   0.6975282954796668\n",
            "  comp.time   157.92 s\n",
            "  Pearson_arr   0.8573192960883165\n",
            "  comp.time   157.93 s\n",
            "p missing rate: 17.08%\n",
            "  nth_start_imputation_init  99\n",
            "  100%\n",
            "  NRMSE_arr   0.6798136760605329\n",
            "  comp.time   169.12 s\n",
            "  Pearson_arr   0.9082413230726074\n",
            "  comp.time   169.12 s\n",
            "p missing rate: 24.53%\n",
            "  nth_start_imputation_init  40\n",
            "  100%\n",
            "  NRMSE_arr   0.729849599942963\n",
            "  comp.time   193.29 s\n",
            "  Pearson_arr   0.9238576535634835\n",
            "  comp.time   193.29 s\n",
            "p missing rate: 29.71%\n",
            "  nth_start_imputation_init  17\n",
            "  100%\n",
            "  NRMSE_arr   0.7752202604077073\n",
            "  comp.time   204.77 s\n",
            "  Pearson_arr   0.9201259582943835\n",
            "  comp.time   204.77 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.1*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKLYVCkfLkcH"
      },
      "source": [
        "#### k = 10% (Percobaan 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TaKhfrgLkcI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d47838e-66e6-4e22-e867-2dfb54f6ee2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.79%\n",
            "  nth_start_imputation_init  594\n",
            "  100%\n",
            "  NRMSE_arr   0.6233539157609664\n",
            "  comp.time   46.74 s\n",
            "  Pearson_arr   0.9204869746377531\n",
            "  comp.time   46.74 s\n",
            "p missing rate: 6.59%\n",
            "  nth_start_imputation_init  392\n",
            "  100%\n",
            "  NRMSE_arr   0.5489162406652143\n",
            "  comp.time   94.79 s\n",
            "  Pearson_arr   0.9803058400941356\n",
            "  comp.time   94.79 s\n",
            "p missing rate: 8.66%\n",
            "  nth_start_imputation_init  303\n",
            "  100%\n",
            "  NRMSE_arr   0.5542133480572996\n",
            "  comp.time   116.25 s\n",
            "  Pearson_arr   0.964919082933679\n",
            "  comp.time   116.25 s\n",
            "p missing rate: 12.37%\n",
            "  nth_start_imputation_init  174\n",
            "  100%\n",
            "  NRMSE_arr   0.7516627456749663\n",
            "  comp.time   150.27 s\n",
            "  Pearson_arr   0.8757043168139057\n",
            "  comp.time   150.28 s\n",
            "p missing rate: 15.04%\n",
            "  nth_start_imputation_init  129\n",
            "  100%\n",
            "  NRMSE_arr   0.6373002497923715\n",
            "  comp.time   162.34 s\n",
            "  Pearson_arr   0.9104383486848007\n",
            "  comp.time   162.34 s\n",
            "p missing rate: 18.57%\n",
            "  nth_start_imputation_init  88\n",
            "  100%\n",
            "  NRMSE_arr   0.7619475655842495\n",
            "  comp.time   173.90 s\n",
            "  Pearson_arr   0.9289103134570545\n",
            "  comp.time   173.90 s\n",
            "p missing rate: 23.43%\n",
            "  nth_start_imputation_init  42\n",
            "  100%\n",
            "  NRMSE_arr   0.8210663442325751\n",
            "  comp.time   196.06 s\n",
            "  Pearson_arr   0.898582765124461\n",
            "  comp.time   196.06 s\n",
            "p missing rate: 29.76%\n",
            "  nth_start_imputation_init  10\n",
            "  100%\n",
            "  NRMSE_arr   0.7472628698149693\n",
            "  comp.time   207.39 s\n",
            "  Pearson_arr   0.9168404357980657\n",
            "  comp.time   207.39 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.1*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyOdOXsiMBWJ"
      },
      "source": [
        "#### k = 10% (Percobaan 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvlecSIKMBWK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7dc487e-f3b4-4ccc-9573-e4c338252c40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 3.06%\n",
            "  nth_start_imputation_init  567\n",
            "  100%\n",
            "  NRMSE_arr   0.5640043359956097\n",
            "  comp.time   50.77 s\n",
            "  Pearson_arr   0.9253179236125499\n",
            "  comp.time   50.78 s\n",
            "p missing rate: 5.96%\n",
            "  nth_start_imputation_init  413\n",
            "  100%\n",
            "  NRMSE_arr   0.48111133630505915\n",
            "  comp.time   86.74 s\n",
            "  Pearson_arr   0.975687397358122\n",
            "  comp.time   86.74 s\n",
            "p missing rate: 8.55%\n",
            "  nth_start_imputation_init  311\n",
            "  100%\n",
            "  NRMSE_arr   0.638516754668874\n",
            "  comp.time   113.35 s\n",
            "  Pearson_arr   0.8980355121956363\n",
            "  comp.time   113.35 s\n",
            "p missing rate: 11.82%\n",
            "  nth_start_imputation_init  216\n",
            "  100%\n",
            "  NRMSE_arr   0.6806969029711741\n",
            "  comp.time   135.25 s\n",
            "  Pearson_arr   0.922376114083542\n",
            "  comp.time   135.25 s\n",
            "p missing rate: 15.01%\n",
            "  nth_start_imputation_init  143\n",
            "  100%\n",
            "  NRMSE_arr   0.5792864545038877\n",
            "  comp.time   156.91 s\n",
            "  Pearson_arr   0.9347654538669695\n",
            "  comp.time   156.91 s\n",
            "p missing rate: 18.04%\n",
            "  nth_start_imputation_init  102\n",
            "  100%\n",
            "  NRMSE_arr   0.7189387997138631\n",
            "  comp.time   168.65 s\n",
            "  Pearson_arr   0.8940691383225758\n",
            "  comp.time   168.65 s\n",
            "p missing rate: 24.40%\n",
            "  nth_start_imputation_init  35\n",
            "  100%\n",
            "  NRMSE_arr   0.7923736460536417\n",
            "  comp.time   192.03 s\n",
            "  Pearson_arr   0.9298644824724559\n",
            "  comp.time   192.04 s\n",
            "p missing rate: 30.24%\n",
            "  nth_start_imputation_init  15\n",
            "  100%\n",
            "  NRMSE_arr   0.7751317323114476\n",
            "  comp.time   202.48 s\n",
            "  Pearson_arr   0.917702448998124\n",
            "  comp.time   202.48 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.1*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XerNtUoUMJX8"
      },
      "source": [
        "#### k = 10% (Percobaan 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfWziZtbMJX8",
        "outputId": "b570ff18-ade9-4f26-d6bd-bb2116a922f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.78%\n",
            "  nth_start_imputation_init  589\n",
            "  100%\n",
            "  NRMSE_arr   0.6101100696332625\n",
            "  comp.time   47.08 s\n",
            "  Pearson_arr   0.9424077434213756\n",
            "  comp.time   47.08 s\n",
            "p missing rate: 6.30%\n",
            "  nth_start_imputation_init  407\n",
            "  100%\n",
            "  NRMSE_arr   0.6413802343555889\n",
            "  comp.time   91.78 s\n",
            "  Pearson_arr   0.8722410423225108\n",
            "  comp.time   91.78 s\n",
            "p missing rate: 8.76%\n",
            "  nth_start_imputation_init  313\n",
            "  100%\n",
            "  NRMSE_arr   0.6660725073541016\n",
            "  comp.time   115.40 s\n",
            "  Pearson_arr   0.865653397949777\n",
            "  comp.time   115.40 s\n",
            "p missing rate: 11.91%\n",
            "  nth_start_imputation_init  208\n",
            "  100%\n",
            "  NRMSE_arr   0.5824356646931664\n",
            "  comp.time   143.82 s\n",
            "  Pearson_arr   0.9489495547438185\n",
            "  comp.time   143.82 s\n",
            "p missing rate: 14.50%\n",
            "  nth_start_imputation_init  157\n",
            "  100%\n",
            "  NRMSE_arr   0.6674180939364419\n",
            "  comp.time   158.59 s\n",
            "  Pearson_arr   0.9176221786283476\n",
            "  comp.time   158.60 s\n",
            "p missing rate: 18.11%\n",
            "  nth_start_imputation_init  80\n",
            "  100%\n",
            "  NRMSE_arr   0.7933872389315134\n",
            "  comp.time   181.20 s\n",
            "  Pearson_arr   0.8883598897776633\n",
            "  comp.time   181.21 s\n",
            "p missing rate: 23.29%\n",
            "  nth_start_imputation_init  49\n",
            "  100%\n",
            "  NRMSE_arr   0.6996545930897737\n",
            "  comp.time   194.70 s\n",
            "  Pearson_arr   0.8771114774352395\n",
            "  comp.time   194.71 s\n",
            "p missing rate: 29.82%\n",
            "  nth_start_imputation_init  19\n",
            "  100%\n",
            "  NRMSE_arr   0.8166471048676714\n",
            "  comp.time   211.06 s\n",
            "  Pearson_arr   0.9208403535455365\n",
            "  comp.time   211.06 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.1*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIbQqmzmMKj_"
      },
      "source": [
        "#### k = 10% (Percobaan 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9nKRM2YMKj_",
        "outputId": "d4b0dbbc-0ba9-489a-c3da-a5be5aece84d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 3.02%\n",
            "  nth_start_imputation_init  574\n",
            "  100%\n",
            "  NRMSE_arr   0.5686027961294619\n",
            "  comp.time   52.56 s\n",
            "  Pearson_arr   0.9724393179036636\n",
            "  comp.time   52.57 s\n",
            "p missing rate: 5.88%\n",
            "  nth_start_imputation_init  416\n",
            "  100%\n",
            "  NRMSE_arr   0.6012467589218174\n",
            "  comp.time   93.93 s\n",
            "  Pearson_arr   0.9463020851678952\n",
            "  comp.time   93.94 s\n",
            "p missing rate: 8.58%\n",
            "  nth_start_imputation_init  303\n",
            "  100%\n",
            "  NRMSE_arr   0.6253245114397733\n",
            "  comp.time   121.62 s\n",
            "  Pearson_arr   0.9676946254378619\n",
            "  comp.time   121.63 s\n",
            "p missing rate: 11.52%\n",
            "  nth_start_imputation_init  212\n",
            "  100%\n",
            "  NRMSE_arr   0.6270650209700747\n",
            "  comp.time   147.42 s\n",
            "  Pearson_arr   0.9324130300925574\n",
            "  comp.time   147.43 s\n",
            "p missing rate: 15.26%\n",
            "  nth_start_imputation_init  135\n",
            "  100%\n",
            "  NRMSE_arr   0.6528875726604285\n",
            "  comp.time   169.61 s\n",
            "  Pearson_arr   0.8969729363542249\n",
            "  comp.time   169.61 s\n",
            "p missing rate: 18.16%\n",
            "  nth_start_imputation_init  94\n",
            "  100%\n",
            "  NRMSE_arr   0.7191360333869964\n",
            "  comp.time   182.54 s\n",
            "  Pearson_arr   0.9431654803218854\n",
            "  comp.time   182.54 s\n",
            "p missing rate: 23.99%\n",
            "  nth_start_imputation_init  35\n",
            "  100%\n",
            "  NRMSE_arr   0.7854352970220213\n",
            "  comp.time   204.10 s\n",
            "  Pearson_arr   0.9154178297886861\n",
            "  comp.time   204.10 s\n",
            "p missing rate: 30.36%\n",
            "  nth_start_imputation_init  10\n",
            "  100%\n",
            "  NRMSE_arr   0.9134089416029462\n",
            "  comp.time   222.94 s\n",
            "  Pearson_arr   0.7214846521318289\n",
            "  comp.time   222.95 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.1*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVLnbLl_C3LS"
      },
      "source": [
        "### Untuk k = 15%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrlpvpRbNiT-"
      },
      "source": [
        "#### k = 15% (Percobaan 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtSiWwlnNiT_",
        "outputId": "c0374d06-2e68-4e43-cff2-2bff5c458a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.88%\n",
            "  nth_start_imputation_init  586\n",
            "  100%\n",
            "  NRMSE_arr   0.5944623808950944\n",
            "  comp.time   47.36 s\n",
            "  Pearson_arr   0.8506385123175971\n",
            "  comp.time   47.36 s\n",
            "p missing rate: 6.11%\n",
            "  nth_start_imputation_init  409\n",
            "  100%\n",
            "  NRMSE_arr   0.6152133139345644\n",
            "  comp.time   91.21 s\n",
            "  Pearson_arr   0.9580316613967682\n",
            "  comp.time   91.21 s\n",
            "p missing rate: 8.81%\n",
            "  nth_start_imputation_init  294\n",
            "  100%\n",
            "  NRMSE_arr   0.5404564462858102\n",
            "  comp.time   117.35 s\n",
            "  Pearson_arr   0.9237384842856473\n",
            "  comp.time   117.35 s\n",
            "p missing rate: 12.09%\n",
            "  nth_start_imputation_init  215\n",
            "  100%\n",
            "  NRMSE_arr   0.627874696493196\n",
            "  comp.time   140.00 s\n",
            "  Pearson_arr   0.9460589100436291\n",
            "  comp.time   140.00 s\n",
            "p missing rate: 14.83%\n",
            "  nth_start_imputation_init  144\n",
            "  100%\n",
            "  NRMSE_arr   0.7007945800964964\n",
            "  comp.time   159.73 s\n",
            "  Pearson_arr   0.8579970198012274\n",
            "  comp.time   159.73 s\n",
            "p missing rate: 17.08%\n",
            "  nth_start_imputation_init  99\n",
            "  100%\n",
            "  NRMSE_arr   0.6815663195687923\n",
            "  comp.time   172.05 s\n",
            "  Pearson_arr   0.9097396556501411\n",
            "  comp.time   172.06 s\n",
            "p missing rate: 24.53%\n",
            "  nth_start_imputation_init  40\n",
            "  100%\n",
            "  NRMSE_arr   0.7261697133617444\n",
            "  comp.time   192.12 s\n",
            "  Pearson_arr   0.9237426028346178\n",
            "  comp.time   192.13 s\n",
            "p missing rate: 29.71%\n",
            "  nth_start_imputation_init  17\n",
            "  100%\n",
            "  NRMSE_arr   0.7787883214903547\n",
            "  comp.time   206.09 s\n",
            "  Pearson_arr   0.9215538234167625\n",
            "  comp.time   206.09 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.15*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_cluster_val_estimate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N0FIvHdu4qW",
        "outputId": "7e15e840-7ea1-4c94-a827-f452ab1d2fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2611.340, 2519.650, 2841.680, 2850.220, 2758.710, 2589.800],\n",
              "       [64.790, 74.140, 73.670, 98.170, 120.140, 122.990],\n",
              "       [29.810, 34.940, 33.780, 38.840, 29.130, 31.410],\n",
              "       ...,\n",
              "       [31.018, 34.940, 29.123, 33.840, 25.660, 31.410],\n",
              "       [8364.420, 7096.130, 4369.719, 8141.800, 7947.560, 4724.867],\n",
              "       [110.976, 106.586, 349.650, 148.880, 132.880, 110.633]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(y_cluster_val_estimate)\n",
        "df.head(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xkSSQrjxAo8B",
        "outputId": "702327fe-5389-4bcb-d384-439fd240bc47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0             1             2             3             4  \\\n",
              "0    2611.340088   2519.649902   2841.679932   2850.219971   2758.709961   \n",
              "1      64.790001     74.139999     73.669998     98.169998    120.139999   \n",
              "2      29.809999     34.939999     33.779999     38.840000     29.129999   \n",
              "3     970.400024   1263.760010   1134.329956   1165.119995   1207.790039   \n",
              "4      63.290001     52.799999     63.150002    113.279999    113.769997   \n",
              "5      69.309998     53.919998    113.430000     33.840000     30.040001   \n",
              "6      29.809999     34.939999     33.779999     33.840000     25.660000   \n",
              "7    4687.750000   5106.700195   5429.589844   3573.030029   3692.540039   \n",
              "8      29.809999     34.939999     33.779999     33.840000     25.660000   \n",
              "9      29.809999     34.939999     33.779999     33.840000     25.660000   \n",
              "10   2019.150024   1767.010010   2047.650024   3275.280029   3372.159912   \n",
              "11     29.809999     34.939999     33.779999     47.470001     33.680000   \n",
              "12     29.809999     34.939999     33.779999     33.840000     25.660000   \n",
              "13    436.980011    447.089996    446.720001    358.170013    389.549988   \n",
              "14   1318.479980   1308.689941   1417.329956    790.770020    831.890015   \n",
              "15     29.809999     34.939999     33.779999     33.840000     25.660000   \n",
              "16     29.809999     34.939999     33.779999     33.840000     25.660000   \n",
              "17   6815.399902   6358.100098   7259.729980   5107.100098   5617.540039   \n",
              "18  54239.929688  62735.101562  59364.171875  38953.789062  35268.000000   \n",
              "19   1032.180054   1204.219971   1282.849976    805.869995    800.950012   \n",
              "20   6370.890137   6137.919922   6759.220215   4491.100098   4450.709961   \n",
              "21   1699.709961   1899.569946   2121.320068   1617.140015   1675.609985   \n",
              "22     63.290001     46.060001     57.299999     33.840000     25.660000   \n",
              "23     29.809999     34.939999     33.779999     63.650002     25.660000   \n",
              "24    126.570000     96.610001    194.119995     33.840000     30.040001   \n",
              "25    170.270004    149.399994    185.940002     98.169998    111.949997   \n",
              "26    791.090027   1300.829956   1203.329956   1284.869995   1302.449951   \n",
              "27    275.750000    168.500000    204.649994    142.399994    121.050003   \n",
              "28     29.809999     34.939999     33.779999     33.840000     25.660000   \n",
              "29     49.730000     70.769997     57.299999     33.840000     25.660000   \n",
              "30     29.809999     34.939999     49.119999     57.180000     36.410000   \n",
              "31   1214.510010    516.739990    622.130005    340.899994    279.420013   \n",
              "32     29.809999     34.939999     33.779999     43.150002     34.590000   \n",
              "33  46666.589844  40230.128906  46249.179688  19055.080078  18286.130859   \n",
              "34   2041.760010   2181.520020   2344.679932    589.030029    524.260010   \n",
              "35    223.009995    221.300003    275.980011    395.920013    344.040009   \n",
              "36     29.809999     34.939999     33.779999     33.840000     25.660000   \n",
              "37     29.809999     44.930000     39.759998    463.890015    443.250000   \n",
              "38     29.809999     34.939999     33.779999     33.840000     25.660000   \n",
              "39    443.010010    733.539978    575.349976    312.859985    270.320007   \n",
              "40  11001.379883  22716.160156  17102.689453   3587.050049   2794.209961   \n",
              "41    610.270020    814.419983    797.539978    553.429993    609.809998   \n",
              "42     29.809999     34.939999     45.610001     84.150002     77.360001   \n",
              "43  13126.009766   9445.030273  12667.099609  13675.030273  13386.709961   \n",
              "44   1092.449951   1097.500000   1317.930054    443.390015    413.220001   \n",
              "45    203.419998    189.839996    224.529999    252.440002    226.630005   \n",
              "46   4412.000000   4676.459961   4793.430176   8427.690430   8313.450195   \n",
              "47     29.809999     34.939999     33.779999     33.840000     25.660000   \n",
              "48     29.809999     34.939999     33.779999     33.840000     30.950001   \n",
              "49     29.809999     34.939999     33.779999     48.549999     32.770000   \n",
              "\n",
              "               5  \n",
              "0    2589.800049  \n",
              "1     122.989998  \n",
              "2      31.410000  \n",
              "3    1172.349976  \n",
              "4      92.900002  \n",
              "5      31.410000  \n",
              "6      31.410000  \n",
              "7    3558.649902  \n",
              "8      31.410000  \n",
              "9      31.410000  \n",
              "10   3361.340088  \n",
              "11     45.119999  \n",
              "12     31.410000  \n",
              "13    371.609985  \n",
              "14    824.630005  \n",
              "15     31.410000  \n",
              "16     31.410000  \n",
              "17   5693.660156  \n",
              "18  35394.500000  \n",
              "19    779.510010  \n",
              "20   4413.359863  \n",
              "21   1612.979980  \n",
              "22     31.410000  \n",
              "23     31.410000  \n",
              "24     31.410000  \n",
              "25    135.369995  \n",
              "26   1232.520020  \n",
              "27    115.019997  \n",
              "28     31.410000  \n",
              "29     31.410000  \n",
              "30     46.889999  \n",
              "31    294.640015  \n",
              "32     31.850000  \n",
              "33  17710.960938  \n",
              "34    522.909973  \n",
              "35    375.149994  \n",
              "36     31.410000  \n",
              "37    430.010010  \n",
              "38     31.410000  \n",
              "39    273.399994  \n",
              "40   3081.739990  \n",
              "41    583.969971  \n",
              "42     66.360001  \n",
              "43  13020.660156  \n",
              "44    464.519989  \n",
              "45    234.470001  \n",
              "46   8272.839844  \n",
              "47     31.410000  \n",
              "48     33.619999  \n",
              "49     31.410000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a7b2ae5-ffbe-4db2-a7c2-55590ae1245c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2611.340088</td>\n",
              "      <td>2519.649902</td>\n",
              "      <td>2841.679932</td>\n",
              "      <td>2850.219971</td>\n",
              "      <td>2758.709961</td>\n",
              "      <td>2589.800049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>64.790001</td>\n",
              "      <td>74.139999</td>\n",
              "      <td>73.669998</td>\n",
              "      <td>98.169998</td>\n",
              "      <td>120.139999</td>\n",
              "      <td>122.989998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29.809999</td>\n",
              "      <td>34.939999</td>\n",
              "      <td>33.779999</td>\n",
              "      <td>38.840000</td>\n",
              "      <td>29.129999</td>\n",
              "      <td>31.410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>970.400024</td>\n",
              "      <td>1263.760010</td>\n",
              "      <td>1134.329956</td>\n",
              "      <td>1165.119995</td>\n",
              "      <td>1207.790039</td>\n",
              "      <td>1172.349976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>63.290001</td>\n",
              "      <td>52.799999</td>\n",
              "      <td>63.150002</td>\n",
              "      <td>113.279999</td>\n",
              "      <td>113.769997</td>\n",
              "      <td>92.900002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>69.309998</td>\n",
              "      <td>53.919998</td>\n",
              "      <td>113.430000</td>\n",
              "      <td>33.840000</td>\n",
              "      <td>30.040001</td>\n",
              "      <td>31.410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>29.809999</td>\n",
              "      <td>34.939999</td>\n",
              "      <td>33.779999</td>\n",
              "      <td>33.840000</td>\n",
              "      <td>25.660000</td>\n",
              "      <td>31.410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4687.750000</td>\n",
              "      <td>5106.700195</td>\n",
              "      <td>5429.589844</td>\n",
              "      <td>3573.030029</td>\n",
              "      <td>3692.540039</td>\n",
              "      <td>3558.649902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>29.809999</td>\n",
              "      <td>34.939999</td>\n",
              "      <td>33.779999</td>\n",
              "      <td>33.840000</td>\n",
              "      <td>25.660000</td>\n",
              "      <td>31.410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>29.809999</td>\n",
              "      <td>34.939999</td>\n",
              "      <td>33.779999</td>\n",
              "      <td>33.840000</td>\n",
              "      <td>25.660000</td>\n",
              "      <td>31.410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2019.150024</td>\n",
              "      <td>1767.010010</td>\n",
              "      <td>2047.650024</td>\n",
              "      <td>3275.280029</td>\n",
              "      <td>3372.159912</td>\n",
              "      <td>3361.340088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>29.809999</td>\n",
              "      <td>34.939999</td>\n",
              "      <td>33.779999</td>\n",
              "      <td>47.470001</td>\n",
              "      <td>33.680000</td>\n",
              "      <td>45.119999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>29.809999</td>\n",
              "      <td>34.939999</td>\n",
              "      <td>33.779999</td>\n",
              "      <td>33.840000</td>\n",
              "      <td>25.660000</td>\n",
              "      <td>31.410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>436.980011</td>\n",
              "      <td>447.089996</td>\n",
              "      <td>446.720001</td>\n",
              "      <td>358.170013</td>\n",
              "      <td>389.549988</td>\n",
              "      <td>371.609985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1318.479980</td>\n",
              "      <td>1308.689941</td>\n",
              "      <td>1417.329956</td>\n",
              "      <td>790.770020</td>\n",
              "      <td>831.890015</td>\n",
              "      <td>824.630005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>29.809999</td>\n",
              "      <td>34.939999</td>\n",
              "      <td>33.779999</td>\n",
              "      <td>33.840000</td>\n",
              "      <td>25.660000</td>\n",
              "      <td>31.410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>29.809999</td>\n",
              "      <td>34.939999</td>\n",
              "      <td>33.779999</td>\n",
              "      <td>33.840000</td>\n",
              "      <td>25.660000</td>\n",
              "      <td>31.410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>6815.399902</td>\n",
              "      <td>6358.100098</td>\n",
              "      <td>7259.729980</td>\n",
              "      <td>5107.100098</td>\n",
              "      <td>5617.540039</td>\n",
              "      <td>5693.660156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>54239.929688</td>\n",
              "      <td>62735.101562</td>\n",
              "      <td>59364.171875</td>\n",
              "      <td>38953.789062</td>\n",
              "      <td>35268.000000</td>\n",
              "      <td>35394.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1032.180054</td>\n",
              "      <td>1204.219971</td>\n",
              "      <td>1282.849976</td>\n",
              "      <td>805.869995</td>\n",
              "      <td>800.950012</td>\n",
              "      <td>779.510010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>6370.890137</td>\n",
              "      <td>6137.919922</td>\n",
              "      <td>6759.220215</td>\n",
              "      <td>4491.100098</td>\n",
              "      <td>4450.709961</td>\n",
              "      <td>4413.359863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1699.709961</td>\n",
              "      <td>1899.569946</td>\n",
              "      <td>2121.320068</td>\n",
              "      <td>1617.140015</td>\n",
              "      <td>1675.609985</td>\n",
              "      <td>1612.979980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>63.290001</td>\n",
              "      <td>46.060001</td>\n",
              "      <td>57.299999</td>\n",
              "      <td>33.840000</td>\n",
              "      <td>25.660000</td>\n",
              "      <td>31.410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>29.809999</td>\n",
              "      <td>34.939999</td>\n",
              "      <td>33.779999</td>\n",
              "      <td>63.650002</td>\n",
              "      <td>25.660000</td>\n",
              "      <td>31.410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>126.570000</td>\n",
              "      <td>96.610001</td>\n",
              "      <td>194.119995</td>\n",
              "      <td>33.840000</td>\n",
              "      <td>30.040001</td>\n",
              "      <td>31.410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>170.270004</td>\n",
              "      <td>149.399994</td>\n",
              "      <td>185.940002</td>\n",
              "      <td>98.169998</td>\n",
              "      <td>111.949997</td>\n",
              "      <td>135.369995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>791.090027</td>\n",
              "      <td>1300.829956</td>\n",
              "      <td>1203.329956</td>\n",
              "      <td>1284.869995</td>\n",
              "      <td>1302.449951</td>\n",
              "      <td>1232.520020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>275.750000</td>\n",
              "      <td>168.500000</td>\n",
              "      <td>204.649994</td>\n",
              "      <td>142.399994</td>\n",
              "      <td>121.050003</td>\n",
              "      <td>115.019997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>29.809999</td>\n",
              "      <td>34.939999</td>\n",
              "      <td>33.779999</td>\n",
              "      <td>33.840000</td>\n",
              "      <td>25.660000</td>\n",
              "      <td>31.410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>49.730000</td>\n",
              "      <td>70.769997</td>\n",
              "      <td>57.299999</td>\n",
              "      <td>33.840000</td>\n",
              "      <td>25.660000</td>\n",
              "      <td>31.410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>29.809999</td>\n",
              "      <td>34.939999</td>\n",
              "      <td>49.119999</td>\n",
              "      <td>57.180000</td>\n",
              "      <td>36.410000</td>\n",
              "      <td>46.889999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>1214.510010</td>\n",
              "      <td>516.739990</td>\n",
              "      <td>622.130005</td>\n",
              "      <td>340.899994</td>\n",
              "      <td>279.420013</td>\n",
              "      <td>294.640015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>29.809999</td>\n",
              "      <td>34.939999</td>\n",
              "      <td>33.779999</td>\n",
              "      <td>43.150002</td>\n",
              "      <td>34.590000</td>\n",
              "      <td>31.850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>46666.589844</td>\n",
              "      <td>40230.128906</td>\n",
              "      <td>46249.179688</td>\n",
              "      <td>19055.080078</td>\n",
              "      <td>18286.130859</td>\n",
              "      <td>17710.960938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2041.760010</td>\n",
              "      <td>2181.520020</td>\n",
              "      <td>2344.679932</td>\n",
              "      <td>589.030029</td>\n",
              "      <td>524.260010</td>\n",
              "      <td>522.909973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>223.009995</td>\n",
              "      <td>221.300003</td>\n",
              "      <td>275.980011</td>\n",
              "      <td>395.920013</td>\n",
              "      <td>344.040009</td>\n",
              "      <td>375.149994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>29.809999</td>\n",
              "      <td>34.939999</td>\n",
              "      <td>33.779999</td>\n",
              "      <td>33.840000</td>\n",
              "      <td>25.660000</td>\n",
              "      <td>31.410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>29.809999</td>\n",
              "      <td>44.930000</td>\n",
              "      <td>39.759998</td>\n",
              "      <td>463.890015</td>\n",
              "      <td>443.250000</td>\n",
              "      <td>430.010010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>29.809999</td>\n",
              "      <td>34.939999</td>\n",
              "      <td>33.779999</td>\n",
              "      <td>33.840000</td>\n",
              "      <td>25.660000</td>\n",
              "      <td>31.410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>443.010010</td>\n",
              "      <td>733.539978</td>\n",
              "      <td>575.349976</td>\n",
              "      <td>312.859985</td>\n",
              "      <td>270.320007</td>\n",
              "      <td>273.399994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>11001.379883</td>\n",
              "      <td>22716.160156</td>\n",
              "      <td>17102.689453</td>\n",
              "      <td>3587.050049</td>\n",
              "      <td>2794.209961</td>\n",
              "      <td>3081.739990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>610.270020</td>\n",
              "      <td>814.419983</td>\n",
              "      <td>797.539978</td>\n",
              "      <td>553.429993</td>\n",
              "      <td>609.809998</td>\n",
              "      <td>583.969971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>29.809999</td>\n",
              "      <td>34.939999</td>\n",
              "      <td>45.610001</td>\n",
              "      <td>84.150002</td>\n",
              "      <td>77.360001</td>\n",
              "      <td>66.360001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>13126.009766</td>\n",
              "      <td>9445.030273</td>\n",
              "      <td>12667.099609</td>\n",
              "      <td>13675.030273</td>\n",
              "      <td>13386.709961</td>\n",
              "      <td>13020.660156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>1092.449951</td>\n",
              "      <td>1097.500000</td>\n",
              "      <td>1317.930054</td>\n",
              "      <td>443.390015</td>\n",
              "      <td>413.220001</td>\n",
              "      <td>464.519989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>203.419998</td>\n",
              "      <td>189.839996</td>\n",
              "      <td>224.529999</td>\n",
              "      <td>252.440002</td>\n",
              "      <td>226.630005</td>\n",
              "      <td>234.470001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>4412.000000</td>\n",
              "      <td>4676.459961</td>\n",
              "      <td>4793.430176</td>\n",
              "      <td>8427.690430</td>\n",
              "      <td>8313.450195</td>\n",
              "      <td>8272.839844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>29.809999</td>\n",
              "      <td>34.939999</td>\n",
              "      <td>33.779999</td>\n",
              "      <td>33.840000</td>\n",
              "      <td>25.660000</td>\n",
              "      <td>31.410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>29.809999</td>\n",
              "      <td>34.939999</td>\n",
              "      <td>33.779999</td>\n",
              "      <td>33.840000</td>\n",
              "      <td>30.950001</td>\n",
              "      <td>33.619999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>29.809999</td>\n",
              "      <td>34.939999</td>\n",
              "      <td>33.779999</td>\n",
              "      <td>48.549999</td>\n",
              "      <td>32.770000</td>\n",
              "      <td>31.410000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a7b2ae5-ffbe-4db2-a7c2-55590ae1245c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4a7b2ae5-ffbe-4db2-a7c2-55590ae1245c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4a7b2ae5-ffbe-4db2-a7c2-55590ae1245c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/SKRIPSI/hasil imputasi k=15% dan MV 5%.csv', index = False)"
      ],
      "metadata": {
        "id": "b9xfwfaBAmE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMdujjNsE0SA"
      },
      "source": [
        "#### k = 15% (Percobaan 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YQ6DwL1E0SC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f306598-25bf-4dad-d015-503ac57eb455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.79%\n",
            "  nth_start_imputation_init  594\n",
            "  100%\n",
            "  NRMSE_arr   0.6530786563879692\n",
            "  comp.time   44.65 s\n",
            "  Pearson_arr   0.9138802114081934\n",
            "  comp.time   44.65 s\n",
            "p missing rate: 6.59%\n",
            "  nth_start_imputation_init  392\n",
            "  100%\n",
            "  NRMSE_arr   0.5586059064499893\n",
            "  comp.time   95.08 s\n",
            "  Pearson_arr   0.9766768113055477\n",
            "  comp.time   95.08 s\n",
            "p missing rate: 8.66%\n",
            "  nth_start_imputation_init  303\n",
            "  100%\n",
            "  NRMSE_arr   0.5522526691370353\n",
            "  comp.time   116.24 s\n",
            "  Pearson_arr   0.9643427116370118\n",
            "  comp.time   116.24 s\n",
            "p missing rate: 12.37%\n",
            "  nth_start_imputation_init  174\n",
            "  100%\n",
            "  NRMSE_arr   0.7553585679639709\n",
            "  comp.time   149.86 s\n",
            "  Pearson_arr   0.8886350467572691\n",
            "  comp.time   149.86 s\n",
            "p missing rate: 15.04%\n",
            "  nth_start_imputation_init  129\n",
            "  100%\n",
            "  NRMSE_arr   0.6285237752821569\n",
            "  comp.time   160.78 s\n",
            "  Pearson_arr   0.9237406824285922\n",
            "  comp.time   160.78 s\n",
            "p missing rate: 18.57%\n",
            "  nth_start_imputation_init  88\n",
            "  100%\n",
            "  NRMSE_arr   0.7612868122094645\n",
            "  comp.time   174.26 s\n",
            "  Pearson_arr   0.9269598727707223\n",
            "  comp.time   174.27 s\n",
            "p missing rate: 23.43%\n",
            "  nth_start_imputation_init  42\n",
            "  100%\n",
            "  NRMSE_arr   0.8224488266180919\n",
            "  comp.time   194.61 s\n",
            "  Pearson_arr   0.89970609417875\n",
            "  comp.time   194.61 s\n",
            "p missing rate: 29.76%\n",
            "  nth_start_imputation_init  10\n",
            "  100%\n",
            "  NRMSE_arr   0.7907017654439772\n",
            "  comp.time   205.89 s\n",
            "  Pearson_arr   0.933584135980882\n",
            "  comp.time   205.89 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.15*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfmoYdhSE0az"
      },
      "source": [
        "#### k = 15% (Percobaan 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuCjZbalE0a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01dc299b-af0c-427a-8e82-d08dd03bd6ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 3.06%\n",
            "  nth_start_imputation_init  567\n",
            "  100%\n",
            "  NRMSE_arr   0.5607120852810978\n",
            "  comp.time   50.44 s\n",
            "  Pearson_arr   0.9313080975525646\n",
            "  comp.time   50.44 s\n",
            "p missing rate: 5.96%\n",
            "  nth_start_imputation_init  413\n",
            "  100%\n",
            "  NRMSE_arr   0.48876163095568026\n",
            "  comp.time   86.31 s\n",
            "  Pearson_arr   0.9769394662968379\n",
            "  comp.time   86.31 s\n",
            "p missing rate: 8.55%\n",
            "  nth_start_imputation_init  311\n",
            "  100%\n",
            "  NRMSE_arr   0.6452168516005762\n",
            "  comp.time   111.99 s\n",
            "  Pearson_arr   0.907425872894329\n",
            "  comp.time   111.99 s\n",
            "p missing rate: 11.82%\n",
            "  nth_start_imputation_init  216\n",
            "  100%\n",
            "  NRMSE_arr   0.6719939294866446\n",
            "  comp.time   135.16 s\n",
            "  Pearson_arr   0.9328383516512924\n",
            "  comp.time   135.17 s\n",
            "p missing rate: 15.01%\n",
            "  nth_start_imputation_init  143\n",
            "  100%\n",
            "  NRMSE_arr   0.6009294203342825\n",
            "  comp.time   155.79 s\n",
            "  Pearson_arr   0.9258471860996296\n",
            "  comp.time   155.79 s\n",
            "p missing rate: 18.04%\n",
            "  nth_start_imputation_init  102\n",
            "  100%\n",
            "  NRMSE_arr   0.708238024013402\n",
            "  comp.time   167.16 s\n",
            "  Pearson_arr   0.8935340009399056\n",
            "  comp.time   167.17 s\n",
            "p missing rate: 24.40%\n",
            "  nth_start_imputation_init  35\n",
            "  100%\n",
            "  NRMSE_arr   0.7912201762556715\n",
            "  comp.time   190.64 s\n",
            "  Pearson_arr   0.9255342942179635\n",
            "  comp.time   190.64 s\n",
            "p missing rate: 30.24%\n",
            "  nth_start_imputation_init  15\n",
            "  100%\n",
            "  NRMSE_arr   0.7659447701126879\n",
            "  comp.time   201.55 s\n",
            "  Pearson_arr   0.920410195573346\n",
            "  comp.time   201.56 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.15*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT8j_XQhE0r2"
      },
      "source": [
        "#### k = 15% (Percobaan 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0AxTg4NE0r2",
        "outputId": "aee492eb-2716-49dd-c6ec-3f7b14da0413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.78%\n",
            "  nth_start_imputation_init  589\n",
            "  100%\n",
            "  NRMSE_arr   0.6460690962563342\n",
            "  comp.time   47.66 s\n",
            "  Pearson_arr   0.934414337527327\n",
            "  comp.time   47.66 s\n",
            "p missing rate: 6.30%\n",
            "  nth_start_imputation_init  407\n",
            "  100%\n",
            "  NRMSE_arr   0.6477485320408455\n",
            "  comp.time   91.99 s\n",
            "  Pearson_arr   0.8761367661562807\n",
            "  comp.time   91.99 s\n",
            "p missing rate: 8.76%\n",
            "  nth_start_imputation_init  313\n",
            "  100%\n",
            "  NRMSE_arr   0.657220023573705\n",
            "  comp.time   115.93 s\n",
            "  Pearson_arr   0.8706751300105171\n",
            "  comp.time   115.93 s\n",
            "p missing rate: 11.91%\n",
            "  nth_start_imputation_init  208\n",
            "  100%\n",
            "  NRMSE_arr   0.5890479448080534\n",
            "  comp.time   144.44 s\n",
            "  Pearson_arr   0.951638069039392\n",
            "  comp.time   144.44 s\n",
            "p missing rate: 14.50%\n",
            "  nth_start_imputation_init  157\n",
            "  100%\n",
            "  NRMSE_arr   0.6719475514646234\n",
            "  comp.time   159.03 s\n",
            "  Pearson_arr   0.9178254295973729\n",
            "  comp.time   159.03 s\n",
            "p missing rate: 18.11%\n",
            "  nth_start_imputation_init  80\n",
            "  100%\n",
            "  NRMSE_arr   0.7967427851026946\n",
            "  comp.time   181.54 s\n",
            "  Pearson_arr   0.9101629462558638\n",
            "  comp.time   181.54 s\n",
            "p missing rate: 23.29%\n",
            "  nth_start_imputation_init  49\n",
            "  100%\n",
            "  NRMSE_arr   0.6952184306023915\n",
            "  comp.time   194.11 s\n",
            "  Pearson_arr   0.8777629577184368\n",
            "  comp.time   194.11 s\n",
            "p missing rate: 29.82%\n",
            "  nth_start_imputation_init  19\n",
            "  100%\n",
            "  NRMSE_arr   0.8124809841273805\n",
            "  comp.time   209.89 s\n",
            "  Pearson_arr   0.9244043869949757\n",
            "  comp.time   209.89 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.15*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLWttpFRE1MS"
      },
      "source": [
        "#### k = 15% (Percobaan 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw74jeqPE1MS",
        "outputId": "4d1c306f-6c0c-4e57-c5a2-7530550465cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 3.02%\n",
            "  nth_start_imputation_init  574\n",
            "  100%\n",
            "  NRMSE_arr   0.5791234024999269\n",
            "  comp.time   52.61 s\n",
            "  Pearson_arr   0.969171604475447\n",
            "  comp.time   52.61 s\n",
            "p missing rate: 5.88%\n",
            "  nth_start_imputation_init  416\n",
            "  100%\n",
            "  NRMSE_arr   0.598370518047057\n",
            "  comp.time   92.46 s\n",
            "  Pearson_arr   0.9491427764519696\n",
            "  comp.time   92.46 s\n",
            "p missing rate: 8.58%\n",
            "  nth_start_imputation_init  303\n",
            "  100%\n",
            "  NRMSE_arr   0.6323838460026472\n",
            "  comp.time   123.61 s\n",
            "  Pearson_arr   0.966066892862873\n",
            "  comp.time   123.62 s\n",
            "p missing rate: 11.52%\n",
            "  nth_start_imputation_init  212\n",
            "  100%\n",
            "  NRMSE_arr   0.5922939880300181\n",
            "  comp.time   146.68 s\n",
            "  Pearson_arr   0.9538046086366403\n",
            "  comp.time   146.68 s\n",
            "p missing rate: 15.26%\n",
            "  nth_start_imputation_init  135\n",
            "  100%\n",
            "  NRMSE_arr   0.6416865542096886\n",
            "  comp.time   170.67 s\n",
            "  Pearson_arr   0.9035265464908889\n",
            "  comp.time   170.67 s\n",
            "p missing rate: 18.16%\n",
            "  nth_start_imputation_init  94\n",
            "  100%\n",
            "  NRMSE_arr   0.7163936611100283\n",
            "  comp.time   182.41 s\n",
            "  Pearson_arr   0.9437477283504426\n",
            "  comp.time   182.41 s\n",
            "p missing rate: 23.99%\n",
            "  nth_start_imputation_init  35\n",
            "  100%\n",
            "  NRMSE_arr   0.7853202534294443\n",
            "  comp.time   203.82 s\n",
            "  Pearson_arr   0.8863920731029264\n",
            "  comp.time   203.83 s\n",
            "p missing rate: 30.36%\n",
            "  nth_start_imputation_init  10\n",
            "  100%\n",
            "  NRMSE_arr   0.9132730010567828\n",
            "  comp.time   220.74 s\n",
            "  Pearson_arr   0.7179168983125351\n",
            "  comp.time   220.74 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.15*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93dNr2HJC3LU"
      },
      "source": [
        "### Untuk k = 20%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXNGYu89OUfN"
      },
      "source": [
        "#### k = 20% (Percobaan 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTRfbBkkOUfO",
        "outputId": "573b9625-9fe4-4817-b0ac-df535572f421"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.88%\n",
            "  nth_start_imputation_init  586\n",
            "  100%\n",
            "  NRMSE_arr   0.6024870457971565\n",
            "  comp.time   47.05 s\n",
            "  Pearson_arr   0.8446066695929367\n",
            "  comp.time   47.06 s\n",
            "p missing rate: 6.11%\n",
            "  nth_start_imputation_init  409\n",
            "  100%\n",
            "  NRMSE_arr   0.6028371603570257\n",
            "  comp.time   89.69 s\n",
            "  Pearson_arr   0.9508515267438411\n",
            "  comp.time   89.69 s\n",
            "p missing rate: 8.81%\n",
            "  nth_start_imputation_init  294\n",
            "  100%\n",
            "  NRMSE_arr   0.5489428537416401\n",
            "  comp.time   119.13 s\n",
            "  Pearson_arr   0.9206507372446048\n",
            "  comp.time   119.13 s\n",
            "p missing rate: 12.09%\n",
            "  nth_start_imputation_init  215\n",
            "  100%\n",
            "  NRMSE_arr   0.632481630759308\n",
            "  comp.time   139.90 s\n",
            "  Pearson_arr   0.9462710522278109\n",
            "  comp.time   139.90 s\n",
            "p missing rate: 14.83%\n",
            "  nth_start_imputation_init  144\n",
            "  100%\n",
            "  NRMSE_arr   0.7087111020300276\n",
            "  comp.time   159.90 s\n",
            "  Pearson_arr   0.8589384361739533\n",
            "  comp.time   159.90 s\n",
            "p missing rate: 17.08%\n",
            "  nth_start_imputation_init  99\n",
            "  100%\n",
            "  NRMSE_arr   0.6867757581580795\n",
            "  comp.time   169.92 s\n",
            "  Pearson_arr   0.9117006708576663\n",
            "  comp.time   169.92 s\n",
            "p missing rate: 24.53%\n",
            "  nth_start_imputation_init  40\n",
            "  100%\n",
            "  NRMSE_arr   0.7453243618474312\n",
            "  comp.time   192.82 s\n",
            "  Pearson_arr   0.9246861334779439\n",
            "  comp.time   192.82 s\n",
            "p missing rate: 29.71%\n",
            "  nth_start_imputation_init  17\n",
            "  100%\n",
            "  NRMSE_arr   0.7819722049656901\n",
            "  comp.time   203.78 s\n",
            "  Pearson_arr   0.9295154809103566\n",
            "  comp.time   203.78 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.2*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvviUvKdFFls"
      },
      "source": [
        "#### k = 20% (Percobaan 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wd3TbjHNFFlt"
      },
      "outputs": [],
      "source": [
        "k_max = round(0.2*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIu0WEAfFFyd"
      },
      "source": [
        "#### k = 20% (Percobaan 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqs5JqlmFFye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b535a21b-9d1e-41da-f767-2fe232764fe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 3.06%\n",
            "  nth_start_imputation_init  567\n",
            "  100%\n",
            "  NRMSE_arr   0.5607705755142367\n",
            "  comp.time   50.56 s\n",
            "  Pearson_arr   0.9452587180914958\n",
            "  comp.time   50.56 s\n",
            "p missing rate: 5.96%\n",
            "  nth_start_imputation_init  413\n",
            "  100%\n",
            "  NRMSE_arr   0.4923807998817518\n",
            "  comp.time   86.91 s\n",
            "  Pearson_arr   0.9775141336323092\n",
            "  comp.time   86.91 s\n",
            "p missing rate: 8.55%\n",
            "  nth_start_imputation_init  311\n",
            "  100%\n",
            "  NRMSE_arr   0.6458270964731423\n",
            "  comp.time   112.82 s\n",
            "  Pearson_arr   0.910427529182466\n",
            "  comp.time   112.83 s\n",
            "p missing rate: 11.82%\n",
            "  nth_start_imputation_init  216\n",
            "  100%\n",
            "  NRMSE_arr   0.6744131897019626\n",
            "  comp.time   135.42 s\n",
            "  Pearson_arr   0.933751139116309\n",
            "  comp.time   135.42 s\n",
            "p missing rate: 15.01%\n",
            "  nth_start_imputation_init  143\n",
            "  100%\n",
            "  NRMSE_arr   0.600604316417947\n",
            "  comp.time   156.97 s\n",
            "  Pearson_arr   0.9248010680868285\n",
            "  comp.time   156.97 s\n",
            "p missing rate: 18.04%\n",
            "  nth_start_imputation_init  102\n",
            "  100%\n",
            "  NRMSE_arr   0.7073713323464706\n",
            "  comp.time   167.90 s\n",
            "  Pearson_arr   0.8889832878932579\n",
            "  comp.time   167.90 s\n",
            "p missing rate: 24.40%\n",
            "  nth_start_imputation_init  35\n",
            "  100%\n",
            "  NRMSE_arr   0.7863852864102694\n",
            "  comp.time   191.57 s\n",
            "  Pearson_arr   0.9256515699286172\n",
            "  comp.time   191.57 s\n",
            "p missing rate: 30.24%\n",
            "  nth_start_imputation_init  15\n",
            "  100%\n",
            "  NRMSE_arr   0.7670214445466764\n",
            "  comp.time   200.70 s\n",
            "  Pearson_arr   0.9181680357617084\n",
            "  comp.time   200.70 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.2*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwLTjQ2vFF4-"
      },
      "source": [
        "#### k = 20% (Percobaan 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v74FpuYFF4_",
        "outputId": "32bdf3bc-d101-4606-bb11-d141a1ef2bca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.78%\n",
            "  nth_start_imputation_init  589\n",
            "  100%\n",
            "  NRMSE_arr   0.6644636164050913\n",
            "  comp.time   46.84 s\n",
            "  Pearson_arr   0.9308408208718704\n",
            "  comp.time   46.84 s\n",
            "p missing rate: 6.30%\n",
            "  nth_start_imputation_init  407\n",
            "  100%\n",
            "  NRMSE_arr   0.6537433472468894\n",
            "  comp.time   91.98 s\n",
            "  Pearson_arr   0.875340658025247\n",
            "  comp.time   91.98 s\n",
            "p missing rate: 8.76%\n",
            "  nth_start_imputation_init  313\n",
            "  100%\n",
            "  NRMSE_arr   0.6488452504634419\n",
            "  comp.time   116.80 s\n",
            "  Pearson_arr   0.8926263683745799\n",
            "  comp.time   116.80 s\n",
            "p missing rate: 11.91%\n",
            "  nth_start_imputation_init  208\n",
            "  100%\n",
            "  NRMSE_arr   0.5951134429305978\n",
            "  comp.time   143.76 s\n",
            "  Pearson_arr   0.9486975868187257\n",
            "  comp.time   143.76 s\n",
            "p missing rate: 14.50%\n",
            "  nth_start_imputation_init  157\n",
            "  100%\n",
            "  NRMSE_arr   0.6731496670854554\n",
            "  comp.time   159.30 s\n",
            "  Pearson_arr   0.9178429190905554\n",
            "  comp.time   159.30 s\n",
            "p missing rate: 18.11%\n",
            "  nth_start_imputation_init  80\n",
            "  100%\n",
            "  NRMSE_arr   0.7999092934114812\n",
            "  comp.time   181.44 s\n",
            "  Pearson_arr   0.9149125789334875\n",
            "  comp.time   181.45 s\n",
            "p missing rate: 23.29%\n",
            "  nth_start_imputation_init  49\n",
            "  100%\n",
            "  NRMSE_arr   0.6885175934021771\n",
            "  comp.time   193.45 s\n",
            "  Pearson_arr   0.8826356479878267\n",
            "  comp.time   193.45 s\n",
            "p missing rate: 29.82%\n",
            "  nth_start_imputation_init  19\n",
            "  100%\n",
            "  NRMSE_arr   0.8114672398766366\n",
            "  comp.time   209.96 s\n",
            "  Pearson_arr   0.927979437262009\n",
            "  comp.time   209.96 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.2*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0up_FYGXFGFd"
      },
      "source": [
        "#### k = 20% (Percobaan 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzQpfe3yFGFd",
        "outputId": "e37bd874-d71b-4858-e61f-6b3efbdd8842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 3.02%\n",
            "  nth_start_imputation_init  574\n",
            "  100%\n",
            "  NRMSE_arr   0.5839188302781829\n",
            "  comp.time   54.31 s\n",
            "  Pearson_arr   0.9681396916390964\n",
            "  comp.time   54.31 s\n",
            "p missing rate: 5.88%\n",
            "  nth_start_imputation_init  416\n",
            "  100%\n",
            "  NRMSE_arr   0.601694879280027\n",
            "  comp.time   93.05 s\n",
            "  Pearson_arr   0.95130399255419\n",
            "  comp.time   93.05 s\n",
            "p missing rate: 8.58%\n",
            "  nth_start_imputation_init  303\n",
            "  100%\n",
            "  NRMSE_arr   0.6345107949135594\n",
            "  comp.time   122.67 s\n",
            "  Pearson_arr   0.9670758261872268\n",
            "  comp.time   122.68 s\n",
            "p missing rate: 11.52%\n",
            "  nth_start_imputation_init  212\n",
            "  100%\n",
            "  NRMSE_arr   0.5941026949198523\n",
            "  comp.time   148.97 s\n",
            "  Pearson_arr   0.9555032562469454\n",
            "  comp.time   148.97 s\n",
            "p missing rate: 15.26%\n",
            "  nth_start_imputation_init  135\n",
            "  100%\n",
            "  NRMSE_arr   0.6445930691980971\n",
            "  comp.time   171.07 s\n",
            "  Pearson_arr   0.9140442084641016\n",
            "  comp.time   171.07 s\n",
            "p missing rate: 18.16%\n",
            "  nth_start_imputation_init  94\n",
            "  100%\n",
            "  NRMSE_arr   0.6964758334218146\n",
            "  comp.time   181.36 s\n",
            "  Pearson_arr   0.9309753925701608\n",
            "  comp.time   181.37 s\n",
            "p missing rate: 23.99%\n",
            "  nth_start_imputation_init  35\n",
            "  100%\n",
            "  NRMSE_arr   0.784718623093488\n",
            "  comp.time   204.13 s\n",
            "  Pearson_arr   0.8810909681144968\n",
            "  comp.time   204.13 s\n",
            "p missing rate: 30.36%\n",
            "  nth_start_imputation_init  10\n",
            "  100%\n",
            "  NRMSE_arr   0.9128770114216362\n",
            "  comp.time   220.72 s\n",
            "  Pearson_arr   0.7192773236930013\n",
            "  comp.time   220.72 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.2*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ccwt61YvC3LX"
      },
      "source": [
        "### Untuk k = 25%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFJLb1nwOcyA"
      },
      "source": [
        "#### k = 25% (Percobaan 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvAY2TdUOcyB",
        "outputId": "17db3303-20bb-49c9-b1fb-35e139e25141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.88%\n",
            "  nth_start_imputation_init  586\n",
            "  100%\n",
            "  NRMSE_arr   0.6026057610223717\n",
            "  comp.time   48.71 s\n",
            "  Pearson_arr   0.8487948468275867\n",
            "  comp.time   48.72 s\n",
            "p missing rate: 6.11%\n",
            "  nth_start_imputation_init  409\n",
            "  100%\n",
            "  NRMSE_arr   0.5927991023358937\n",
            "  comp.time   89.60 s\n",
            "  Pearson_arr   0.9569457049841089\n",
            "  comp.time   89.60 s\n",
            "p missing rate: 8.81%\n",
            "  nth_start_imputation_init  294\n",
            "  100%\n",
            "  NRMSE_arr   0.5360201756042656\n",
            "  comp.time   118.33 s\n",
            "  Pearson_arr   0.9246671268122787\n",
            "  comp.time   118.33 s\n",
            "p missing rate: 12.09%\n",
            "  nth_start_imputation_init  215\n",
            "  100%\n",
            "  NRMSE_arr   0.6377265974522178\n",
            "  comp.time   141.84 s\n",
            "  Pearson_arr   0.9457625411412387\n",
            "  comp.time   141.84 s\n",
            "p missing rate: 14.83%\n",
            "  nth_start_imputation_init  144\n",
            "  100%\n",
            "  NRMSE_arr   0.7121702528164683\n",
            "  comp.time   158.62 s\n",
            "  Pearson_arr   0.8566809756485962\n",
            "  comp.time   158.62 s\n",
            "p missing rate: 17.08%\n",
            "  nth_start_imputation_init  99\n",
            "  100%\n",
            "  NRMSE_arr   0.691228024649781\n",
            "  comp.time   172.25 s\n",
            "  Pearson_arr   0.9155597189366228\n",
            "  comp.time   172.26 s\n",
            "p missing rate: 24.53%\n",
            "  nth_start_imputation_init  40\n",
            "  100%\n",
            "  NRMSE_arr   0.7687276368870964\n",
            "  comp.time   192.32 s\n",
            "  Pearson_arr   0.9262152213362554\n",
            "  comp.time   192.33 s\n",
            "p missing rate: 29.71%\n",
            "  nth_start_imputation_init  17\n",
            "  100%\n",
            "  NRMSE_arr   0.7804439385132249\n",
            "  comp.time   205.01 s\n",
            "  Pearson_arr   0.9250089944860013\n",
            "  comp.time   205.01 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.25*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeMxq6jpFT4v"
      },
      "source": [
        "#### k = 25% (Percobaan 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtsoMRfyFT4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1b38d4a-2c57-4484-bd8e-952af21cc353"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "p missing rate: 2.79%\n",
            "  nth_start_imputation_init  594\n",
            "  100%\n",
            "  NRMSE_arr   0.6270724779083671\n",
            "  comp.time   45.30 s\n",
            "  Pearson_arr   0.9440558754461787\n",
            "  comp.time   45.30 s\n",
            "p missing rate: 6.59%\n",
            "  nth_start_imputation_init  392\n",
            "  100%\n",
            "  NRMSE_arr   0.5661118351305235\n",
            "  comp.time   94.44 s\n",
            "  Pearson_arr   0.9764303647658609\n",
            "  comp.time   94.44 s\n",
            "p missing rate: 8.66%\n",
            "  nth_start_imputation_init  303\n",
            "  100%\n",
            "  NRMSE_arr   0.6105236111098352\n",
            "  comp.time   117.38 s\n",
            "  Pearson_arr   0.9682299812222155\n",
            "  comp.time   117.39 s\n",
            "p missing rate: 12.37%\n",
            "  nth_start_imputation_init  174\n",
            "  100%\n",
            "  NRMSE_arr   0.7586283774221242\n",
            "  comp.time   148.10 s\n",
            "  Pearson_arr   0.8987381753757971\n",
            "  comp.time   148.10 s\n",
            "p missing rate: 15.04%\n",
            "  nth_start_imputation_init  129\n",
            "  100%\n",
            "  NRMSE_arr   0.6393782112894121\n",
            "  comp.time   162.67 s\n",
            "  Pearson_arr   0.9243137302775469\n",
            "  comp.time   162.67 s\n",
            "p missing rate: 18.57%\n",
            "  nth_start_imputation_init  88\n",
            "  100%\n",
            "  NRMSE_arr   0.7648945948885778\n",
            "  comp.time   173.33 s\n",
            "  Pearson_arr   0.9338736080337313\n",
            "  comp.time   173.33 s\n",
            "p missing rate: 23.43%\n",
            "  nth_start_imputation_init  42\n",
            "  100%\n",
            "  NRMSE_arr   0.8198679506333909\n",
            "  comp.time   193.12 s\n",
            "  Pearson_arr   0.9002907797708206\n",
            "  comp.time   193.12 s\n",
            "p missing rate: 29.76%\n",
            "  nth_start_imputation_init  10\n",
            "  100%\n",
            "  NRMSE_arr   0.7886191687027964\n",
            "  comp.time   205.50 s\n",
            "  Pearson_arr   0.9269595190572565\n",
            "  comp.time   205.51 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.25*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw0kV5z-FUDJ"
      },
      "source": [
        "#### k = 25% (Percobaan 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMKwb4tLFUDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32eef487-fc8a-48d5-ec99-19540f75d8b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 3.06%\n",
            "  nth_start_imputation_init  567\n",
            "  100%\n",
            "  NRMSE_arr   0.5645666623423136\n",
            "  comp.time   50.69 s\n",
            "  Pearson_arr   0.9455844148396247\n",
            "  comp.time   50.69 s\n",
            "p missing rate: 5.96%\n",
            "  nth_start_imputation_init  413\n",
            "  100%\n",
            "  NRMSE_arr   0.49387164023231783\n",
            "  comp.time   87.17 s\n",
            "  Pearson_arr   0.9786262428904631\n",
            "  comp.time   87.17 s\n",
            "p missing rate: 8.55%\n",
            "  nth_start_imputation_init  311\n",
            "  100%\n",
            "  NRMSE_arr   0.6492868790596691\n",
            "  comp.time   111.58 s\n",
            "  Pearson_arr   0.9075188146731692\n",
            "  comp.time   111.58 s\n",
            "p missing rate: 11.82%\n",
            "  nth_start_imputation_init  216\n",
            "  100%\n",
            "  NRMSE_arr   0.6794885219530604\n",
            "  comp.time   137.12 s\n",
            "  Pearson_arr   0.9286735280592753\n",
            "  comp.time   137.12 s\n",
            "p missing rate: 15.01%\n",
            "  nth_start_imputation_init  143\n",
            "  100%\n",
            "  NRMSE_arr   0.5823165041653806\n",
            "  comp.time   157.11 s\n",
            "  Pearson_arr   0.9306707209298691\n",
            "  comp.time   157.11 s\n",
            "p missing rate: 18.04%\n",
            "  nth_start_imputation_init  102\n",
            "  100%\n",
            "  NRMSE_arr   0.7085124834096768\n",
            "  comp.time   168.94 s\n",
            "  Pearson_arr   0.8991701497193095\n",
            "  comp.time   168.94 s\n",
            "p missing rate: 24.40%\n",
            "  nth_start_imputation_init  35\n",
            "  100%\n",
            "  NRMSE_arr   0.7903841808364127\n",
            "  comp.time   192.68 s\n",
            "  Pearson_arr   0.9260189066673389\n",
            "  comp.time   192.69 s\n",
            "p missing rate: 30.24%\n",
            "  nth_start_imputation_init  15\n",
            "  100%\n",
            "  NRMSE_arr   0.7615390482979201\n",
            "  comp.time   200.83 s\n",
            "  Pearson_arr   0.9135422658132494\n",
            "  comp.time   200.83 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.25*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OuGPX5hFUOB"
      },
      "source": [
        "#### k = 25% (Percobaan 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiTJHKcsFUOC",
        "outputId": "261bf545-a87d-46bd-9ad0-ffc990d87188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.78%\n",
            "  nth_start_imputation_init  589\n",
            "  100%\n",
            "  NRMSE_arr   0.6806671565846818\n",
            "  comp.time   48.07 s\n",
            "  Pearson_arr   0.9246374091740553\n",
            "  comp.time   48.08 s\n",
            "p missing rate: 6.30%\n",
            "  nth_start_imputation_init  407\n",
            "  100%\n",
            "  NRMSE_arr   0.6481180242902913\n",
            "  comp.time   92.51 s\n",
            "  Pearson_arr   0.9018741673727818\n",
            "  comp.time   92.51 s\n",
            "p missing rate: 8.76%\n",
            "  nth_start_imputation_init  313\n",
            "  100%\n",
            "  NRMSE_arr   0.6535861644357827\n",
            "  comp.time   117.35 s\n",
            "  Pearson_arr   0.892478183922686\n",
            "  comp.time   117.35 s\n",
            "p missing rate: 11.91%\n",
            "  nth_start_imputation_init  208\n",
            "  100%\n",
            "  NRMSE_arr   0.5927276458741457\n",
            "  comp.time   142.93 s\n",
            "  Pearson_arr   0.9513024802973021\n",
            "  comp.time   142.93 s\n",
            "p missing rate: 14.50%\n",
            "  nth_start_imputation_init  157\n",
            "  100%\n",
            "  NRMSE_arr   0.6748258032212547\n",
            "  comp.time   161.24 s\n",
            "  Pearson_arr   0.9172029278014163\n",
            "  comp.time   161.24 s\n",
            "p missing rate: 18.11%\n",
            "  nth_start_imputation_init  80\n",
            "  100%\n",
            "  NRMSE_arr   0.8016291179040997\n",
            "  comp.time   180.38 s\n",
            "  Pearson_arr   0.913656228323348\n",
            "  comp.time   180.38 s\n",
            "p missing rate: 23.29%\n",
            "  nth_start_imputation_init  49\n",
            "  100%\n",
            "  NRMSE_arr   0.6953402573092521\n",
            "  comp.time   194.95 s\n",
            "  Pearson_arr   0.9030756780886491\n",
            "  comp.time   194.95 s\n",
            "p missing rate: 29.82%\n",
            "  nth_start_imputation_init  19\n",
            "  100%\n",
            "  NRMSE_arr   0.8114943835224108\n",
            "  comp.time   208.55 s\n",
            "  Pearson_arr   0.9242608173985948\n",
            "  comp.time   208.55 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.25*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbTzEqgcFUf2"
      },
      "source": [
        "#### k = 25% (Percobaan 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZBs33-QFUf3",
        "outputId": "050db5da-0fbb-4505-8131-76d6640eed8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 3.02%\n",
            "  nth_start_imputation_init  574\n",
            "  100%\n",
            "  NRMSE_arr   0.559841501805325\n",
            "  comp.time   53.26 s\n",
            "  Pearson_arr   0.9837985259991564\n",
            "  comp.time   53.27 s\n",
            "p missing rate: 5.88%\n",
            "  nth_start_imputation_init  416\n",
            "  100%\n",
            "  NRMSE_arr   0.6061490202552389\n",
            "  comp.time   93.09 s\n",
            "  Pearson_arr   0.9510728171852824\n",
            "  comp.time   93.09 s\n",
            "p missing rate: 8.58%\n",
            "  nth_start_imputation_init  303\n",
            "  100%\n",
            "  NRMSE_arr   0.6386325831414851\n",
            "  comp.time   124.79 s\n",
            "  Pearson_arr   0.9684692417115138\n",
            "  comp.time   124.79 s\n",
            "p missing rate: 11.52%\n",
            "  nth_start_imputation_init  212\n",
            "  100%\n",
            "  NRMSE_arr   0.5967698167320916\n",
            "  comp.time   147.07 s\n",
            "  Pearson_arr   0.9578057354933219\n",
            "  comp.time   147.07 s\n",
            "p missing rate: 15.26%\n",
            "  nth_start_imputation_init  135\n",
            "  100%\n",
            "  NRMSE_arr   0.6497455003096655\n",
            "  comp.time   171.64 s\n",
            "  Pearson_arr   0.913078790333673\n",
            "  comp.time   171.64 s\n",
            "p missing rate: 18.16%\n",
            "  nth_start_imputation_init  94\n",
            "  100%\n",
            "  NRMSE_arr   0.6992786888718222\n",
            "  comp.time   183.11 s\n",
            "  Pearson_arr   0.932104624579551\n",
            "  comp.time   183.11 s\n",
            "p missing rate: 23.99%\n",
            "  nth_start_imputation_init  35\n",
            "  100%\n",
            "  NRMSE_arr   0.7849195073873894\n",
            "  comp.time   202.64 s\n",
            "  Pearson_arr   0.909327324087952\n",
            "  comp.time   202.65 s\n",
            "p missing rate: 30.36%\n",
            "  nth_start_imputation_init  10\n",
            "  100%\n",
            "  NRMSE_arr   0.9132059797638089\n",
            "  comp.time   221.28 s\n",
            "  Pearson_arr   0.7122454087225519\n",
            "  comp.time   221.28 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.25*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIU1wN2nC3La"
      },
      "source": [
        "### Untuk k = 30%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "714MuQcIC3La"
      },
      "source": [
        "#### k = 30% (Percobaan 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZoOGuS5C3La",
        "outputId": "f76514c5-f8f5-40c5-c6a2-95c2630c252f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.88%\n",
            "  nth_start_imputation_init  586\n",
            "  100%\n",
            "  NRMSE_arr   0.6089481248944316\n",
            "  comp.time   51.87 s\n",
            "  Pearson_arr   0.847975926579995\n",
            "  comp.time   51.87 s\n",
            "p missing rate: 6.11%\n",
            "  nth_start_imputation_init  409\n",
            "  100%\n",
            "  NRMSE_arr   0.5992439165991225\n",
            "  comp.time   95.39 s\n",
            "  Pearson_arr   0.9579702615627866\n",
            "  comp.time   95.39 s\n",
            "p missing rate: 8.81%\n",
            "  nth_start_imputation_init  294\n",
            "  100%\n",
            "  NRMSE_arr   0.5382066921612179\n",
            "  comp.time   126.48 s\n",
            "  Pearson_arr   0.9256553042180417\n",
            "  comp.time   126.49 s\n",
            "p missing rate: 12.09%\n",
            "  nth_start_imputation_init  215\n",
            "  100%\n",
            "  NRMSE_arr   0.6433201565508812\n",
            "  comp.time   146.25 s\n",
            "  Pearson_arr   0.9465673433425215\n",
            "  comp.time   146.26 s\n",
            "p missing rate: 14.83%\n",
            "  nth_start_imputation_init  144\n",
            "  100%\n",
            "  NRMSE_arr   0.6953195446608946\n",
            "  comp.time   167.33 s\n",
            "  Pearson_arr   0.8720020764846032\n",
            "  comp.time   167.34 s\n",
            "p missing rate: 17.08%\n",
            "  nth_start_imputation_init  99\n",
            "  100%\n",
            "  NRMSE_arr   0.6931022612654125\n",
            "  comp.time   177.75 s\n",
            "  Pearson_arr   0.9130260263424768\n",
            "  comp.time   177.76 s\n",
            "p missing rate: 24.53%\n",
            "  nth_start_imputation_init  40\n",
            "  100%\n",
            "  NRMSE_arr   0.7428764239091706\n",
            "  comp.time   199.44 s\n",
            "  Pearson_arr   0.9262185104728028\n",
            "  comp.time   199.44 s\n",
            "p missing rate: 29.71%\n",
            "  nth_start_imputation_init  17\n",
            "  100%\n",
            "  NRMSE_arr   0.7823124866656237\n",
            "  comp.time   213.48 s\n",
            "  Pearson_arr   0.9250706722638187\n",
            "  comp.time   213.49 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.3*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbLK_XOSC3La"
      },
      "source": [
        "#### k = 30% (Percobaan 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nHtdZx0C3La",
        "outputId": "a33893e8-0bd2-479b-9ea3-c99fbb1a4330"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.79%\n",
            "  nth_start_imputation_init  594\n",
            "  100%\n",
            "  NRMSE_arr   0.6290643175908824\n",
            "  comp.time   57.12 s\n",
            "  Pearson_arr   0.9449486946516401\n",
            "  comp.time   57.13 s\n",
            "p missing rate: 6.59%\n",
            "  nth_start_imputation_init  392\n",
            "  100%\n",
            "  NRMSE_arr   0.5672461034869967\n",
            "  comp.time   99.25 s\n",
            "  Pearson_arr   0.9755826311851378\n",
            "  comp.time   99.26 s\n",
            "p missing rate: 8.66%\n",
            "  nth_start_imputation_init  303\n",
            "  100%\n",
            "  NRMSE_arr   0.6143154202342231\n",
            "  comp.time   121.01 s\n",
            "  Pearson_arr   0.9679274061529034\n",
            "  comp.time   121.01 s\n",
            "p missing rate: 12.37%\n",
            "  nth_start_imputation_init  174\n",
            "  100%\n",
            "  NRMSE_arr   0.7551662916237171\n",
            "  comp.time   154.82 s\n",
            "  Pearson_arr   0.8899830049733893\n",
            "  comp.time   154.82 s\n",
            "p missing rate: 15.04%\n",
            "  nth_start_imputation_init  129\n",
            "  100%\n",
            "  NRMSE_arr   0.6540114576598929\n",
            "  comp.time   169.20 s\n",
            "  Pearson_arr   0.9237717028405911\n",
            "  comp.time   169.21 s\n",
            "p missing rate: 18.57%\n",
            "  nth_start_imputation_init  88\n",
            "  100%\n",
            "  NRMSE_arr   0.7639216290723644\n",
            "  comp.time   179.31 s\n",
            "  Pearson_arr   0.926129341879948\n",
            "  comp.time   179.31 s\n",
            "p missing rate: 23.43%\n",
            "  nth_start_imputation_init  42\n",
            "  100%\n",
            "  NRMSE_arr   0.8213167502520093\n",
            "  comp.time   202.43 s\n",
            "  Pearson_arr   0.8987755495508162\n",
            "  comp.time   202.44 s\n",
            "p missing rate: 29.76%\n",
            "  nth_start_imputation_init  10\n",
            "  100%\n",
            "  NRMSE_arr   0.7846462261950563\n",
            "  comp.time   212.96 s\n",
            "  Pearson_arr   0.9325005768694409\n",
            "  comp.time   212.96 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.3*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMrB2Jm6C3Lb"
      },
      "source": [
        "#### k = 30% (Percobaan 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j93E4J5C3Lb",
        "outputId": "28df9603-7422-4baf-d01c-83eea793d1b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 3.06%\n",
            "  nth_start_imputation_init  567\n",
            "  100%\n",
            "  NRMSE_arr   0.568429220315209\n",
            "  comp.time   63.39 s\n",
            "  Pearson_arr   0.9651789645829626\n",
            "  comp.time   63.39 s\n",
            "p missing rate: 5.96%\n",
            "  nth_start_imputation_init  413\n",
            "  100%\n",
            "  NRMSE_arr   0.49078823396705734\n",
            "  comp.time   93.42 s\n",
            "  Pearson_arr   0.9795873319484569\n",
            "  comp.time   93.42 s\n",
            "p missing rate: 8.55%\n",
            "  nth_start_imputation_init  311\n",
            "  100%\n",
            "  NRMSE_arr   0.6441023410833542\n",
            "  comp.time   118.48 s\n",
            "  Pearson_arr   0.9068691509194279\n",
            "  comp.time   118.48 s\n",
            "p missing rate: 11.82%\n",
            "  nth_start_imputation_init  216\n",
            "  100%\n",
            "  NRMSE_arr   0.6800323258370402\n",
            "  comp.time   146.14 s\n",
            "  Pearson_arr   0.9251739261570536\n",
            "  comp.time   146.14 s\n",
            "p missing rate: 15.01%\n",
            "  nth_start_imputation_init  143\n",
            "  100%\n",
            "  NRMSE_arr   0.583290801736885\n",
            "  comp.time   166.83 s\n",
            "  Pearson_arr   0.9378878741537141\n",
            "  comp.time   166.83 s\n",
            "p missing rate: 18.04%\n",
            "  nth_start_imputation_init  102\n",
            "  100%\n",
            "  NRMSE_arr   0.7087134542392645\n",
            "  comp.time   178.94 s\n",
            "  Pearson_arr   0.9001202811900525\n",
            "  comp.time   178.94 s\n",
            "p missing rate: 24.40%\n",
            "  nth_start_imputation_init  35\n",
            "  100%\n",
            "  NRMSE_arr   0.7926718221811273\n",
            "  comp.time   203.41 s\n",
            "  Pearson_arr   0.9254628245622005\n",
            "  comp.time   203.41 s\n",
            "p missing rate: 30.24%\n",
            "  nth_start_imputation_init  15\n",
            "  100%\n",
            "  NRMSE_arr   0.763006351459609\n",
            "  comp.time   212.59 s\n",
            "  Pearson_arr   0.9146456947055227\n",
            "  comp.time   212.59 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.3*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3-Uw7tuC3Lb"
      },
      "source": [
        "#### k = 30% (Percobaan 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gsb29dJKC3Lc",
        "outputId": "d58b310e-cdb4-4348-90c4-e43ab71bc4ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.78%\n",
            "  nth_start_imputation_init  589\n",
            "  100%\n",
            "  NRMSE_arr   0.6898170765334871\n",
            "  comp.time   60.86 s\n",
            "  Pearson_arr   0.9212009842212818\n",
            "  comp.time   60.86 s\n",
            "p missing rate: 6.30%\n",
            "  nth_start_imputation_init  407\n",
            "  100%\n",
            "  NRMSE_arr   0.6559004420226158\n",
            "  comp.time   93.91 s\n",
            "  Pearson_arr   0.8974571684857243\n",
            "  comp.time   93.92 s\n",
            "p missing rate: 8.76%\n",
            "  nth_start_imputation_init  313\n",
            "  100%\n",
            "  NRMSE_arr   0.6535809552639311\n",
            "  comp.time   119.57 s\n",
            "  Pearson_arr   0.8974782787475658\n",
            "  comp.time   119.57 s\n",
            "p missing rate: 11.91%\n",
            "  nth_start_imputation_init  208\n",
            "  100%\n",
            "  NRMSE_arr   0.6005865462092106\n",
            "  comp.time   146.27 s\n",
            "  Pearson_arr   0.9718277151733904\n",
            "  comp.time   146.27 s\n",
            "p missing rate: 14.50%\n",
            "  nth_start_imputation_init  157\n",
            "  100%\n",
            "  NRMSE_arr   0.6805642092349036\n",
            "  comp.time   162.90 s\n",
            "  Pearson_arr   0.917216497415677\n",
            "  comp.time   162.90 s\n",
            "p missing rate: 18.11%\n",
            "  nth_start_imputation_init  80\n",
            "  100%\n",
            "  NRMSE_arr   0.8030594796007469\n",
            "  comp.time   187.67 s\n",
            "  Pearson_arr   0.9134156573867648\n",
            "  comp.time   187.67 s\n",
            "p missing rate: 23.29%\n",
            "  nth_start_imputation_init  49\n",
            "  100%\n",
            "  NRMSE_arr   0.697795358029766\n",
            "  comp.time   198.15 s\n",
            "  Pearson_arr   0.9021686461244993\n",
            "  comp.time   198.16 s\n",
            "p missing rate: 29.82%\n",
            "  nth_start_imputation_init  19\n",
            "  100%\n",
            "  NRMSE_arr   0.8139239995442981\n",
            "  comp.time   212.35 s\n",
            "  Pearson_arr   0.9235928478126932\n",
            "  comp.time   212.35 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.3*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TLJeZWSC3Lc"
      },
      "source": [
        "#### k = 30% (Percobaan 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFi8PJxeC3Lc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f98efd4e-9407-46be-bf10-a3180b21b7a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 3.02%\n",
            "  nth_start_imputation_init  574\n",
            "  100%\n",
            "  NRMSE_arr   0.5603285306050517\n",
            "  comp.time   54.92 s\n",
            "  Pearson_arr   0.9836929637967696\n",
            "  comp.time   54.92 s\n",
            "p missing rate: 5.88%\n",
            "  nth_start_imputation_init  416\n",
            "  100%\n",
            "  NRMSE_arr   0.6113111668377893\n",
            "  comp.time   92.68 s\n",
            "  Pearson_arr   0.9516825374740282\n",
            "  comp.time   92.68 s\n",
            "p missing rate: 8.58%\n",
            "  nth_start_imputation_init  303\n",
            "  100%\n",
            "  NRMSE_arr   0.6387072427333891\n",
            "  comp.time   126.31 s\n",
            "  Pearson_arr   0.9627078406733559\n",
            "  comp.time   126.31 s\n",
            "p missing rate: 11.52%\n",
            "  nth_start_imputation_init  212\n",
            "  100%\n",
            "  NRMSE_arr   0.5972358538009587\n",
            "  comp.time   150.21 s\n",
            "  Pearson_arr   0.9579827261870084\n",
            "  comp.time   150.21 s\n",
            "p missing rate: 15.26%\n",
            "  nth_start_imputation_init  135\n",
            "  100%\n",
            "  NRMSE_arr   0.652708918687429\n",
            "  comp.time   174.87 s\n",
            "  Pearson_arr   0.9125216060649111\n",
            "  comp.time   174.87 s\n",
            "p missing rate: 18.16%\n",
            "  nth_start_imputation_init  94\n",
            "  100%\n",
            "  NRMSE_arr   0.7035970120607788\n",
            "  comp.time   181.78 s\n",
            "  Pearson_arr   0.9310570270120553\n",
            "  comp.time   181.78 s\n",
            "p missing rate: 23.99%\n",
            "  nth_start_imputation_init  35\n",
            "  100%\n",
            "  NRMSE_arr   0.787905144293688\n",
            "  comp.time   208.46 s\n",
            "  Pearson_arr   0.9129163643493842\n",
            "  comp.time   208.46 s\n",
            "p missing rate: 30.36%\n",
            "  nth_start_imputation_init  10\n",
            "  100%\n",
            "  NRMSE_arr   0.9142511708368035\n",
            "  comp.time   224.61 s\n",
            "  Pearson_arr   0.7421305223481\n",
            "  comp.time   224.61 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.3*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZghXuCFC3Lc"
      },
      "source": [
        "### Untuk k = 40%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqI-LSYCC3Ld"
      },
      "source": [
        "#### k = 40% (Percobaan 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9h6iyGMC3Ld",
        "outputId": "922926b1-8f45-4be8-ec7c-b1bd9adf7d34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.88%\n",
            "  nth_start_imputation_init  586\n",
            "  100%\n",
            "  NRMSE_arr   0.6175742807265314\n",
            "  comp.time   49.28 s\n",
            "  Pearson_arr   0.8442765116462342\n",
            "  comp.time   49.28 s\n",
            "p missing rate: 6.11%\n",
            "  nth_start_imputation_init  409\n",
            "  100%\n",
            "  NRMSE_arr   0.6055659743212015\n",
            "  comp.time   94.95 s\n",
            "  Pearson_arr   0.9601037827611241\n",
            "  comp.time   94.95 s\n",
            "p missing rate: 8.81%\n",
            "  nth_start_imputation_init  294\n",
            "  100%\n",
            "  NRMSE_arr   0.5430702678881034\n",
            "  comp.time   122.05 s\n",
            "  Pearson_arr   0.9251506487306473\n",
            "  comp.time   122.06 s\n",
            "p missing rate: 12.09%\n",
            "  nth_start_imputation_init  215\n",
            "  100%\n",
            "  NRMSE_arr   0.6452395539824853\n",
            "  comp.time   146.23 s\n",
            "  Pearson_arr   0.9456587934607881\n",
            "  comp.time   146.23 s\n",
            "p missing rate: 14.83%\n",
            "  nth_start_imputation_init  144\n",
            "  100%\n",
            "  NRMSE_arr   0.6801390626524261\n",
            "  comp.time   164.17 s\n",
            "  Pearson_arr   0.8647368666298773\n",
            "  comp.time   164.17 s\n",
            "p missing rate: 17.08%\n",
            "  nth_start_imputation_init  99\n",
            "  100%\n",
            "  NRMSE_arr   0.6763734209180272\n",
            "  comp.time   183.42 s\n",
            "  Pearson_arr   0.9322337439680283\n",
            "  comp.time   183.42 s\n",
            "p missing rate: 24.53%\n",
            "  nth_start_imputation_init  40\n",
            "  100%\n",
            "  NRMSE_arr   0.7441661415412125\n",
            "  comp.time   201.95 s\n",
            "  Pearson_arr   0.9206300992195922\n",
            "  comp.time   201.95 s\n",
            "p missing rate: 29.71%\n",
            "  nth_start_imputation_init  17\n",
            "  100%\n",
            "  NRMSE_arr   0.7836370592693738\n",
            "  comp.time   212.95 s\n",
            "  Pearson_arr   0.9217584136857616\n",
            "  comp.time   212.95 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.4*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xjk_qEaC3Ld"
      },
      "source": [
        "#### k = 40% (Percobaan 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX4e0pqGC3Ld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f52854bb-c571-49ac-860d-7699cd6f405c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.79%\n",
            "  nth_start_imputation_init  594\n",
            "  100%\n",
            "  NRMSE_arr   0.6321134705079324\n",
            "  comp.time   46.90 s\n",
            "  Pearson_arr   0.9443122828006918\n",
            "  comp.time   46.90 s\n",
            "p missing rate: 6.59%\n",
            "  nth_start_imputation_init  392\n",
            "  100%\n",
            "  NRMSE_arr   0.5729904907860394\n",
            "  comp.time   98.01 s\n",
            "  Pearson_arr   0.9749883550574359\n",
            "  comp.time   98.02 s\n",
            "p missing rate: 8.66%\n",
            "  nth_start_imputation_init  303\n",
            "  100%\n",
            "  NRMSE_arr   0.6139750716990807\n",
            "  comp.time   122.04 s\n",
            "  Pearson_arr   0.9649966988557407\n",
            "  comp.time   122.04 s\n",
            "p missing rate: 12.37%\n",
            "  nth_start_imputation_init  174\n",
            "  100%\n",
            "  NRMSE_arr   0.7566095863565234\n",
            "  comp.time   156.90 s\n",
            "  Pearson_arr   0.8912167744970002\n",
            "  comp.time   156.90 s\n",
            "p missing rate: 15.04%\n",
            "  nth_start_imputation_init  129\n",
            "  100%\n",
            "  NRMSE_arr   0.6568055139909643\n",
            "  comp.time   167.78 s\n",
            "  Pearson_arr   0.9250585942927373\n",
            "  comp.time   167.78 s\n",
            "p missing rate: 18.57%\n",
            "  nth_start_imputation_init  88\n",
            "  100%\n",
            "  NRMSE_arr   0.7643297835587458\n",
            "  comp.time   180.81 s\n",
            "  Pearson_arr   0.9255803011257729\n",
            "  comp.time   180.81 s\n",
            "p missing rate: 23.43%\n",
            "  nth_start_imputation_init  42\n",
            "  100%\n",
            "  NRMSE_arr   0.819098773923415\n",
            "  comp.time   204.86 s\n",
            "  Pearson_arr   0.8901395408028122\n",
            "  comp.time   204.86 s\n",
            "p missing rate: 29.76%\n",
            "  nth_start_imputation_init  10\n",
            "  100%\n",
            "  NRMSE_arr   0.7858743603518825\n",
            "  comp.time   213.87 s\n",
            "  Pearson_arr   0.9290893428117153\n",
            "  comp.time   213.87 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.4*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuGoYv2vC3Le"
      },
      "source": [
        "#### k = 40% (Percobaan 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDR5JOAkC3Le",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73d36e00-c8cb-4466-88d5-b3afa7d0c1b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 3.06%\n",
            "  nth_start_imputation_init  567\n",
            "  100%\n",
            "  NRMSE_arr   0.5682047023146793\n",
            "  comp.time   53.61 s\n",
            "  Pearson_arr   0.9658078293451974\n",
            "  comp.time   53.61 s\n",
            "p missing rate: 5.96%\n",
            "  nth_start_imputation_init  413\n",
            "  100%\n",
            "  NRMSE_arr   0.4935687104191821\n",
            "  comp.time   92.28 s\n",
            "  Pearson_arr   0.9842488415354164\n",
            "  comp.time   92.28 s\n",
            "p missing rate: 8.55%\n",
            "  nth_start_imputation_init  311\n",
            "  100%\n",
            "  NRMSE_arr   0.6434324331724813\n",
            "  comp.time   119.71 s\n",
            "  Pearson_arr   0.9376901010241416\n",
            "  comp.time   119.71 s\n",
            "p missing rate: 11.82%\n",
            "  nth_start_imputation_init  216\n",
            "  100%\n",
            "  NRMSE_arr   0.6804473098760891\n",
            "  comp.time   143.71 s\n",
            "  Pearson_arr   0.92351225514421\n",
            "  comp.time   143.71 s\n",
            "p missing rate: 15.01%\n",
            "  nth_start_imputation_init  143\n",
            "  100%\n",
            "  NRMSE_arr   0.5901395817975794\n",
            "  comp.time   165.40 s\n",
            "  Pearson_arr   0.9423648787977491\n",
            "  comp.time   165.40 s\n",
            "p missing rate: 18.04%\n",
            "  nth_start_imputation_init  102\n",
            "  100%\n",
            "  NRMSE_arr   0.7092046486623361\n",
            "  comp.time   179.42 s\n",
            "  Pearson_arr   0.9023365973502863\n",
            "  comp.time   179.43 s\n",
            "p missing rate: 24.40%\n",
            "  nth_start_imputation_init  35\n",
            "  100%\n",
            "  NRMSE_arr   0.7954910252362427\n",
            "  comp.time   201.22 s\n",
            "  Pearson_arr   0.9228813839065237\n",
            "  comp.time   201.22 s\n",
            "p missing rate: 30.24%\n",
            "  nth_start_imputation_init  15\n",
            "  100%\n",
            "  NRMSE_arr   0.7615226327334289\n",
            "  comp.time   213.07 s\n",
            "  Pearson_arr   0.9138576604519312\n",
            "  comp.time   213.07 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.4*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTNAb1kMC3Le"
      },
      "source": [
        "#### k = 40% (Percobaan 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VW4WXARQC3Le",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1efc76f3-1e5a-4a3f-af42-486ec0f00c07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.78%\n",
            "  nth_start_imputation_init  589\n",
            "  100%\n",
            "  NRMSE_arr   0.7005256476529805\n",
            "  comp.time   48.61 s\n",
            "  Pearson_arr   0.9205461044479392\n",
            "  comp.time   48.61 s\n",
            "p missing rate: 6.30%\n",
            "  nth_start_imputation_init  407\n",
            "  100%\n",
            "  NRMSE_arr   0.6489926060171861\n",
            "  comp.time   93.77 s\n",
            "  Pearson_arr   0.9057648376474732\n",
            "  comp.time   93.77 s\n",
            "p missing rate: 8.76%\n",
            "  nth_start_imputation_init  313\n",
            "  100%\n",
            "  NRMSE_arr   0.6616275688270884\n",
            "  comp.time   119.56 s\n",
            "  Pearson_arr   0.895621914194143\n",
            "  comp.time   119.57 s\n",
            "p missing rate: 11.91%\n",
            "  nth_start_imputation_init  208\n",
            "  100%\n",
            "  NRMSE_arr   0.6046265943346942\n",
            "  comp.time   146.08 s\n",
            "  Pearson_arr   0.97018382700164\n",
            "  comp.time   146.08 s\n",
            "p missing rate: 14.50%\n",
            "  nth_start_imputation_init  157\n",
            "  100%\n",
            "  NRMSE_arr   0.6873728128931431\n",
            "  comp.time   163.86 s\n",
            "  Pearson_arr   0.9171782235748097\n",
            "  comp.time   163.86 s\n",
            "p missing rate: 18.11%\n",
            "  nth_start_imputation_init  80\n",
            "  100%\n",
            "  NRMSE_arr   0.8027391692979942\n",
            "  comp.time   182.71 s\n",
            "  Pearson_arr   0.9113145158196512\n",
            "  comp.time   182.72 s\n",
            "p missing rate: 23.29%\n",
            "  nth_start_imputation_init  49\n",
            "  100%\n",
            "  NRMSE_arr   0.6995836497426438\n",
            "  comp.time   198.49 s\n",
            "  Pearson_arr   0.9004797088770335\n",
            "  comp.time   198.50 s\n",
            "p missing rate: 29.82%\n",
            "  nth_start_imputation_init  19\n",
            "  100%\n",
            "  NRMSE_arr   0.8136413621954564\n",
            "  comp.time   212.61 s\n",
            "  Pearson_arr   0.921448923495367\n",
            "  comp.time   212.61 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.4*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SpqzNM-C3Lf"
      },
      "source": [
        "#### k = 40% (Percobaan 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTEdQePkC3Lf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b28750-74dd-4a04-9bac-4a2e28e7d905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 3.02%\n",
            "  nth_start_imputation_init  574\n",
            "  100%\n",
            "  NRMSE_arr   0.5644734739232052\n",
            "  comp.time   52.71 s\n",
            "  Pearson_arr   0.9833542590491782\n",
            "  comp.time   52.72 s\n",
            "p missing rate: 5.88%\n",
            "  nth_start_imputation_init  416\n",
            "  100%\n",
            "  NRMSE_arr   0.6164727198347723\n",
            "  comp.time   92.63 s\n",
            "  Pearson_arr   0.9499099553894469\n",
            "  comp.time   92.64 s\n",
            "p missing rate: 8.58%\n",
            "  nth_start_imputation_init  303\n",
            "  100%\n",
            "  NRMSE_arr   0.633529596936976\n",
            "  comp.time   123.18 s\n",
            "  Pearson_arr   0.9617718558578242\n",
            "  comp.time   123.18 s\n",
            "p missing rate: 11.52%\n",
            "  nth_start_imputation_init  212\n",
            "  100%\n",
            "  NRMSE_arr   0.6009728673914153\n",
            "  comp.time   147.93 s\n",
            "  Pearson_arr   0.9581374194502276\n",
            "  comp.time   147.94 s\n",
            "p missing rate: 15.26%\n",
            "  nth_start_imputation_init  135\n",
            "  100%\n",
            "  NRMSE_arr   0.6541770096043088\n",
            "  comp.time   169.21 s\n",
            "  Pearson_arr   0.9137924948999381\n",
            "  comp.time   169.21 s\n",
            "p missing rate: 18.16%\n",
            "  nth_start_imputation_init  94\n",
            "  100%\n",
            "  NRMSE_arr   0.7058422631183255\n",
            "  comp.time   179.39 s\n",
            "  Pearson_arr   0.9302409363994991\n",
            "  comp.time   179.39 s\n",
            "p missing rate: 23.99%\n",
            "  nth_start_imputation_init  35\n",
            "  100%\n",
            "  NRMSE_arr   0.7919045678372162\n",
            "  comp.time   199.54 s\n",
            "  Pearson_arr   0.9175301846299995\n",
            "  comp.time   199.54 s\n",
            "p missing rate: 30.36%\n",
            "  nth_start_imputation_init  10\n",
            "  100%\n",
            "  NRMSE_arr   0.9154700377354799\n",
            "  comp.time   221.48 s\n",
            "  Pearson_arr   0.7434374490731241\n",
            "  comp.time   221.48 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.4*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_6RdBskC3Lf"
      },
      "source": [
        "### Untuk k = 50%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNI5DyvOC3Lf"
      },
      "source": [
        "#### k = 50% (Percobaan 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqhV3bpDC3Lf",
        "outputId": "609ca8ce-5f9c-4a33-d548-17963377ad5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.88%\n",
            "  nth_start_imputation_init  586\n",
            "  100%\n",
            "  NRMSE_arr   0.6230992156817572\n",
            "  comp.time   48.79 s\n",
            "  Pearson_arr   0.8429443961477483\n",
            "  comp.time   48.79 s\n",
            "p missing rate: 6.11%\n",
            "  nth_start_imputation_init  409\n",
            "  100%\n",
            "  NRMSE_arr   0.6071471613358346\n",
            "  comp.time   93.32 s\n",
            "  Pearson_arr   0.9610570279288199\n",
            "  comp.time   93.33 s\n",
            "p missing rate: 8.81%\n",
            "  nth_start_imputation_init  294\n",
            "  100%\n",
            "  NRMSE_arr   0.5515109454910413\n",
            "  comp.time   123.80 s\n",
            "  Pearson_arr   0.9228455697093029\n",
            "  comp.time   123.81 s\n",
            "p missing rate: 12.09%\n",
            "  nth_start_imputation_init  215\n",
            "  100%\n",
            "  NRMSE_arr   0.6461676900663742\n",
            "  comp.time   144.33 s\n",
            "  Pearson_arr   0.9444308542334776\n",
            "  comp.time   144.34 s\n",
            "p missing rate: 14.83%\n",
            "  nth_start_imputation_init  144\n",
            "  100%\n",
            "  NRMSE_arr   0.6783112414642193\n",
            "  comp.time   166.05 s\n",
            "  Pearson_arr   0.866725833298248\n",
            "  comp.time   166.06 s\n",
            "p missing rate: 17.08%\n",
            "  nth_start_imputation_init  99\n",
            "  100%\n",
            "  NRMSE_arr   0.6759490274490122\n",
            "  comp.time   178.96 s\n",
            "  Pearson_arr   0.9330186615734039\n",
            "  comp.time   178.96 s\n",
            "p missing rate: 24.53%\n",
            "  nth_start_imputation_init  40\n",
            "  100%\n",
            "  NRMSE_arr   0.7449361123308584\n",
            "  comp.time   198.90 s\n",
            "  Pearson_arr   0.9242811580923154\n",
            "  comp.time   198.91 s\n",
            "p missing rate: 29.71%\n",
            "  nth_start_imputation_init  17\n",
            "  100%\n",
            "  NRMSE_arr   0.7841160477200715\n",
            "  comp.time   213.44 s\n",
            "  Pearson_arr   0.9226112685775626\n",
            "  comp.time   213.44 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.5*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsupVsLfC3Lg"
      },
      "source": [
        "#### k = 50% (Percobaan 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05qRGR8tC3Lg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3353ba99-dfaa-4a07-8f11-4a3b3f039c24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.79%\n",
            "  nth_start_imputation_init  594\n",
            "  100%\n",
            "  NRMSE_arr   0.6353329526210569\n",
            "  comp.time   48.85 s\n",
            "  Pearson_arr   0.9516314885793608\n",
            "  comp.time   48.85 s\n",
            "p missing rate: 6.59%\n",
            "  nth_start_imputation_init  392\n",
            "  100%\n",
            "  NRMSE_arr   0.5737692163112961\n",
            "  comp.time   99.18 s\n",
            "  Pearson_arr   0.9754215987543253\n",
            "  comp.time   99.19 s\n",
            "p missing rate: 8.66%\n",
            "  nth_start_imputation_init  303\n",
            "  100%\n",
            "  NRMSE_arr   0.6154539295970276\n",
            "  comp.time   120.16 s\n",
            "  Pearson_arr   0.9650948221501066\n",
            "  comp.time   120.16 s\n",
            "p missing rate: 12.37%\n",
            "  nth_start_imputation_init  174\n",
            "  100%\n",
            "  NRMSE_arr   0.7561043486242757\n",
            "  comp.time   155.98 s\n",
            "  Pearson_arr   0.8854220000182371\n",
            "  comp.time   155.98 s\n",
            "p missing rate: 15.04%\n",
            "  nth_start_imputation_init  129\n",
            "  100%\n",
            "  NRMSE_arr   0.6549875825888324\n",
            "  comp.time   166.92 s\n",
            "  Pearson_arr   0.9283104747731714\n",
            "  comp.time   166.92 s\n",
            "p missing rate: 18.57%\n",
            "  nth_start_imputation_init  88\n",
            "  100%\n",
            "  NRMSE_arr   0.7637047294474244\n",
            "  comp.time   180.97 s\n",
            "  Pearson_arr   0.9147303626260413\n",
            "  comp.time   180.98 s\n",
            "p missing rate: 23.43%\n",
            "  nth_start_imputation_init  42\n",
            "  100%\n",
            "  NRMSE_arr   0.8208552570056608\n",
            "  comp.time   202.80 s\n",
            "  Pearson_arr   0.8946879704553286\n",
            "  comp.time   202.80 s\n",
            "p missing rate: 29.76%\n",
            "  nth_start_imputation_init  10\n",
            "  100%\n",
            "  NRMSE_arr   0.7865944143392526\n",
            "  comp.time   214.22 s\n",
            "  Pearson_arr   0.9304873636796887\n",
            "  comp.time   214.23 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.5*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbG6bnrPC3Lg"
      },
      "source": [
        "#### k = 50% (Percobaan 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXbIaK-9C3Lg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc5edc4-86ce-42e1-8e14-e957c5a3f0a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 3.06%\n",
            "  nth_start_imputation_init  567\n",
            "  100%\n",
            "  NRMSE_arr   0.4735187459541012\n",
            "  comp.time   53.95 s\n",
            "  Pearson_arr   0.9629587892466247\n",
            "  comp.time   53.95 s\n",
            "p missing rate: 5.96%\n",
            "  nth_start_imputation_init  413\n",
            "  100%\n",
            "  NRMSE_arr   0.4952410220478155\n",
            "  comp.time   93.77 s\n",
            "  Pearson_arr   0.9849070457190614\n",
            "  comp.time   93.77 s\n",
            "p missing rate: 8.55%\n",
            "  nth_start_imputation_init  311\n",
            "  100%\n",
            "  NRMSE_arr   0.6498247971410946\n",
            "  comp.time   118.37 s\n",
            "  Pearson_arr   0.9355340633034366\n",
            "  comp.time   118.38 s\n",
            "p missing rate: 11.82%\n",
            "  nth_start_imputation_init  216\n",
            "  100%\n",
            "  NRMSE_arr   0.6809853033369574\n",
            "  comp.time   145.65 s\n",
            "  Pearson_arr   0.9205347415732968\n",
            "  comp.time   145.65 s\n",
            "p missing rate: 15.01%\n",
            "  nth_start_imputation_init  143\n",
            "  100%\n",
            "  NRMSE_arr   0.5794433774483726\n",
            "  comp.time   164.73 s\n",
            "  Pearson_arr   0.9462467565348426\n",
            "  comp.time   164.73 s\n",
            "p missing rate: 18.04%\n",
            "  nth_start_imputation_init  102\n",
            "  100%\n",
            "  NRMSE_arr   0.7118843369499294\n",
            "  comp.time   179.97 s\n",
            "  Pearson_arr   0.8994983650274054\n",
            "  comp.time   179.97 s\n",
            "p missing rate: 24.40%\n",
            "  nth_start_imputation_init  35\n",
            "  100%\n",
            "  NRMSE_arr   0.7960567659586514\n",
            "  comp.time   202.69 s\n",
            "  Pearson_arr   0.9234117459202061\n",
            "  comp.time   202.69 s\n",
            "p missing rate: 30.24%\n",
            "  nth_start_imputation_init  15\n",
            "  100%\n",
            "  NRMSE_arr   0.7633747799558357\n",
            "  comp.time   210.66 s\n",
            "  Pearson_arr   0.9117023317505755\n",
            "  comp.time   210.66 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.5*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXdwmbHkC3Lh"
      },
      "source": [
        "#### k = 50% (Percobaan 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqlKrdOhC3Lh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c24c4dce-26b5-4198-c7c4-a3cc4ed68f72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 2.78%\n",
            "  nth_start_imputation_init  589\n",
            "  100%\n",
            "  NRMSE_arr   0.7065724849407381\n",
            "  comp.time   48.66 s\n",
            "  Pearson_arr   0.923754213189941\n",
            "  comp.time   48.66 s\n",
            "p missing rate: 6.30%\n",
            "  nth_start_imputation_init  407\n",
            "  100%\n",
            "  NRMSE_arr   0.6567460267616385\n",
            "  comp.time   94.13 s\n",
            "  Pearson_arr   0.9014088769720372\n",
            "  comp.time   94.13 s\n",
            "p missing rate: 8.76%\n",
            "  nth_start_imputation_init  313\n",
            "  100%\n",
            "  NRMSE_arr   0.6633434630578335\n",
            "  comp.time   119.36 s\n",
            "  Pearson_arr   0.8780834542773926\n",
            "  comp.time   119.36 s\n",
            "p missing rate: 11.91%\n",
            "  nth_start_imputation_init  208\n",
            "  100%\n",
            "  NRMSE_arr   0.6009153232533142\n",
            "  comp.time   145.97 s\n",
            "  Pearson_arr   0.97008843465822\n",
            "  comp.time   145.98 s\n",
            "p missing rate: 14.50%\n",
            "  nth_start_imputation_init  157\n",
            "  100%\n",
            "  NRMSE_arr   0.6897171060654751\n",
            "  comp.time   164.78 s\n",
            "  Pearson_arr   0.9157654751205555\n",
            "  comp.time   164.78 s\n",
            "p missing rate: 18.11%\n",
            "  nth_start_imputation_init  80\n",
            "  100%\n",
            "  NRMSE_arr   0.8040271077666188\n",
            "  comp.time   183.00 s\n",
            "  Pearson_arr   0.9115476584314266\n",
            "  comp.time   183.00 s\n",
            "p missing rate: 23.29%\n",
            "  nth_start_imputation_init  49\n",
            "  100%\n",
            "  NRMSE_arr   0.696515094642498\n",
            "  comp.time   197.25 s\n",
            "  Pearson_arr   0.9196658631118352\n",
            "  comp.time   197.25 s\n",
            "p missing rate: 29.82%\n",
            "  nth_start_imputation_init  19\n",
            "  100%\n",
            "  NRMSE_arr   0.8114451095142702\n",
            "  comp.time   212.39 s\n",
            "  Pearson_arr   0.9164468807241329\n",
            "  comp.time   212.39 s\n"
          ]
        }
      ],
      "source": [
        "k_max = round(0.5*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T9IPs2fC3Li"
      },
      "source": [
        "#### k = 50% (Percobaan 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9H7KaQjC3Li",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "592e5497-81c3-4f7e-b8c1-118017b48886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p missing rate: 3.02%\n",
            "  nth_start_imputation_init  574\n",
            "  100%\n",
            "  NRMSE_arr   0.5643806979554085\n",
            "  comp.time   53.40 s\n",
            "  Pearson_arr   0.9824920253522559\n",
            "  comp.time   53.40 s\n",
            "p missing rate: 5.88%\n",
            "  nth_start_imputation_init  416\n",
            "  100%\n",
            "  NRMSE_arr   0.6214728463425316\n",
            "  comp.time   92.23 s\n",
            "  Pearson_arr   0.9478422157470437\n",
            "  comp.time   92.23 s\n",
            "p missing rate: 8.58%\n",
            "  nth_start_imputation_init  303\n",
            "  100%\n",
            "  NRMSE_arr   0.6414198425236274\n",
            "  comp.time   120.75 s\n",
            "  Pearson_arr   0.9590827798655663\n",
            "  comp.time   120.75 s\n",
            "p missing rate: 11.52%\n",
            "  nth_start_imputation_init  212\n",
            "  100%\n",
            "  NRMSE_arr   0.6034275187282931\n",
            "  comp.time   146.53 s\n",
            "  Pearson_arr   0.9586708686542034\n",
            "  comp.time   146.53 s\n",
            "p missing rate: 15.26%\n",
            "  nth_start_imputation_init  135\n",
            "   51%"
          ]
        }
      ],
      "source": [
        "k_max = round(0.5*D_gene_complete.raw_df.shape[0])\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLkzI_EcC3Li"
      },
      "source": [
        "#### k = 125 (Percobaan 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQNDCG9gC3Lj",
        "outputId": "de17b93f-1fd1-4fce-b12f-34a9fc941a87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "p missing rate: 2.88%\n",
            "  nth_start_imputation_init  586\n",
            "  100%\n",
            "  NRMSE_arr   0.5960939111618456\n",
            "  comp.time   51.14 s\n",
            "  Pearson_arr   0.8507361283219557\n",
            "  comp.time   51.14 s\n",
            "p missing rate: 6.11%\n",
            "  nth_start_imputation_init  409\n",
            "  100%\n",
            "  NRMSE_arr   0.6175173039418621\n",
            "  comp.time   94.66 s\n",
            "  Pearson_arr   0.9626709880825008\n",
            "  comp.time   94.66 s\n",
            "p missing rate: 8.81%\n",
            "  nth_start_imputation_init  294\n",
            "  100%\n",
            "  NRMSE_arr   0.5389321954903415\n",
            "  comp.time   122.08 s\n",
            "  Pearson_arr   0.9242911860982941\n",
            "  comp.time   122.08 s\n",
            "p missing rate: 12.09%\n",
            "  nth_start_imputation_init  215\n",
            "  100%\n",
            "  NRMSE_arr   0.6296288549697572\n",
            "  comp.time   146.28 s\n",
            "  Pearson_arr   0.9453727356129976\n",
            "  comp.time   146.28 s\n",
            "p missing rate: 14.83%\n",
            "  nth_start_imputation_init  144\n",
            "  100%\n",
            "  NRMSE_arr   0.7038134392959943\n",
            "  comp.time   166.14 s\n",
            "  Pearson_arr   0.8571980575201885\n",
            "  comp.time   166.15 s\n",
            "p missing rate: 17.08%\n",
            "  nth_start_imputation_init  99\n",
            "  100%\n",
            "  NRMSE_arr   0.6836468033799721\n",
            "  comp.time   178.07 s\n",
            "  Pearson_arr   0.9121321270497267\n",
            "  comp.time   178.07 s\n",
            "p missing rate: 24.53%\n",
            "  nth_start_imputation_init  40\n",
            "  100%\n",
            "  NRMSE_arr   0.7191231659276212\n",
            "  comp.time   200.97 s\n",
            "  Pearson_arr   0.9254112408188295\n",
            "  comp.time   200.98 s\n",
            "p missing rate: 29.71%\n",
            "  nth_start_imputation_init  17\n",
            "  100%\n",
            "  NRMSE_arr   0.7791687560263274\n",
            "  comp.time   218.85 s\n",
            "  Pearson_arr   0.9210085452361223\n",
            "  comp.time   218.85 s\n"
          ]
        }
      ],
      "source": [
        "#k_max = 25, 35, 45\n",
        "k_max = 125\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8MX47fHC3Lj"
      },
      "source": [
        "#### k = 125 (Percobaan 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OFvsZ_RC3Lk"
      },
      "outputs": [],
      "source": [
        "#k_max = 25, 35, 45\n",
        "k_max = 125\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE1Vn53jC3Lk"
      },
      "source": [
        "#### k = 125 (Percobaan 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aXKhbvXC3Lk"
      },
      "outputs": [],
      "source": [
        "#k_max = 25, 35, 45\n",
        "k_max = 125\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXfydGO6C3Ll"
      },
      "source": [
        "#### k = 125 (Percobaan 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFVDtjJRC3Ll"
      },
      "outputs": [],
      "source": [
        "#k_max = 25, 35, 45\n",
        "k_max = 125\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))#### k = 125 (Percobaan 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yezolvu8C3Lm"
      },
      "source": [
        "#### k = 125 (Percobaan 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqlXwaUIC3Lm"
      },
      "outputs": [],
      "source": [
        "#k_max = 25, 35, 45\n",
        "k_max = 125\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv6C0mpWC3Lo"
      },
      "source": [
        "#### k = 145 (Percobaan 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlBXK7AkC3Lo",
        "outputId": "cd6d8a46-5cdb-4939-c268-6cd3434120a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "p missing rate: 2.88%\n",
            "  nth_start_imputation_init  586\n",
            "  100%\n",
            "  NRMSE_arr   0.5971177932148954\n",
            "  comp.time   50.11 s\n",
            "  Pearson_arr   0.8502935710270406\n",
            "  comp.time   50.11 s\n",
            "p missing rate: 6.11%\n",
            "  nth_start_imputation_init  409\n",
            "  100%\n",
            "  NRMSE_arr   0.621518300128091\n",
            "  comp.time   91.78 s\n",
            "  Pearson_arr   0.9625547673265112\n",
            "  comp.time   91.78 s\n",
            "p missing rate: 8.81%\n",
            "  nth_start_imputation_init  294\n",
            "  100%\n",
            "  NRMSE_arr   0.5397470790379765\n",
            "  comp.time   124.89 s\n",
            "  Pearson_arr   0.9255976174539665\n",
            "  comp.time   124.89 s\n",
            "p missing rate: 12.09%\n",
            "  nth_start_imputation_init  215\n",
            "  100%\n",
            "  NRMSE_arr   0.6282056744206076\n",
            "  comp.time   149.82 s\n",
            "  Pearson_arr   0.9469871819128932\n",
            "  comp.time   149.83 s\n",
            "p missing rate: 14.83%\n",
            "  nth_start_imputation_init  144\n",
            "  100%\n",
            "  NRMSE_arr   0.7110300649157654\n",
            "  comp.time   164.60 s\n",
            "  Pearson_arr   0.8573613130463994\n",
            "  comp.time   164.60 s\n",
            "p missing rate: 17.08%\n",
            "  nth_start_imputation_init  99\n",
            "  100%\n",
            "  NRMSE_arr   0.6868678048004996\n",
            "  comp.time   175.78 s\n",
            "  Pearson_arr   0.9105258366646132\n",
            "  comp.time   175.78 s\n",
            "p missing rate: 24.53%\n",
            "  nth_start_imputation_init  40\n",
            "  100%\n",
            "  NRMSE_arr   0.7201380149224541\n",
            "  comp.time   198.50 s\n",
            "  Pearson_arr   0.927529022923299\n",
            "  comp.time   198.50 s\n",
            "p missing rate: 29.71%\n",
            "  nth_start_imputation_init  17\n",
            "  100%\n",
            "  NRMSE_arr   0.7833584661393463\n",
            "  comp.time   212.79 s\n",
            "  Pearson_arr   0.9294632696427753\n",
            "  comp.time   212.80 s\n"
          ]
        }
      ],
      "source": [
        "#k_max = 25, 35, 45\n",
        "k_max = 145\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhjekHNdC3Lp"
      },
      "source": [
        "#### k = 165 (Percobaan 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7BJcI1wC3Lp",
        "outputId": "d7bafa38-164f-43de-dd76-7d2a7ea84c0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "p missing rate: 2.88%\n",
            "  nth_start_imputation_init  586\n",
            "  100%\n",
            "  NRMSE_arr   0.6036454680497818\n",
            "  comp.time   48.79 s\n",
            "  Pearson_arr   0.8445146591447305\n",
            "  comp.time   48.79 s\n",
            "p missing rate: 6.11%\n",
            "  nth_start_imputation_init  409\n",
            "  100%\n",
            "  NRMSE_arr   0.5907442934373217\n",
            "  comp.time   91.93 s\n",
            "  Pearson_arr   0.9553014649162211\n",
            "  comp.time   91.93 s\n",
            "p missing rate: 8.81%\n",
            "  nth_start_imputation_init  294\n",
            "  100%\n",
            "  NRMSE_arr   0.543442002292941\n",
            "  comp.time   121.56 s\n",
            "  Pearson_arr   0.9244610148279934\n",
            "  comp.time   121.56 s\n",
            "p missing rate: 12.09%\n",
            "  nth_start_imputation_init  215\n",
            "  100%\n",
            "  NRMSE_arr   0.63272037000178\n",
            "  comp.time   142.03 s\n",
            "  Pearson_arr   0.9467866466392119\n",
            "  comp.time   142.03 s\n",
            "p missing rate: 14.83%\n",
            "  nth_start_imputation_init  144\n",
            "  100%\n",
            "  NRMSE_arr   0.7091035338106435\n",
            "  comp.time   161.56 s\n",
            "  Pearson_arr   0.8588952603003258\n",
            "  comp.time   161.57 s\n",
            "p missing rate: 17.08%\n",
            "  nth_start_imputation_init  99\n",
            "  100%\n",
            "  NRMSE_arr   0.691284351164987\n",
            "  comp.time   174.90 s\n",
            "  Pearson_arr   0.9072973254921463\n",
            "  comp.time   174.90 s\n",
            "p missing rate: 24.53%\n",
            "  nth_start_imputation_init  40\n",
            "  100%\n",
            "  NRMSE_arr   0.7460586630915561\n",
            "  comp.time   197.48 s\n",
            "  Pearson_arr   0.9242000769273772\n",
            "  comp.time   197.49 s\n",
            "p missing rate: 29.71%\n",
            "  nth_start_imputation_init  17\n",
            "  100%\n",
            "  NRMSE_arr   0.7818728125229526\n",
            "  comp.time   206.61 s\n",
            "  Pearson_arr   0.9287105744039239\n",
            "  comp.time   206.61 s\n"
          ]
        }
      ],
      "source": [
        "#k_max = 25, 35, 45\n",
        "k_max = 165\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAOgE1I6C3Lq"
      },
      "source": [
        "#### k = 335"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ut_OshIcC3Lq"
      },
      "outputs": [],
      "source": [
        "#k_max = 25, 35, 45\n",
        "k_max = 335\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0_bKx8SC3Lr"
      },
      "source": [
        "#### k = 375"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRFi1RBSC3Lr"
      },
      "outputs": [],
      "source": [
        "#k_max = 25, 35, 45\n",
        "k_max = 375\n",
        "\n",
        "y_cluster_val = D_gene_complete.value.copy()\n",
        "\n",
        "NRMSE_arr = np.zeros(len(list_missing_files))\n",
        "Pearson_arr = np.zeros(len(list_missing_files))\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):\n",
        "    # create y_cluster_val_mis\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    p_mis_rate = y_cluster_val_mis.get_p_mis_rate()\n",
        "    \n",
        "    # compute y_estimate\n",
        "    print(\"p missing rate: {:.2f}%\".format(p_mis_rate*10))\n",
        "    y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted \\\n",
        "        = SBi_MSRE(y_cluster_val, y_cluster_val_mis.value, k_max=k_max)\n",
        "    print(\"\")\n",
        "    #print(f\"F_mat_mis\\n{F_mat_mis}\")\n",
        "    #print(f\"F_mat_orig\\n{np.argwhere(F_mat_orig == 0)}\")\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_arr[i] = compute_NRMSE(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  NRMSE_arr  \", NRMSE_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))\n",
        "\n",
        "    # compute Pearson Correlation\n",
        "    Pearson_arr[i] = compute_pearsoncorr(y_cluster_val_sorted, y_cluster_val_estimate, F_mat_sorted)\n",
        "    print(\"  Pearson_arr  \", Pearson_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKdtru_2Qf5_"
      },
      "source": [
        "### Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aigv2g8GW_DC"
      },
      "outputs": [],
      "source": [
        "class AvgWeightImputation(object):\n",
        "    \"\"\"\n",
        "        A class to define an object of row or column imputation method\n",
        "        There are two type of average division.\n",
        "        You can set \"full\" division. It means whatever your element (NaN or not)\n",
        "        it will be counted as a number of divisor.\n",
        "        If you select \"partial\" division, you only divide the sum of row or column\n",
        "        by the elements which are not NaN.\n",
        "        \n",
        "        Available types of weight: \"ones\", \"random\", \"euclid\"\n",
        "        \n",
        "        When we select method=\"full\" and weights=\"random\", we assume\n",
        "        that NaN elements has zero values such that doesn't contribute\n",
        "        to the sum.\n",
        "        \n",
        "        For the type of weight is \"euclid\", it will use the same procedure\n",
        "        in the calculation of `compute_alpha_mis`.\n",
        "        Selecting {\"full\", \"euclid\"} or {\"partial\", \"euclid\"} doesn't have any \n",
        "        difference, because we have performed rowImputation or colImputation\n",
        "        before calculating euclidean distance.\n",
        "    \"\"\"\n",
        "    def __init__(self, avg_div=\"full\", method=\"row\", weights=\"ones\", rand_range=[0, 1]):\n",
        "        self.avg_div = avg_div\n",
        "        self.method = method\n",
        "        self.weights = weights\n",
        "        self.rand_range = rand_range\n",
        "        \n",
        "    def fit_transform(self, D_gene_mis):\n",
        "        avg_div = self.avg_div\n",
        "        method = self.method\n",
        "        weights = self.weights\n",
        "        \n",
        "        if method == \"row\":\n",
        "            A = self.row_avg(self, D_gene_mis, avg_div, weights)\n",
        "        elif method == \"col\":\n",
        "            A = self.col_avg(self, D_gene_mis, avg_div, weights)\n",
        "        elif method == \"rowcol\":\n",
        "            A = self.rowcol_avg(self, D_gene_mis, avg_div, weights)\n",
        "        else:\n",
        "            print(f'Set the correct imputation: \"row\" or \"col\"')\n",
        "        \n",
        "        return A\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def row_avg(self, D_gene_mis, avg_div, weights):\n",
        "        a, b = self.rand_range\n",
        "        missing_idx = np.argwhere(np.isnan(D_gene_mis))\n",
        "        A = D_gene_mis.copy()\n",
        "        D_gene_shape = D_gene_mis.shape\n",
        "        \n",
        "        # we need a complete gene expression (without missing val to \n",
        "        # compute euclidean distance). Another option is to set\n",
        "        # the missing val to be zero, but this will differ to the SBi_MSRE algorithm\n",
        "        # which is set the initial missing val by row average\n",
        "        if weights == \"euclid\":\n",
        "            B = self.row_avg(self, D_gene_mis, avg_div, \"ones\")\n",
        "    \n",
        "    \n",
        "        if avg_div == \"partial\":\n",
        "            \n",
        "            for p, q in missing_idx:\n",
        "                \n",
        "                idx_cols_without_nan = np.argwhere(np.isnan(D_gene_mis[p]) == False).flatten()\n",
        "                \n",
        "                if weights == \"ones\":\n",
        "                    A[p, q] = np.sum(D_gene_mis[p, idx_cols_without_nan])/len(idx_cols_without_nan)\n",
        "                elif weights == \"random\":\n",
        "                    rand_weights = self.generate_random(self, a, b, len(idx_cols_without_nan))\n",
        "                    #rand_weights = rng_generator.random(len(idx_cols_without_nan))\n",
        "                    A[p, q] = np.sum(D_gene_mis[p, idx_cols_without_nan] * rand_weights)/np.sum(rand_weights)\n",
        "                elif weights == \"euclid\":\n",
        "                    idx_cols_without_q = np.arange(D_gene_shape[1], dtype=int)\\\n",
        "                                     [np.arange(D_gene_shape[1], dtype=int) != q]\n",
        "                    euclid_weights = self.weight_for_row_avg(B, q)\n",
        "                    A[p, q] = np.sum(B[p, idx_cols_without_q] * euclid_weights)\\\n",
        "                              /np.sum(euclid_weights)\n",
        "                                        \n",
        "                else:\n",
        "                    print(f'Set the correct weights: \"ones\", \"random\", or \"euclid\"')\n",
        "                    break\n",
        "                    \n",
        "        \n",
        "        elif avg_div == \"full\":\n",
        "            \n",
        "            for p, q in missing_idx:\n",
        "                \n",
        "                idx_cols_without_nan = np.argwhere(np.isnan(D_gene_mis[p]) == False).flatten()\n",
        "\n",
        "                if weights == \"ones\":\n",
        "                    A[p, q] = np.sum(D_gene_mis[p, idx_cols_without_nan])/len(D_gene_mis[p])\n",
        "                elif weights == \"random\":\n",
        "                    rand_weights = self.generate_random(self, a, b, len(D_gene_mis[p]))\n",
        "                    #rand_weights = rng_generator.random(len(D_gene_mis[p]))\n",
        "                    A[p, q] = np.sum(D_gene_mis[p, idx_cols_without_nan] \\\n",
        "                                     * rand_weights[idx_cols_without_nan])\\\n",
        "                              /np.sum(rand_weights)\n",
        "                elif weights == \"euclid\":\n",
        "                    idx_cols_without_q = np.arange(D_gene_shape[1], dtype=int)\\\n",
        "                                     [np.arange(D_gene_shape[1], dtype=int) != q]\n",
        "                    euclid_weights = self.weight_for_row_avg(B, q)\n",
        "                    A[p, q] = np.sum(B[p, idx_cols_without_q] * euclid_weights)\\\n",
        "                              /np.sum(euclid_weights)\n",
        "                else:\n",
        "                    print(f'Set the correct weights: \"ones\", \"random\", or \"euclid\"')\n",
        "                    break\n",
        "                \n",
        "        else:\n",
        "            print(f'Set the correct option for avg_div: \"full\" or \"partial\"')\n",
        "            return None\n",
        "        \n",
        "        return A\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def col_avg(self, D_gene_mis, avg_div, weights):\n",
        "        a, b = self.rand_range\n",
        "        A = D_gene_mis.copy()\n",
        "        D_gene_shape = D_gene_mis.shape\n",
        "        \n",
        "        # we need a complete gene expression (without missing val to \n",
        "        # compute euclidean distance). Another option is to set\n",
        "        # the missing val to be zero, but this will differ to the SBi_MSRE algorithm\n",
        "        # which is set the initial missing val by row average\n",
        "        if weights == \"euclid\":\n",
        "            B = self.col_avg(self, D_gene_mis, avg_div, \"ones\")\n",
        "        \n",
        "        if avg_div == \"partial\":\n",
        "            \n",
        "            for col in range(len(D_gene_mis[0])):\n",
        "                missing_rows = np.argwhere(np.isnan(D_gene_mis[:, col])).flatten()\n",
        "                row_without_nan = np.argwhere(np.isnan(D_gene_mis[:, col]) == False).flatten()\n",
        "                \n",
        "                # Two for loops aren't not slowing down the computation,\n",
        "                # because the number of missing cols are small\n",
        "                for row in missing_rows:\n",
        "                    if weights == \"ones\":\n",
        "                        A[row, col] = np.sum(D_gene_mis[row_without_nan, col])/len(row_without_nan)\n",
        "                    elif weights == \"random\":\n",
        "                        rand_weights = self.generate_random(self, a, b, len(row_without_nan))\n",
        "                        #rand_weights = rng_generator.random(len(row_without_nan))\n",
        "                        A[row, col] = np.sum(D_gene_mis[row_without_nan, col] * rand_weights)\\\n",
        "                                      /np.sum(rand_weights)\n",
        "                    elif weights == \"euclid\":\n",
        "                        idx_rows_without_row = np.arange(D_gene_shape[0], dtype=int)\\\n",
        "                                               [np.arange(D_gene_shape[0], dtype=int) != row]\n",
        "                        euclid_weights = self.weight_for_col_avg(B, row)\n",
        "                        A[row, col] = np.sum(B[idx_rows_without_row, col] * euclid_weights)\\\n",
        "                                      /np.sum(euclid_weights)\n",
        "                    else:\n",
        "                        print(f'Set the correct weights: \"ones\", \"random\", or \"euclid\"')\n",
        "                        break\n",
        "                    \n",
        "                    \n",
        "        elif avg_div == \"full\":\n",
        "            for col in range(len(D_gene_mis[0])):\n",
        "                missing_rows = np.argwhere(np.isnan(D_gene_mis[:, col])).flatten()\n",
        "                row_without_nan = np.argwhere(np.isnan(D_gene_mis[:, col]) == False).flatten()\n",
        "                \n",
        "                for row in missing_rows:\n",
        "                    if weights == \"ones\":\n",
        "                        A[row, col] = np.sum(D_gene_mis[row_without_nan, col])/len(D_gene_mis)\n",
        "                    elif weights == \"random\":\n",
        "                        rand_weights = self.generate_random(self, a, b, len(D_gene_mis))\n",
        "                        #rand_weights = rng_generator.random(len(D_gene_mis))\n",
        "                        A[row, col] = np.sum(D_gene_mis[row_without_nan, col] *  rand_weights[row_without_nan])\\\n",
        "                                      /np.sum(rand_weights)\n",
        "                    elif weights == \"euclid\":\n",
        "                        idx_rows_without_row = np.arange(D_gene_shape[0], dtype=int)\\\n",
        "                                               [np.arange(D_gene_shape[0], dtype=int) != row]\n",
        "                        euclid_weights = self.weight_for_col_avg(B, row)\n",
        "                        A[row, col] = np.sum(B[idx_rows_without_row, col] * euclid_weights)\\\n",
        "                                      /np.sum(euclid_weights)\n",
        "                    else:\n",
        "                        print(f'Set the correct weights: \"ones\", \"random\", or \"euclid\"')\n",
        "                        break\n",
        "                    \n",
        "        else:\n",
        "            print(f'Set the correct option for avg_div: \"full\" or \"partial\"')\n",
        "            return None\n",
        "        \n",
        "        return A\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def rowcol_avg(self, D_gene_mis, avg_div, weights):\n",
        "        missing_idx = np.argwhere(np.isnan(D_gene_mis))\n",
        "        A = D_gene_mis.copy()\n",
        "        \n",
        "        Arow = self.row_avg(self, D_gene_mis, avg_div, weights)\n",
        "        Acol = self.col_avg(self, D_gene_mis, avg_div, weights)\n",
        "                \n",
        "        for p, q in missing_idx:\n",
        "            A[p, q] = (Arow[p, q] + Acol[p, q])/2.\n",
        "        \n",
        "        \n",
        "        return A\n",
        "    \n",
        "    @staticmethod\n",
        "    def generate_random(self, a, b, N):\n",
        "        a, b = self.rand_range\n",
        " \n",
        "        return (b - a)*rng_generator.random(N) + a\n",
        "\n",
        "    @staticmethod\n",
        "    def weight_for_row_avg(C_bicluster, target_col):\n",
        "        C_bicluster_shape = C_bicluster.shape\n",
        "        col_without_target_col = np.arange(C_bicluster_shape[1], dtype=int)\\\n",
        "                                 [np.arange(C_bicluster_shape[1], dtype=int) != target_col]\n",
        "        C_target_col = C_bicluster[:, target_col].reshape(-1, 1)\n",
        "        C_remain = C_bicluster[:, col_without_target_col]\n",
        "\n",
        "        euclidean_arr = np.sqrt(np.sum((C_remain - C_target_col)**2, axis=0))\n",
        "\n",
        "\n",
        "        if np.any(euclidean_arr < 1e-14):\n",
        "            # We only consider the closest and discard the others\n",
        "            idx_nan_weight = np.argwhere(euclidean_arr < 1e-14)\n",
        "            W_jl = np.zeros_like(euclidean_arr)\n",
        "            W_jl[idx_nan_weight] = 1/len(idx_nan_weight)\n",
        "        else:\n",
        "            inv_euclid_arr = 1./euclidean_arr  # further genes should have small contribution\n",
        "            W_jl = (inv_euclid_arr) /np.sum(inv_euclid_arr) \\\n",
        "                    if np.sum(inv_euclid_arr) > 1e-14 else np.zeros_like(inv_euclid_arr)\n",
        "        \n",
        "        return W_jl\n",
        "    \n",
        "    @staticmethod\n",
        "    def weight_for_col_avg(C_bicluster, target_row):\n",
        "        C_bicluster_shape = C_bicluster.shape\n",
        "        row_without_target_row = np.arange(C_bicluster_shape[0], dtype=int)\\\n",
        "                                 [np.arange(C_bicluster_shape[0], dtype=int) != target_row]\n",
        "        \n",
        "        C_target_row = C_bicluster[target_row]\n",
        "        C_remain = C_bicluster[row_without_target_row]\n",
        "\n",
        "        euclidean_arr = np.sqrt(np.sum((C_remain - C_target_row)**2, axis=1))\n",
        "\n",
        "        if np.any(euclidean_arr < 1e-14):\n",
        "            # We only consider the closest and discard the others\n",
        "            idx_nan_weight = np.argwhere(euclidean_arr < 1e-14)\n",
        "            W_ik = np.zeros_like(euclidean_arr)\n",
        "            W_ik[idx_nan_weight] = 1/len(idx_nan_weight)\n",
        "        else:\n",
        "            inv_euclid_arr = 1./euclidean_arr   # further genes should have small contribution\n",
        "            W_ik = (inv_euclid_arr) /np.sum(inv_euclid_arr) \\\n",
        "                    if np.sum(inv_euclid_arr) > 1e-14 else np.zeros_like(inv_euclid_arr)\n",
        "        \n",
        "        return W_ik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fH0wbD2W44W"
      },
      "outputs": [],
      "source": [
        "# lower bound should be >= 0\n",
        "rand_range = [0, 2]\n",
        "\n",
        "NRMSE_row_avg_arr = np.zeros_like(NRMSE_arr)\n",
        "NRMSE_col_avg_arr = np.zeros_like(NRMSE_arr)\n",
        "NRMSE_rowcol_avg_arr = np.zeros_like(NRMSE_arr)\n",
        "\n",
        "row_imputer = AvgWeightImputation(method=\"row\", weights=\"euclid\")\n",
        "col_imputer = AvgWeightImputation(method=\"col\", weights=\"euclid\")\n",
        "rowcol_imputer = AvgWeightImputation(method=\"rowcol\", weights=\"euclid\")\n",
        "\n",
        "for i, y_cluster_val_mis in enumerate(D_gene_mis_arr):    \n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    y_cluster_val_estimate_row = row_imputer.fit_transform(y_cluster_val_mis.value)\n",
        "    y_cluster_val_estimate_col = col_imputer.fit_transform(y_cluster_val_mis.value)\n",
        "    y_cluster_val_estimate_rowcol = rowcol_imputer.fit_transform(y_cluster_val_mis.value)\n",
        "    \n",
        "    F_mat_orig = y_cluster_val_mis.get_F_mat()\n",
        "    \n",
        "    # compute NRMSE\n",
        "    NRMSE_row_avg_arr[i] = compute_NRMSE(y_cluster_val, y_cluster_val_estimate_row, F_mat_orig)\n",
        "    NRMSE_col_avg_arr[i] = compute_NRMSE(y_cluster_val, y_cluster_val_estimate_col, F_mat_orig)\n",
        "    NRMSE_rowcol_avg_arr[i] = compute_NRMSE(y_cluster_val, y_cluster_val_estimate_rowcol, F_mat_orig)\n",
        "    #print(\"  NRMSE_arr  \", NRMSE_rowcol_avg_arr[i])\n",
        "    print(\"  comp.time   {:.2f} s\".format(time.perf_counter() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MM-F2-mC3Ls"
      },
      "outputs": [],
      "source": [
        "gold = \"#D4AF37\"\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "p_mis_rate_arr = [D_gene_mis.get_p_mis_rate() for D_gene_mis in D_gene_mis_arr]\n",
        "\n",
        "ax.plot(p_mis_rate_arr, NRMSE_arr, \"ro-\", label=\"SBiMSRE\",\n",
        "        markeredgecolor='red', markerfacecolor=\"white\");\n",
        "ax.plot(p_mis_rate_arr, NRMSE_rowcol_avg_arr, \"o-.\", color=gold, label=\"RowColAvgWeight\",\n",
        "        markeredgecolor=gold, markerfacecolor=\"white\")\n",
        "\n",
        "ax.set_xlabel(\"Rate of missing entries\")\n",
        "ax.set_ylabel(\"NRMSE\")\n",
        "\n",
        "ax.legend(loc=\"upper left\", bbox_to_anchor=[1.03, 1], handlelength=4, borderaxespad=0)\n",
        "\n",
        "plt.show(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNC3uG4lC3Ls"
      },
      "outputs": [],
      "source": [
        "gold = \"#D4AF37\"\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "p_mis_rate_arr = [D_gene_mis.get_p_mis_rate() for D_gene_mis in D_gene_mis_arr]\n",
        "\n",
        "ax.plot(p_mis_rate_arr, NRMSE_arr, \"ro-\", label=\"SBiMSRE\",\n",
        "        markeredgecolor='red', markerfacecolor=\"white\");\n",
        "ax.plot(p_mis_rate_arr, NRMSE_row_avg_arr, \"bo--\", label=\"RowAvgWeight\",\n",
        "        markeredgecolor='blue', markerfacecolor=\"white\");\n",
        "ax.plot(p_mis_rate_arr, NRMSE_col_avg_arr, \"go:\", label=\"ColAvgWeight\",\n",
        "        markeredgecolor='green', markerfacecolor=\"white\")\n",
        "ax.plot(p_mis_rate_arr, NRMSE_rowcol_avg_arr, \"o-.\", color=gold, label=\"RowColAvgWeight\",\n",
        "        markeredgecolor=gold, markerfacecolor=\"white\")\n",
        "\n",
        "ax.set_xlabel(\"Rate of missing entries\")\n",
        "ax.set_ylabel(\"NRMSE\")\n",
        "\n",
        "ax.legend(loc=\"upper left\", bbox_to_anchor=[1.03, 1], handlelength=4, borderaxespad=0)\n",
        "\n",
        "plt.show(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmvgbzYkqfxK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SBi-SSSim-MSRimpute.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}